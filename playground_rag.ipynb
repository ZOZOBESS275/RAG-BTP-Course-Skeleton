{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import PointStruct, VectorParams, Distance\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "driver = GraphDatabase.driver(\"bolt://localhost:7687\", auth=(\"neo4j\", \"12345678\"))\n",
    "\n",
    "def get_related_keywords(keyword):\n",
    "    query = \"\"\"\n",
    "    MATCH (n)\n",
    "    WHERE toLower(n.name) CONTAINS toLower($keyword)\n",
    "    MATCH (n)--(related)\n",
    "    RETURN DISTINCT related.name AS keyword, labels(related) AS type\n",
    "    \"\"\"\n",
    "    with driver.session() as session:\n",
    "        result = session.run(query, keyword=keyword)\n",
    "        return [record[\"keyword\"] for record in result]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pompe à chaleur', 'Plancher chauffant', 'Isolation thermique']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(get_related_keywords(\"chauffage\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding dimension: 768\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(\"CHUNKS\\\\file_chunks.csv\") \n",
    "model = SentenceTransformer(\"dangvantuan/sentence-camembert-base\")\n",
    "\n",
    "# Let's quickly check the embedding dimension:\n",
    "dummy_vector = model.encode(\"texte de test\")\n",
    "dim = len(dummy_vector)  # This will be used in Qdrant's vector params\n",
    "print(f\"Embedding dimension: {dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amine\\AppData\\Local\\Temp\\ipykernel_30736\\3057219795.py:6: DeprecationWarning: `recreate_collection` method is deprecated and will be removed in the future. Use `collection_exists` to check collection existence and `create_collection` instead.\n",
      "  client.recreate_collection(\n",
      "11630it [03:10, 60.97it/s]\n"
     ]
    },
    {
     "ename": "UnexpectedResponse",
     "evalue": "Unexpected Response: 400 (Bad Request)\nRaw response content:\nb'{\"status\":{\"error\":\"Payload error: JSON payload (196289181 bytes) is larger than allowed (limit: 33554432 bytes).\"},\"time\":0.0}'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnexpectedResponse\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 35\u001b[0m\n\u001b[0;32m     26\u001b[0m     points_to_upsert\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m     27\u001b[0m         PointStruct(\n\u001b[0;32m     28\u001b[0m             \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39mpoint_id,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     31\u001b[0m         )\n\u001b[0;32m     32\u001b[0m     )\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Upsert in batches (here everything at once for brevity):\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupsert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpoints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpoints_to_upsert\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpsert complete. Stored embeddings in Qdrant.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\conda\\envs\\ds_env\\lib\\site-packages\\qdrant_client\\qdrant_client.py:1567\u001b[0m, in \u001b[0;36mQdrantClient.upsert\u001b[1;34m(self, collection_name, points, wait, ordering, shard_key_selector, **kwargs)\u001b[0m\n\u001b[0;32m   1564\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m         points \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embed_models(points, is_query\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m-> 1567\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mupsert(\n\u001b[0;32m   1568\u001b[0m     collection_name\u001b[38;5;241m=\u001b[39mcollection_name,\n\u001b[0;32m   1569\u001b[0m     points\u001b[38;5;241m=\u001b[39mpoints,\n\u001b[0;32m   1570\u001b[0m     wait\u001b[38;5;241m=\u001b[39mwait,\n\u001b[0;32m   1571\u001b[0m     ordering\u001b[38;5;241m=\u001b[39mordering,\n\u001b[0;32m   1572\u001b[0m     shard_key_selector\u001b[38;5;241m=\u001b[39mshard_key_selector,\n\u001b[0;32m   1573\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1574\u001b[0m )\n",
      "File \u001b[1;32md:\\conda\\envs\\ds_env\\lib\\site-packages\\qdrant_client\\qdrant_remote.py:1908\u001b[0m, in \u001b[0;36mQdrantRemote.upsert\u001b[1;34m(self, collection_name, points, wait, ordering, shard_key_selector, **kwargs)\u001b[0m\n\u001b[0;32m   1905\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(points, models\u001b[38;5;241m.\u001b[39mBatch):\n\u001b[0;32m   1906\u001b[0m     points \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mPointsBatch(batch\u001b[38;5;241m=\u001b[39mpoints, shard_key\u001b[38;5;241m=\u001b[39mshard_key_selector)\n\u001b[1;32m-> 1908\u001b[0m http_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopenapi_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoints_api\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupsert_points\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1909\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1910\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1911\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpoint_insert_operations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpoints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1912\u001b[0m \u001b[43m    \u001b[49m\u001b[43mordering\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mordering\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1913\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mresult\n\u001b[0;32m   1914\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m http_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpsert returned None result\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1915\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m http_result\n",
      "File \u001b[1;32md:\\conda\\envs\\ds_env\\lib\\site-packages\\qdrant_client\\http\\api\\points_api.py:987\u001b[0m, in \u001b[0;36mSyncPointsApi.upsert_points\u001b[1;34m(self, collection_name, wait, ordering, point_insert_operations)\u001b[0m\n\u001b[0;32m    977\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupsert_points\u001b[39m(\n\u001b[0;32m    978\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    979\u001b[0m     collection_name: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    982\u001b[0m     point_insert_operations: m\u001b[38;5;241m.\u001b[39mPointInsertOperations \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    983\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m m\u001b[38;5;241m.\u001b[39mInlineResponse2006:\n\u001b[0;32m    984\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    985\u001b[0m \u001b[38;5;124;03m    Perform insert + updates on points. If point with given ID already exists - it will be overwritten.\u001b[39;00m\n\u001b[0;32m    986\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 987\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_for_upsert_points\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    988\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    989\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    990\u001b[0m \u001b[43m        \u001b[49m\u001b[43mordering\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mordering\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    991\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpoint_insert_operations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpoint_insert_operations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    992\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\conda\\envs\\ds_env\\lib\\site-packages\\qdrant_client\\http\\api\\points_api.py:512\u001b[0m, in \u001b[0;36m_PointsApi._build_for_upsert_points\u001b[1;34m(self, collection_name, wait, ordering, point_insert_operations)\u001b[0m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m headers:\n\u001b[0;32m    511\u001b[0m     headers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 512\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    513\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtype_\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInlineResponse2006\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    514\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPUT\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    515\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/collections/\u001b[39;49m\u001b[38;5;132;43;01m{collection_name}\u001b[39;49;00m\u001b[38;5;124;43m/points\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    516\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    517\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    519\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    520\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\conda\\envs\\ds_env\\lib\\site-packages\\qdrant_client\\http\\api_client.py:89\u001b[0m, in \u001b[0;36mApiClient.request\u001b[1;34m(self, type_, method, url, path_params, **kwargs)\u001b[0m\n\u001b[0;32m     87\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     88\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mbuild_request(method, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 89\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtype_\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\conda\\envs\\ds_env\\lib\\site-packages\\qdrant_client\\http\\api_client.py:112\u001b[0m, in \u001b[0;36mApiClient.send\u001b[1;34m(self, request, type_)\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ValidationError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    111\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ResponseHandlingException(e)\n\u001b[1;32m--> 112\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m UnexpectedResponse\u001b[38;5;241m.\u001b[39mfor_response(response)\n",
      "\u001b[1;31mUnexpectedResponse\u001b[0m: Unexpected Response: 400 (Bad Request)\nRaw response content:\nb'{\"status\":{\"error\":\"Payload error: JSON payload (196289181 bytes) is larger than allowed (limit: 33554432 bytes).\"},\"time\":0.0}'"
     ]
    }
   ],
   "source": [
    "# Adjust host/port if Qdrant is elsewhere:\n",
    "client = QdrantClient(url=\"http://localhost:6333\")  # or QdrantClient(\"localhost\", port=6333)\n",
    "\n",
    "# Create or recreate a collection\n",
    "collection_name = \"PROJET_RCRA2\"\n",
    "client.recreate_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=VectorParams(size=dim, distance=Distance.COSINE)\n",
    ")\n",
    "\n",
    "# Now, embed and upsert each CSV chunk as a separate point in Qdrant\n",
    "points_to_upsert = []\n",
    "for idx, row in tqdm(df.iterrows()):\n",
    "    text_chunk = row[\"chunk\"]\n",
    "    file_id = row[\"file\"]  # might be useful metadata\n",
    "    vector = model.encode(text_chunk)\n",
    "\n",
    "    # Create a unique ID for each chunk row\n",
    "    point_id = idx  \n",
    "    payload = {\n",
    "        \"file\": file_id, \n",
    "        \"chunk\": text_chunk\n",
    "    }\n",
    "\n",
    "    # Construct a PointStruct\n",
    "    points_to_upsert.append(\n",
    "        PointStruct(\n",
    "            id=point_id,\n",
    "            vector=vector.tolist(),\n",
    "            payload=payload\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Uploaded batch 0 to 100\n",
      "✅ Uploaded batch 100 to 200\n",
      "✅ Uploaded batch 200 to 300\n",
      "✅ Uploaded batch 300 to 400\n",
      "✅ Uploaded batch 400 to 500\n",
      "✅ Uploaded batch 500 to 600\n",
      "✅ Uploaded batch 600 to 700\n",
      "✅ Uploaded batch 700 to 800\n",
      "✅ Uploaded batch 800 to 900\n",
      "✅ Uploaded batch 900 to 1000\n",
      "✅ Uploaded batch 1000 to 1100\n",
      "✅ Uploaded batch 1100 to 1200\n",
      "✅ Uploaded batch 1200 to 1300\n",
      "✅ Uploaded batch 1300 to 1400\n",
      "✅ Uploaded batch 1400 to 1500\n",
      "✅ Uploaded batch 1500 to 1600\n",
      "✅ Uploaded batch 1600 to 1700\n",
      "✅ Uploaded batch 1700 to 1800\n",
      "✅ Uploaded batch 1800 to 1900\n",
      "✅ Uploaded batch 1900 to 2000\n",
      "✅ Uploaded batch 2000 to 2100\n",
      "✅ Uploaded batch 2100 to 2200\n",
      "✅ Uploaded batch 2200 to 2300\n",
      "✅ Uploaded batch 2300 to 2400\n",
      "✅ Uploaded batch 2400 to 2500\n",
      "✅ Uploaded batch 2500 to 2600\n",
      "✅ Uploaded batch 2600 to 2700\n",
      "✅ Uploaded batch 2700 to 2800\n",
      "✅ Uploaded batch 2800 to 2900\n",
      "✅ Uploaded batch 2900 to 3000\n",
      "✅ Uploaded batch 3000 to 3100\n",
      "✅ Uploaded batch 3100 to 3200\n",
      "✅ Uploaded batch 3200 to 3300\n",
      "✅ Uploaded batch 3300 to 3400\n",
      "✅ Uploaded batch 3400 to 3500\n",
      "✅ Uploaded batch 3500 to 3600\n",
      "✅ Uploaded batch 3600 to 3700\n",
      "✅ Uploaded batch 3700 to 3800\n",
      "✅ Uploaded batch 3800 to 3900\n",
      "✅ Uploaded batch 3900 to 4000\n",
      "✅ Uploaded batch 4000 to 4100\n",
      "✅ Uploaded batch 4100 to 4200\n",
      "✅ Uploaded batch 4200 to 4300\n",
      "✅ Uploaded batch 4300 to 4400\n",
      "✅ Uploaded batch 4400 to 4500\n",
      "✅ Uploaded batch 4500 to 4600\n",
      "✅ Uploaded batch 4600 to 4700\n",
      "✅ Uploaded batch 4700 to 4800\n",
      "✅ Uploaded batch 4800 to 4900\n",
      "✅ Uploaded batch 4900 to 5000\n",
      "✅ Uploaded batch 5000 to 5100\n",
      "✅ Uploaded batch 5100 to 5200\n",
      "✅ Uploaded batch 5200 to 5300\n",
      "✅ Uploaded batch 5300 to 5400\n",
      "✅ Uploaded batch 5400 to 5500\n",
      "✅ Uploaded batch 5500 to 5600\n",
      "✅ Uploaded batch 5600 to 5700\n",
      "✅ Uploaded batch 5700 to 5800\n",
      "✅ Uploaded batch 5800 to 5900\n",
      "✅ Uploaded batch 5900 to 6000\n",
      "✅ Uploaded batch 6000 to 6100\n",
      "✅ Uploaded batch 6100 to 6200\n",
      "✅ Uploaded batch 6200 to 6300\n",
      "✅ Uploaded batch 6300 to 6400\n",
      "✅ Uploaded batch 6400 to 6500\n",
      "✅ Uploaded batch 6500 to 6600\n",
      "✅ Uploaded batch 6600 to 6700\n",
      "✅ Uploaded batch 6700 to 6800\n",
      "✅ Uploaded batch 6800 to 6900\n",
      "✅ Uploaded batch 6900 to 7000\n",
      "✅ Uploaded batch 7000 to 7100\n",
      "✅ Uploaded batch 7100 to 7200\n",
      "✅ Uploaded batch 7200 to 7300\n",
      "✅ Uploaded batch 7300 to 7400\n",
      "✅ Uploaded batch 7400 to 7500\n",
      "✅ Uploaded batch 7500 to 7600\n",
      "✅ Uploaded batch 7600 to 7700\n",
      "✅ Uploaded batch 7700 to 7800\n",
      "✅ Uploaded batch 7800 to 7900\n",
      "✅ Uploaded batch 7900 to 8000\n",
      "✅ Uploaded batch 8000 to 8100\n",
      "✅ Uploaded batch 8100 to 8200\n",
      "✅ Uploaded batch 8200 to 8300\n",
      "✅ Uploaded batch 8300 to 8400\n",
      "✅ Uploaded batch 8400 to 8500\n",
      "✅ Uploaded batch 8500 to 8600\n",
      "✅ Uploaded batch 8600 to 8700\n",
      "✅ Uploaded batch 8700 to 8800\n",
      "✅ Uploaded batch 8800 to 8900\n",
      "✅ Uploaded batch 8900 to 9000\n",
      "✅ Uploaded batch 9000 to 9100\n",
      "✅ Uploaded batch 9100 to 9200\n",
      "✅ Uploaded batch 9200 to 9300\n",
      "✅ Uploaded batch 9300 to 9400\n",
      "✅ Uploaded batch 9400 to 9500\n",
      "✅ Uploaded batch 9500 to 9600\n",
      "✅ Uploaded batch 9600 to 9700\n",
      "✅ Uploaded batch 9700 to 9800\n",
      "✅ Uploaded batch 9800 to 9900\n",
      "✅ Uploaded batch 9900 to 10000\n",
      "✅ Uploaded batch 10000 to 10100\n",
      "✅ Uploaded batch 10100 to 10200\n",
      "✅ Uploaded batch 10200 to 10300\n",
      "✅ Uploaded batch 10300 to 10400\n",
      "✅ Uploaded batch 10400 to 10500\n",
      "✅ Uploaded batch 10500 to 10600\n",
      "✅ Uploaded batch 10600 to 10700\n",
      "✅ Uploaded batch 10700 to 10800\n",
      "✅ Uploaded batch 10800 to 10900\n",
      "✅ Uploaded batch 10900 to 11000\n",
      "✅ Uploaded batch 11000 to 11100\n",
      "✅ Uploaded batch 11100 to 11200\n",
      "✅ Uploaded batch 11200 to 11300\n",
      "✅ Uploaded batch 11300 to 11400\n",
      "✅ Uploaded batch 11400 to 11500\n",
      "✅ Uploaded batch 11500 to 11600\n",
      "✅ Uploaded batch 11600 to 11630\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 100  # you can tweak this\n",
    "\n",
    "for i in range(0, len(points_to_upsert), BATCH_SIZE):\n",
    "    batch = points_to_upsert[i:i + BATCH_SIZE]\n",
    "    client.upsert(\n",
    "        collection_name=collection_name,\n",
    "        points=batch\n",
    "    )\n",
    "    print(f\"✅ Uploaded batch {i} to {i + len(batch)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_query_with_neo4j(user_query):\n",
    "    \"\"\"\n",
    "    Naive approach: split user query into tokens \n",
    "    and gather related keywords from Neo4j.\n",
    "    \"\"\"\n",
    "    tokens = user_query.lower().split()\n",
    "    all_expanded = set()\n",
    "    for token in tokens:\n",
    "        expansions = get_related_keywords(token)\n",
    "        all_expanded.update(expansions)\n",
    "    return list(all_expanded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_relevant_chunks(user_query, expansions, top_k=5):\n",
    "    \"\"\"\n",
    "    - Combine the user query with expansions\n",
    "    - Embed once\n",
    "    - Query Qdrant for the top_k most similar chunks\n",
    "    \"\"\"\n",
    "    if expansions:\n",
    "        expansion_text = \" \".join(expansions)\n",
    "        augmented_text = user_query + \" \" + expansion_text\n",
    "    else:\n",
    "        augmented_text = user_query\n",
    "    \n",
    "    query_vector = model.encode(augmented_text)\n",
    "\n",
    "    # Qdrant query\n",
    "    results = client.query_points(\n",
    "        collection_name=collection_name,\n",
    "        query=query_vector.tolist(),\n",
    "        limit=top_k\n",
    "    )\n",
    "    \n",
    "    # 'results' will be a list of ScoredPoint objects\n",
    "    # Each contains 'payload' (with our stored chunk)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_query(user_query, top_k=5):\n",
    "    # 1) Expand user query with Neo4j\n",
    "    expansions = expand_query_with_neo4j(user_query)\n",
    "    # 2) Retrieve relevant chunks from Qdrant\n",
    "    docs = retrieve_relevant_chunks(user_query, expansions, top_k=top_k)\n",
    "    context_text = \"\"\n",
    "    for doc in docs:\n",
    "        payload = doc[1][0].payload\n",
    "        context_text += f\"Fichier: {payload['file']}\\nChunk: {payload['chunk']}\\n\\n\"\n",
    "    full_prompt = f\"\"\"\n",
    "    CONTEXTE:\n",
    "    {context_text}\n",
    "\n",
    "    QUESTION UTILISATEUR:\n",
    "    {user_query}\n",
    "\n",
    "    RÉPONSE ATTENDUE (en utilisant uniquement les informations ci-dessus) :\n",
    "    \"\"\"\n",
    "    return full_prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ventilation', 'Chauffage', 'Isolation thermique', \"Membrane d'étanchéité\", 'Chauffe-eau thermodynamique', 'RE2020', 'VMC double flux', 'Pompe à chaleur', 'Plancher chauffant', 'Énergie renouvelable']\n"
     ]
    }
   ],
   "source": [
    "query = \"Quels sont les avantages d’utiliser une pompe à chaleur avec un plancher chauffant ?\"\n",
    "query = expand_query(query, top_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def query_ollama(prompt, model=\"llama3.2\"):\n",
    "    response = requests.post(\n",
    "        \"http://localhost:11434/api/generate\",\n",
    "        json={\n",
    "            \"model\": model,\n",
    "            \"prompt\": prompt,\n",
    "            \"stream\": False  # you can use True if you want streamed responses\n",
    "        }\n",
    "    )\n",
    "    data = response.json()\n",
    "    return data[\"response\"]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les avantages de l'utilisation d'une pompe à chaleur avec un plancher chauffant sont :\n",
      "\n",
      "1. Chauffage thermodynamique basse température : Cette technologie permet un chauffage efficace et respectueux de l'environnement, en utilisant les énergies renouvelables pour chauffer le plancher.\n",
      "2. Suppression du bouclage ECS (Équilibreur de Charge Solaire) : En utilisant une pompe à chaleur avec un plancher chauffant, il n'est pas nécessaire d'installer un système de bouclage ECS, ce qui réduit les coûts et l'importance des déchets thermiques.\n",
      "3. Économie d'énergie : Le chauffage basse température peut réduire la consommation d'énergie pour chauffer le plancher, ce qui peut entraîner une réduction des factures de gaz ou d'électricité.\n",
      "4. Sécurité et confort : L'utilisation d'une pompe à chaleur avec un plancher chauffant peut améliorer la sécurité et le confort dans les bâtiments, en particulier pour les personnes âgées ou handicapées.\n",
      "5. Double ou triple service : Cette technologie permet de fournir plusieurs services (chauffage, éclairage et climatisation) à partir d'un même système, ce qui peut réduire la complexité du système et améliorer l'efficacité énergétique.\n",
      "\n",
      "Il est important de noter que ces avantages sont étayés par les informations fournies dans le fichier \"La Pompe à chaleur, des solutions disponibles en habitat collectif.md\".\n"
     ]
    }
   ],
   "source": [
    "\n",
    "result = query_ollama(query)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
