{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importation des bibliothèques nécessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation du module 'driver' de la bibliothèque lib2to3.pgen2 (lib2to3 est un module utilisé pour automatiser la conversion de code source Python 2 vers Python 3)\n",
    "from lib2to3.pgen2 import driver\n",
    "\n",
    "# Importation de la bibliothèque Selenium pour le contrôle automatisé des navigateurs web\n",
    "from selenium import webdriver\n",
    "\n",
    "# Importation du module 'By' de Selenium pour sélectionner les éléments du DOM par divers attributs (id, name, class, etc.)\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# Importation de 'WebDriverWait' de Selenium pour spécifier le délai d'attente pour trouver un élément sur une page\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "\n",
    "# Importation de 'expected_conditions' de Selenium pour définir des conditions sur les éléments (comme être cliquable, visible, etc.)\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# Importation de l'exception TimeoutException de Selenium pour gérer les erreurs de dépassement de temps\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "\n",
    "# Importation de la bibliothèque BeautifulSoup pour analyser (parser) le HTML et extraire des données du contenu web\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "# Importation de la bibliothèque requests pour envoyer des requêtes HTTP (GET, POST, etc.)\n",
    "import requests\n",
    "\n",
    "# Importation de la bibliothèque os pour interagir avec le système d'exploitation (création de dossiers, manipulation de fichiers, etc.)\n",
    "import os\n",
    "\n",
    "# Importation de la classe Workbook de la bibliothèque openpyxl pour créer et manipuler des fichiers Excel\n",
    "from openpyxl import Workbook\n",
    "\n",
    "# Importation de la bibliothèque time pour manipuler les fonctions temporelles (temporisation, mesure du temps, etc.)\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Configuration et initialisation du navigateur :\n",
    "\n",
    "Cette section de code configure et initialise un navigateur web automatisé (Chrome) en utilisant la bibliothèque **Selenium**. L'objectif est de gérer les notifications et les pop-ups indésirables qui peuvent perturber le bon déroulement d'un processus automatisé. Ce script inclut également l'initialisation d'une liste pour stocker les liens trouvés lors de la navigation sur les pages web.\n",
    "\n",
    "- **Objectif** : Configurer un navigateur Chrome automatisé avec des préférences spécifiques pour désactiver les notifications et préparer un espace de stockage pour les liens collectés.\n",
    "- **Contexte** : Utilisé pour l'automatisation de tâches de scraping ou de tests automatisés où l'interaction avec des pop-ups peut perturber le déroulement du script.\n",
    "\n",
    "- **Approche** :\n",
    "  1. Définir les options de Chrome, incluant la désactivation des notifications.\n",
    "  2. Appliquer ces options au navigateur automatisé.\n",
    "  3. Initialiser le navigateur avec ces configurations.\n",
    "  4. Créer une liste pour stocker tous les liens extraits des pages web.\n",
    "\n",
    "- **Avantages** :\n",
    "  - Assure que les interruptions de notifications ne bloquent pas le script.\n",
    "  - Facilite la gestion des informations extraites en utilisant une structure de liste.\n",
    "\n",
    "#### Prérequis :\n",
    "- La bibliothèque `selenium` doit être installée (`pip install selenium`).\n",
    "- Le `webdriver` de Chrome doit être configuré (téléchargement du `chromedriver`).\n",
    "- Le module `chromedriver` doit être accessible dans le PATH du système ou le chemin d'accès doit être spécifié.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Options du navigateur pour gérer les pop-ups et désactiver les notifications indésirables.\n",
    "options = webdriver.ChromeOptions()  # Créer un objet d'options pour le navigateur Chrome.\n",
    "\n",
    "# Préférences définies pour désactiver les notifications (valeur 2 désactive les notifications de manière globale).\n",
    "prefs = {\"profile.default_content_setting_values.notifications\": 2}\n",
    "\n",
    "# Ajouter ces préférences spécifiques dans la configuration du navigateur via les options.\n",
    "options.add_experimental_option(\"prefs\", prefs)\n",
    "\n",
    "# Initialisation du navigateur Chrome avec les options configurées.\n",
    "driver = webdriver.Chrome(options=options)\n",
    "\n",
    "# Création d'une liste vide pour stocker tous les liens collectés lors de la navigation sur les pages web.\n",
    "links_list = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Création de dossiers :\n",
    "\n",
    "Ce segment de code crée des dossiers spécifiques pour organiser les fichiers téléchargés et générés par le script, en utilisant la bibliothèque **os** pour interagir avec le système de fichiers. Les dossiers sont créés pour stocker les images, les fichiers PDF, ainsi que les fichiers Excel générés lors du traitement des données.\n",
    "\n",
    "- **Objectif** : Créer et organiser des répertoires pour stocker les différentes catégories de fichiers, tels que les images, les PDF et les fichiers Excel.\n",
    "- **Contexte** : Utilisé dans des scripts de scraping ou de génération de rapports pour centraliser les résultats de manière ordonnée dans des répertoires dédiés.\n",
    "  \n",
    "- **Approche** :\n",
    "  1. Définir le nom des dossiers pour chaque type de fichier.\n",
    "  2. Vérifier si les dossiers existent déjà, sinon les créer automatiquement.\n",
    "  3. Créer des répertoires distincts pour séparer chaque type de fichier afin de faciliter leur organisation.\n",
    "\n",
    "- **Avantages** :\n",
    "  - Assure que les fichiers sont organisés de manière cohérente.\n",
    "  - Prévient les erreurs en créant automatiquement les répertoires s'ils n'existent pas.\n",
    "  \n",
    "#### Prérequis :\n",
    "- La bibliothèque `os` doit être disponible (standard en Python).\n",
    "- Les chemins d'accès spécifiés doivent avoir les permissions de création de dossiers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Dossier où enregistrer les images téléchargées\n",
    "download_folder = 'Images'  # Nom du dossier pour les fichiers image.\n",
    "os.makedirs(download_folder, exist_ok=True)  # Crée le dossier 'Images' s'il n'existe pas déjà.\n",
    "\n",
    "# Dossier où enregistrer les fichiers PDF téléchargés\n",
    "pdf_folder = 'PDFs'  # Nom du dossier pour les fichiers PDF.\n",
    "os.makedirs(pdf_folder, exist_ok=True)  # Crée le dossier 'PDFs' s'il n'existe pas déjà.\n",
    "\n",
    "# Dossier où enregistrer le fichier Excel\n",
    "excel_folder = 'Fichiers_Excel'  # Nom du dossier pour les fichiers Excel.\n",
    "os.makedirs(excel_folder, exist_ok=True)  # Crée le dossier 'Fichiers_Excel' s'il n'existe pas déjà.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Création du fichier excel :\n",
    "\n",
    "Ce segment de code initialise un nouveau classeur Excel en utilisant la bibliothèque **openpyxl** et crée une feuille de calcul intitulée *'Informations générales'*. Un ensemble d'en-têtes de colonnes est défini pour structurer les informations qui seront enregistrées dans cette feuille de calcul. Ce type de configuration est particulièrement utile pour centraliser et organiser les données extraites ou générées par le script sous forme de tableau dans un fichier Excel.\n",
    "\n",
    "- **Objectif** : Créer un fichier Excel avec une feuille de calcul nommée, et définir des en-têtes de colonnes pour structurer les données.\n",
    "- **Contexte** : Utilisé dans des contextes où il est nécessaire de sauvegarder des informations textuelles ou chiffrées dans un format tabulaire pour une analyse ou un traitement ultérieur.\n",
    "  \n",
    "- **Approche** :\n",
    "  1. Créer un nouveau classeur Excel.\n",
    "  2. Définir la feuille de calcul principale avec un titre explicite.\n",
    "  3. Ajouter des en-têtes de colonnes correspondant aux catégories de données qui seront insérées dans le tableau.\n",
    "\n",
    "- **Avantages** :\n",
    "  - Facilite la centralisation des informations dans un format Excel compatible avec la plupart des outils de traitement de données.\n",
    "  - Simplifie l'accès, la visualisation et l'analyse des données structurées.\n",
    "  \n",
    "#### Prérequis :\n",
    "- La bibliothèque `openpyxl` doit être installée (`pip install openpyxl`).\n",
    "- Aucune configuration supplémentaire n'est nécessaire pour créer le fichier Excel localement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Créer un nouveau classeur Excel\n",
    "wb = Workbook()  # Initialise un nouveau classeur Excel vide.\n",
    "\n",
    "# Sélectionner la première feuille active et la nommer 'Informations générales'\n",
    "ws_general = wb.active  # Accéder à la feuille par défaut (première feuille).\n",
    "ws_general.title = 'Informations générales'  # Renommer la feuille avec un titre explicite.\n",
    "\n",
    "# Définir les en-têtes de colonnes pour structurer les informations\n",
    "headers = [\n",
    "    'Titre', 'A retenir', 'Sommaire', 'Texte', 'Source', 'Catégorie', \n",
    "    'Thématique', 'Nb_consultation', 'Nb_evaluation_positive', 'Lien', \n",
    "    'Lien_video', 'Titre_video', 'Nom_chaine', 'Likes', 'Vues', \n",
    "    'Date_publication', 'Description', 'Nombre_de_commentaires'\n",
    "]  # Liste des en-têtes pour organiser les colonnes de la feuille Excel.\n",
    "\n",
    "# Ajouter la ligne d'en-têtes dans la feuille de calcul\n",
    "ws_general.append(headers)  # Insère les en-têtes dans la première ligne de la feuille 'Informations générales'.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Création de fichier unique :\n",
    "\n",
    "Cette fonction `get_unique_filename` est conçue pour générer automatiquement un nom de fichier unique dans un répertoire donné si un fichier avec le même nom existe déjà. Cela permet d'éviter les conflits de noms lors de l'enregistrement de fichiers dans un dossier. La fonction prend en compte le nom de fichier souhaité et ajoute un suffixe numérique pour différencier les versions, garantissant ainsi que chaque fichier enregistré dans le répertoire a un nom unique.\n",
    "\n",
    "- **Objectif** : Éviter l'écrasement des fichiers en créant automatiquement des noms uniques pour les nouveaux fichiers dans un répertoire spécifique.\n",
    "- **Contexte** : Utilisé dans des scripts de téléchargement ou de manipulation de fichiers où plusieurs fichiers peuvent avoir le même nom (ex. : téléchargement d'images ou de documents similaires).\n",
    "  \n",
    "- **Approche** :\n",
    "  1. Extraire le nom de base et l'extension du fichier.\n",
    "  2. Initialiser un compteur pour générer un suffixe unique.\n",
    "  3. Vérifier si le fichier avec le nom spécifié existe déjà dans le dossier.\n",
    "  4. Si le fichier existe, incrémenter le compteur et générer un nouveau nom jusqu'à ce qu'un nom unique soit trouvé.\n",
    "  5. Retourner le nom de fichier unique.\n",
    "\n",
    "- **Avantages** :\n",
    "  - Prévient l'écrasement accidentel de fichiers existants.\n",
    "  - Permet de gérer automatiquement la duplication de fichiers sans intervention manuelle.\n",
    "  \n",
    "#### Prérequis :\n",
    "- Le module `os` doit être importé pour vérifier l'existence de fichiers et manipuler les chemins d'accès (`os.path`).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Fonction pour générer un nom de fichier unique si un fichier existe déjà\n",
    "def get_unique_filename(folder, filename):\n",
    "    # Séparer le nom de base et l'extension du fichier (par exemple, 'document' et '.pdf')\n",
    "    base, extension = os.path.splitext(filename)  # Extraction de la base et de l'extension du fichier.\n",
    "\n",
    "    # Initialiser un compteur pour gérer les conflits de noms\n",
    "    counter = 1  # Compteur pour générer un suffixe unique (ex. : document_1.pdf).\n",
    "\n",
    "    # Initialiser le nouveau nom de fichier avec le nom d'origine\n",
    "    new_filename = filename  # Par défaut, utiliser le nom de fichier original.\n",
    "\n",
    "    # Tant qu'un fichier avec ce nom existe déjà dans le dossier, générer un nouveau nom\n",
    "    while os.path.exists(os.path.join(folder, new_filename)):\n",
    "        # Générer un nouveau nom de fichier en ajoutant le compteur (ex. : document_1.pdf, document_2.pdf, etc.)\n",
    "        new_filename = f\"{base}_{counter}{extension}\"  # Ajouter le suffixe basé sur le compteur.\n",
    "\n",
    "        # Incrémenter le compteur pour le prochain essai\n",
    "        counter += 1  # Incrémenter le compteur pour les nouvelles tentatives.\n",
    "\n",
    "    # Retourner le nom de fichier unique\n",
    "    return new_filename  # Renvoie le nom de fichier final qui n'existe pas dans le dossier.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Téléchargement d'images :\n",
    "\n",
    "La fonction `download_image` télécharge une image à partir d'une URL donnée, enregistre l'image localement avec un nom de fichier unique, et affiche un message de confirmation ou d'erreur en fonction du résultat. Cette fonction utilise la bibliothèque `requests` pour envoyer une requête HTTP et obtenir le contenu de l'image, puis enregistre le fichier dans le répertoire spécifié après avoir vérifié l'unicité de son nom.\n",
    "\n",
    "- **Objectif** : Télécharger des images depuis des URLs tout en évitant les conflits de noms de fichiers dans le répertoire de destination.\n",
    "- **Contexte** : Utilisé pour automatiser le téléchargement d'images depuis le web (scraping d'images, récupération de contenu multimédia, etc.), où plusieurs images peuvent avoir le même nom.\n",
    "  \n",
    "- **Approche** :\n",
    "  1. Vérifier et générer un nom de fichier unique en utilisant la fonction `get_unique_filename`.\n",
    "  2. Envoyer une requête HTTP à l'URL de l'image pour récupérer son contenu.\n",
    "  3. Vérifier si la requête a réussi (code de statut HTTP 200).\n",
    "  4. Enregistrer le contenu de l'image dans un fichier local en mode binaire.\n",
    "  5. Afficher un message de succès ou d'échec selon le résultat de l'opération.\n",
    "\n",
    "- **Avantages** :\n",
    "  - Gère automatiquement les conflits de noms en créant des versions uniques.\n",
    "  - Permet de traiter et de sauvegarder rapidement des images à partir de différentes sources.\n",
    "  \n",
    "#### Prérequis :\n",
    "- Le module `requests` doit être installé (`pip install requests`).\n",
    "- Le module `os` doit être importé pour gérer les chemins de fichiers.\n",
    "- La fonction `get_unique_filename` doit être définie pour générer des noms uniques.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Fonction pour télécharger une image à partir d'une URL donnée et l'enregistrer localement avec un nom de fichier unique.\n",
    "def download_image(url, filename):\n",
    "    try:\n",
    "        # Vérifier l'unicité du nom de fichier et générer un nouveau nom si nécessaire\n",
    "        filename = get_unique_filename(download_folder, filename)  # Utiliser un nom de fichier unique pour éviter les conflits.\n",
    "\n",
    "        # Envoyer une requête HTTP pour récupérer le contenu de l'image\n",
    "        response = requests.get(url)  # Récupérer l'image depuis l'URL spécifiée.\n",
    "\n",
    "        # Vérifier si la requête a réussi (code 200 indique un succès)\n",
    "        if response.status_code == 200:\n",
    "            # Construire le chemin complet pour l'enregistrement de l'image\n",
    "            full_path = os.path.join(download_folder, filename)  # Définir le chemin complet du fichier image.\n",
    "\n",
    "            # Ouvrir un nouveau fichier en mode binaire pour écrire le contenu de l'image\n",
    "            with open(full_path, 'wb') as f:\n",
    "                f.write(response.content)  # Enregistrer le contenu de l'image dans le fichier.\n",
    "\n",
    "            # Afficher un message de succès indiquant le chemin du fichier téléchargé\n",
    "            print(f\"Téléchargement réussi : {full_path}\")  # Confirmation de téléchargement réussi.\n",
    "\n",
    "        else:\n",
    "            # Afficher un message d'erreur si la requête a échoué\n",
    "            print(f\"Échec du téléchargement : {filename}\")  # Erreur si le statut de la requête n'est pas 200.\n",
    "\n",
    "    except Exception as e:\n",
    "        # Capturer et afficher toute exception rencontrée lors du téléchargement\n",
    "        print(f\"Erreur lors du téléchargement de l'image {filename} : {str(e)}\")  # Afficher l'erreur en cas de problème.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Téléchéchargement de pdf :\n",
    "\n",
    "La fonction `download_pdf` télécharge un fichier PDF à partir d'une URL fournie, l'enregistre localement dans un répertoire dédié, et gère les conflits de noms en générant automatiquement un nom de fichier unique. La fonction utilise `requests` pour effectuer la requête HTTP et obtenir le contenu du PDF, puis enregistre le fichier localement en mode binaire. Elle inclut également une gestion des erreurs pour identifier les problèmes de téléchargement et informer l'utilisateur.\n",
    "\n",
    "- **Objectif** : Télécharger des fichiers PDF depuis une URL et les enregistrer dans un dossier local tout en gérant les conflits de noms de fichiers.\n",
    "- **Contexte** : Utilisé pour automatiser le téléchargement de documents PDF dans des scripts de scraping ou de collecte d'informations, lorsque plusieurs fichiers peuvent avoir des noms similaires.\n",
    "  \n",
    "- **Approche** :\n",
    "  1. Vérifier et générer un nom de fichier unique en utilisant la fonction `get_unique_filename`.\n",
    "  2. Envoyer une requête HTTP à l'URL spécifiée pour récupérer le contenu du PDF.\n",
    "  3. Vérifier si la requête a réussi (code de statut HTTP 200).\n",
    "  4. Enregistrer le contenu du PDF dans un fichier local en mode binaire.\n",
    "  5. Afficher un message de succès ou d'échec selon le résultat de l'opération.\n",
    "\n",
    "- **Avantages** :\n",
    "  - Gère automatiquement les conflits de noms de fichiers pour éviter l'écrasement accidentel.\n",
    "  - Prend en charge les erreurs de téléchargement et permet de diagnostiquer facilement les problèmes.\n",
    "  \n",
    "#### Prérequis :\n",
    "- Le module `requests` doit être installé (`pip install requests`).\n",
    "- Le module `os` doit être importé pour gérer les chemins de fichiers.\n",
    "- La fonction `get_unique_filename` doit être définie pour générer des noms uniques.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Fonction pour télécharger un fichier PDF depuis une URL et l'enregistrer localement avec un nom de fichier unique.\n",
    "def download_pdf(url, filename):\n",
    "    try:\n",
    "        # Vérifier l'unicité du nom de fichier et générer un nouveau nom si nécessaire\n",
    "        filename = get_unique_filename(pdf_folder, filename)  # Utiliser un nom de fichier unique pour éviter les conflits.\n",
    "\n",
    "        # Envoyer une requête HTTP pour récupérer le contenu du PDF\n",
    "        response = requests.get(url)  # Récupérer le fichier PDF depuis l'URL spécifiée.\n",
    "\n",
    "        # Vérifier si la requête a réussi (code 200 indique un succès)\n",
    "        if response.status_code == 200:\n",
    "            # Construire le chemin complet pour l'enregistrement du PDF\n",
    "            full_path = os.path.join(pdf_folder, filename)  # Définir le chemin complet du fichier PDF.\n",
    "\n",
    "            # Ouvrir un nouveau fichier en mode binaire pour écrire le contenu du PDF\n",
    "            with open(full_path, 'wb') as f:\n",
    "                f.write(response.content)  # Enregistrer le contenu du PDF dans le fichier.\n",
    "\n",
    "            # Afficher un message de succès indiquant le chemin du fichier téléchargé\n",
    "            print(f\"Téléchargement réussi : {full_path}\")  # Confirmation de téléchargement réussi.\n",
    "\n",
    "        else:\n",
    "            # Afficher un message d'erreur si la requête a échoué\n",
    "            print(f\"Échec du téléchargement : {filename}\")  # Erreur si le statut de la requête n'est pas 200.\n",
    "\n",
    "    except Exception as e:\n",
    "        # Capturer et afficher toute exception rencontrée lors du téléchargement\n",
    "        print(f\"Erreur lors du téléchargement du PDF {filename} : {str(e)}\")  # Afficher l'erreur en cas de problème.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Exportation des données dans un fichier excel :\n",
    "\n",
    "La fonction `export_to_excel` prend une liste de données et l'exporte dans un fichier Excel préconfiguré. Elle parcourt chaque ligne de la liste fournie et l'ajoute à une feuille de calcul existante. Ensuite, la fonction sauvegarde le classeur dans un dossier dédié sous un nom de fichier spécifique. En cas d'erreur, un message est affiché pour indiquer le problème. Cette méthode est utile pour centraliser les informations collectées sous un format tabulaire, compatible avec les outils d'analyse et de visualisation de données.\n",
    "\n",
    "- **Objectif** : Exporter les données collectées vers un fichier Excel tout en gérant les erreurs potentielles.\n",
    "- **Contexte** : Utilisé lorsque l'on souhaite stocker et structurer des données sous un format Excel lisible pour des rapports ou des analyses.\n",
    "  \n",
    "- **Approche** :\n",
    "  1. Parcourir les données ligne par ligne et les ajouter dans la feuille Excel `ws_general`.\n",
    "  2. Spécifier le chemin complet du fichier Excel et le nommer `data_Tp_demain.xlsx`.\n",
    "  3. Sauvegarder le fichier dans le répertoire désigné (`excel_folder`).\n",
    "  4. Afficher un message de confirmation si l'exportation réussit, sinon afficher le message d'erreur.\n",
    "\n",
    "- **Avantages** :\n",
    "  - Simplifie l'exportation de grandes quantités de données sous un format Excel lisible.\n",
    "  - Permet de centraliser les informations collectées pour une utilisation future.\n",
    "  \n",
    "#### Prérequis :\n",
    "- Le module `openpyxl` doit être installé pour créer et manipuler des fichiers Excel.\n",
    "- La variable globale `ws_general` doit faire référence à une feuille de calcul valide.\n",
    "- Le dossier `excel_folder` doit exister pour y stocker le fichier Excel.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Fonction pour exporter une liste de données vers un fichier Excel dans le dossier spécifié.\n",
    "def export_to_excel(data):\n",
    "    try:\n",
    "        # Parcourir chaque ligne de la liste de données et l'ajouter dans la feuille Excel 'ws_general'\n",
    "        for line in data:\n",
    "            ws_general.append(line)  # Ajouter chaque ligne dans la feuille Excel.\n",
    "\n",
    "        # Spécifier le chemin complet pour enregistrer le fichier Excel avec un nom spécifique\n",
    "        excel_filename = os.path.join(excel_folder, 'data_Tp_demain.xlsx')  # Définir le chemin du fichier Excel.\n",
    "\n",
    "        # Sauvegarder le classeur Excel dans le dossier 'Fichiers_Excel'\n",
    "        wb.save(excel_filename)  # Enregistrer le fichier Excel avec toutes les modifications.\n",
    "\n",
    "        # Afficher un message de confirmation lorsque l'exportation est réussie\n",
    "        print(f\"Données exportées avec succès vers : {excel_filename}\")  # Confirmation d'exportation réussie.\n",
    "\n",
    "    except Exception as e:\n",
    "        # Capturer et afficher toute exception rencontrée lors de l'exportation\n",
    "        print(f\"Une erreur est survenue lors de l'exportation vers Excel : {str(e)}\")  # Afficher l'erreur en cas de problème.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Défilement du pop-up :\n",
    "\n",
    "La fonction `scroll_in_video_popup` effectue un défilement vertical dans un pop-up vidéo à l'aide de la bibliothèque **Selenium**. Cette fonction est utile lorsqu'un contenu est chargé dynamiquement dans une boîte de dialogue (pop-up) et que l'accès à des éléments supplémentaires nécessite un défilement. Le script identifie le conteneur de ce pop-up en utilisant un sélecteur CSS spécifique, puis utilise du JavaScript pour simuler le défilement jusqu'en bas de cette boîte de dialogue.\n",
    "\n",
    "- **Objectif** : Dérouler le contenu d'un pop-up vidéo pour accéder à des éléments qui ne sont visibles qu'après un défilement.\n",
    "- **Contexte** : Utilisé dans des scénarios où l'on doit interagir avec des boîtes de dialogue vidéo dans des sites complexes comme YouTube, pour charger plus d'éléments ou d'informations (ex. : chargement des commentaires, détails supplémentaires, etc.).\n",
    "  \n",
    "- **Approche** :\n",
    "  1. Attendre que l'élément du conteneur de pop-up soit présent dans le DOM.\n",
    "  2. Utiliser un script JavaScript pour effectuer un défilement vers le bas de ce conteneur.\n",
    "  3. Afficher un message de confirmation en cas de succès.\n",
    "  4. Capturer et afficher toute exception rencontrée si le conteneur n'est pas trouvé ou si le défilement échoue.\n",
    "\n",
    "- **Avantages** :\n",
    "  - Permet de naviguer dans des éléments cachés de l'interface utilisateur sans intervention manuelle.\n",
    "  - Automatiser l'accès à du contenu visible uniquement après un défilement dans une boîte de dialogue.\n",
    "\n",
    "#### Prérequis :\n",
    "- Le module `selenium` doit être installé (`pip install selenium`).\n",
    "- Le `driver` Selenium doit être correctement initialisé avec une page contenant le pop-up cible.\n",
    "- La bibliothèque `WebDriverWait` et les conditions `EC` doivent être importées pour gérer les délais d'attente d'apparition des éléments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fonction pour effectuer un défilement (scroll) dans le pop-up d'une vidéo en utilisant Selenium.\n",
    "def scroll_in_video_popup():\n",
    "    try:\n",
    "        # Attendre que le conteneur du pop-up soit présent dans le DOM (jusqu'à 10 secondes d'attente)\n",
    "        popup_container = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, \"tp-yt-iron-overlay-backdrop\"))  # Sélectionner le conteneur par son sélecteur CSS.\n",
    "        )\n",
    "\n",
    "        # Utiliser JavaScript pour défiler jusqu'en bas de ce conteneur\n",
    "        driver.execute_script(\"arguments[0].scrollTop = arguments[0].scrollHeight;\", popup_container)  # Défilement jusqu'en bas de la boîte de dialogue.\n",
    "\n",
    "        # Afficher un message de confirmation si le défilement s'est bien effectué\n",
    "        print(\"Scroll dans le pop-up des vidéos effectué.\")  # Confirmation de réussite.\n",
    "\n",
    "    except Exception as e:\n",
    "        # Capturer et afficher toute exception rencontrée lors du défilement\n",
    "        print(f\"Erreur lors du scroll dans le pop-up des vidéos : {str(e)}\")  # Afficher l'erreur en cas de problème.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Refus automatique des cookies :\n",
    "\n",
    "La fonction `refuse_video_cookies` est conçue pour refuser automatiquement les cookies dans les pop-ups vidéo qui apparaissent sur certains sites, tels que YouTube. Elle utilise la fonction `scroll_in_video_popup` pour s'assurer que le bouton de refus des cookies est visible, puis elle interagit avec ce bouton en simulant un clic. Cela permet d'éviter toute interaction manuelle avec ces fenêtres intrusives et d'améliorer le flux de navigation automatisé.\n",
    "\n",
    "- **Objectif** : Refuser automatiquement les cookies dans les pop-ups vidéo afin d'éviter les interruptions pendant le scraping ou la navigation automatisée.\n",
    "- **Contexte** : Utilisé dans des scripts Selenium lorsqu'un site affiche une fenêtre de consentement aux cookies avant d'afficher le contenu principal de la vidéo.\n",
    "  \n",
    "- **Approche** :\n",
    "  1. Utiliser la fonction `scroll_in_video_popup` pour défiler vers le bas du conteneur de la vidéo.\n",
    "  2. Ajouter une pause de 2 secondes pour laisser le temps au bouton de refus de se charger.\n",
    "  3. Identifier le bouton \"Tout refuser\" en utilisant un sélecteur XPath et vérifier s'il est cliquable.\n",
    "  4. Effectuer un clic sur le bouton \"Tout refuser\" pour rejeter les cookies.\n",
    "  5. Gérer les erreurs de type `TimeoutException` si le bouton n'est pas trouvé.\n",
    "  6. Capturer et afficher toute autre exception rencontrée.\n",
    "\n",
    "- **Avantages** :\n",
    "  - Évite les interruptions de navigation causées par les pop-ups de consentement.\n",
    "  - Automatisation robuste en utilisant des conditions d'attente pour s'assurer que le bouton est visible et cliquable.\n",
    "\n",
    "#### Prérequis :\n",
    "- Le module `selenium` doit être installé (`pip install selenium`).\n",
    "- Le `driver` Selenium doit être correctement initialisé avec une page contenant le pop-up vidéo.\n",
    "- Les fonctions `scroll_in_video_popup` et les bibliothèques de gestion d'attente (`WebDriverWait`, `EC`) doivent être importées.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fonction pour refuser automatiquement les cookies dans le pop-up d'une vidéo.\n",
    "def refuse_video_cookies():\n",
    "    try:\n",
    "        # Effectuer un défilement dans le pop-up vidéo pour rendre le bouton de refus visible\n",
    "        scroll_in_video_popup()  # Appeler la fonction de défilement pour s'assurer que le contenu est bien visible.\n",
    "\n",
    "        # Ajouter une pause de 2 secondes pour s'assurer que tous les éléments sont chargés\n",
    "        time.sleep(2)  # Pause pour laisser le temps au bouton de refus de s'afficher.\n",
    "\n",
    "        # Attendre que le bouton \"Tout refuser\" soit cliquable (jusqu'à 5 secondes d'attente)\n",
    "        refuse_button = WebDriverWait(driver, 5).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, \"//button//span[text()='Tout refuser']\"))  # Rechercher le bouton de refus par son XPath.\n",
    "        )\n",
    "\n",
    "        # Simuler un clic sur le bouton \"Tout refuser\" pour rejeter les cookies\n",
    "        driver.execute_script(\"arguments[0].click();\", refuse_button)  # Clic sur le bouton via un script JavaScript.\n",
    "\n",
    "        # Afficher un message de confirmation lorsque le clic est réussi\n",
    "        print(\"Cookies des vidéos refusés avec succès.\")  # Confirmation de réussite.\n",
    "\n",
    "    except TimeoutException:\n",
    "        # Gérer le cas où le bouton n'est pas trouvé dans le temps imparti\n",
    "        print(\"Aucun bouton de cookies trouvé dans la vidéo, passage à l'étape suivante.\")  # Indiquer que le bouton de refus n'est pas présent.\n",
    "\n",
    "    except Exception as e:\n",
    "        # Capturer et afficher toute autre exception rencontrée lors de l'exécution\n",
    "        print(f\"Erreur lors du clic sur 'Tout refuser' dans les vidéos : {str(e)}\")  # Afficher l'erreur en cas de problème.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Afficher la description complète :\n",
    "\n",
    "La fonction `click_show_more_button` simule un clic sur le bouton \"Afficher plus\" d'une vidéo YouTube pour étendre la description complète de celle-ci. Cette action est essentielle lorsque des informations supplémentaires (telles que des liens, des détails ou des descriptions complètes) sont masquées par défaut sous le bouton \"Afficher plus\". La fonction utilise Selenium pour rechercher le bouton à l'aide d'un sélecteur XPath, vérifie que le bouton est cliquable, puis effectue l'action de clic.\n",
    "\n",
    "- **Objectif** : Cliquer sur le bouton \"Afficher plus\" afin de révéler la description complète sous une vidéo YouTube.\n",
    "- **Contexte** : Utilisé dans des scripts de scraping où des informations textuelles sont cachées sous des sections repliées et nécessitent un clic pour être affichées.\n",
    "  \n",
    "- **Approche** :\n",
    "  1. Attendre que le bouton \"Afficher plus\" soit présent et cliquable.\n",
    "  2. Utiliser un sélecteur XPath spécifique pour identifier le bouton dans le DOM.\n",
    "  3. Simuler un clic sur le bouton à l'aide d'un script JavaScript.\n",
    "  4. Afficher un message de confirmation si le clic réussit.\n",
    "  5. Gérer les erreurs de type `TimeoutException` si le bouton n'est pas trouvé.\n",
    "  6. Capturer et afficher toute autre exception rencontrée.\n",
    "\n",
    "- **Avantages** :\n",
    "  - Permet d'accéder à des informations masquées qui ne sont pas visibles par défaut.\n",
    "  - Améliore la robustesse du script en gérant les délais d'affichage des éléments dynamiques.\n",
    "\n",
    "#### Prérequis :\n",
    "- Le module `selenium` doit être installé (`pip install selenium`).\n",
    "- Le `driver` Selenium doit être correctement initialisé avec une page YouTube contenant le bouton cible.\n",
    "- Les bibliothèques de gestion d'attente (`WebDriverWait`, `EC`) doivent être importées.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Fonction pour cliquer sur le bouton \"Afficher plus\" afin de révéler la description complète de la vidéo.\n",
    "def click_show_more_button():\n",
    "    try:\n",
    "        # Attendre que le bouton \"Afficher plus\" soit cliquable (jusqu'à 15 secondes d'attente)\n",
    "        show_more_button = WebDriverWait(driver, 15).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, '/html/body/ytd-app/div[1]/ytd-page-manager/ytd-watch-flexy/div[5]/div[1]/div/div[2]/ytd-watch-metadata/div/div[4]/div[1]/div/ytd-text-inline-expander/tp-yt-paper-button[1]'))  # Sélectionner le bouton \"Afficher plus\" par son XPath.\n",
    "        )\n",
    "\n",
    "        # Simuler un clic sur le bouton pour dérouler la description complète\n",
    "        driver.execute_script(\"arguments[0].click();\", show_more_button)  # Utiliser un script JavaScript pour cliquer sur le bouton.\n",
    "\n",
    "        # Afficher un message de confirmation lorsque le clic est réussi\n",
    "        print(\"Le bouton 'Afficher plus' a été cliqué pour révéler la description complète.\")  # Confirmation de réussite.\n",
    "\n",
    "    except TimeoutException:\n",
    "        # Gérer le cas où le bouton n'est pas trouvé dans le temps imparti\n",
    "        print(\"Aucun bouton 'Afficher plus' trouvé.\")  # Indiquer que le bouton n'est pas présent.\n",
    "\n",
    "    except Exception as e:\n",
    "        # Capturer et afficher toute autre exception rencontrée lors de l'exécution\n",
    "        print(f\"Erreur lors du clic sur 'Afficher plus' : {str(e)}\")  # Afficher l'erreur en cas de problème.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Défilement de la page vers le bas :\n",
    "\n",
    "La fonction `scroll_to_bottom` fait défiler la page vers le bas jusqu'à ce qu'elle atteigne la fin. Cette technique est utile sur des sites web où le contenu se charge dynamiquement au fur et à mesure du défilement (ex. : pages infinies, sites de médias sociaux, ou résultats de recherche). La fonction utilise Selenium pour simuler un défilement vertical et vérifie si de nouveaux contenus ont été chargés en comparant la hauteur actuelle de la page avant et après le défilement.\n",
    "\n",
    "- **Objectif** : Effectuer un défilement complet jusqu'en bas d'une page pour charger tout le contenu dynamique.\n",
    "- **Contexte** : Utilisé pour automatiser le chargement de contenu sur des sites où des éléments supplémentaires sont chargés à la fin de chaque défilement.\n",
    "  \n",
    "- **Approche** :\n",
    "  1. Obtenir la hauteur actuelle de la page (`last_height`).\n",
    "  2. Effectuer un défilement jusqu'en bas de la page.\n",
    "  3. Ajouter une courte pause pour laisser le contenu se charger.\n",
    "  4. Comparer la nouvelle hauteur de la page (`new_height`) avec l'ancienne.\n",
    "  5. Répéter l'opération jusqu'à ce que la hauteur n'augmente plus (indiquant que la fin de la page est atteinte).\n",
    "  6. Quitter la boucle lorsque la page ne se charge plus.\n",
    "\n",
    "- **Avantages** :\n",
    "  - Permet de charger tout le contenu dynamique sur des pages infinies.\n",
    "  - Automatisation efficace pour les scénarios de scraping où il est nécessaire de parcourir tout le contenu.\n",
    "\n",
    "#### Prérequis :\n",
    "- Le module `selenium` doit être installé (`pip install selenium`).\n",
    "- Le `driver` Selenium doit être correctement initialisé avec une page web dynamique.\n",
    "- La bibliothèque `WebDriverWait` et les conditions `EC` doivent être importées pour gérer les délais de chargement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Fonction pour faire défiler la page jusqu'en bas pour charger tout le contenu dynamique.\n",
    "def scroll_to_bottom():\n",
    "    # Obtenir la hauteur actuelle de la page\n",
    "    last_height = driver.execute_script(\"return document.documentElement.scrollHeight\")  # Récupérer la hauteur de la page avant le défilement.\n",
    "\n",
    "    while True:\n",
    "        # Effectuer un défilement jusqu'en bas de la page\n",
    "        driver.execute_script(\"window.scrollTo(0, document.documentElement.scrollHeight);\")  # Faire défiler la page jusqu'à la nouvelle hauteur.\n",
    "\n",
    "        # Attendre brièvement pour permettre le chargement du contenu\n",
    "        WebDriverWait(driver, 2).until(\n",
    "            EC.presence_of_element_located((By.TAG_NAME, 'body'))  # Attendre la présence de l'élément 'body' après le défilement.\n",
    "        )\n",
    "\n",
    "        # Obtenir la nouvelle hauteur de la page après le défilement\n",
    "        new_height = driver.execute_script(\"return document.documentElement.scrollHeight\")  # Récupérer la nouvelle hauteur de la page.\n",
    "\n",
    "        # Si la nouvelle hauteur est égale à l'ancienne, cela signifie que la page est complètement chargée\n",
    "        if new_height == last_height:\n",
    "            break  # Sortir de la boucle si la hauteur n'augmente plus.\n",
    "\n",
    "        # Mettre à jour la dernière hauteur connue pour la prochaine comparaison\n",
    "        last_height = new_height  # Actualiser la dernière hauteur pour continuer le défilement.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Récupération des informations de la vidéo :\n",
    "\n",
    "La fonction `get_video_details` récupère les informations clés d'une vidéo YouTube telles que le titre, le nom de la chaîne, le nombre de vues, les likes, la date de publication, la description et le nombre de commentaires. Elle utilise Selenium pour automatiser la navigation sur la page de la vidéo, interagir avec les boutons de la page, et collecter les informations affichées. La fonction gère également les cookies, effectue un défilement vers le bas pour charger tout le contenu et gère les erreurs pour assurer la robustesse de l'extraction.\n",
    "\n",
    "- **Objectif** : Extraire les détails principaux d'une vidéo YouTube pour les stocker ou les analyser.\n",
    "- **Contexte** : Utilisé dans des scripts de scraping où les détails des vidéos doivent être collectés automatiquement à partir de YouTube.\n",
    "  \n",
    "- **Approche** :\n",
    "  1. Charger l'URL de la vidéo spécifiée.\n",
    "  2. Refuser les cookies si le pop-up apparaît.\n",
    "  3. Cliquer sur \"Afficher plus\" pour révéler la description complète.\n",
    "  4. Dérouler jusqu'en bas de la page pour charger tous les commentaires.\n",
    "  5. Extraire les détails de la vidéo (titre, chaîne, likes, vues, date de publication, description, nombre de commentaires).\n",
    "  6. Gérer les erreurs de chargement et renvoyer des valeurs par défaut si des informations sont manquantes.\n",
    "\n",
    "- **Avantages** :\n",
    "  - Automatisation complète de la collecte de détails pour une vidéo.\n",
    "  - Prend en charge les changements dynamiques de l'interface utilisateur avec des attentes conditionnelles (`WebDriverWait`).\n",
    "\n",
    "#### Prérequis :\n",
    "- Le module `selenium` doit être installé (`pip install selenium`).\n",
    "- Le `driver` Selenium doit être correctement initialisé avec une instance de navigateur.\n",
    "- Les fonctions `refuse_video_cookies`, `click_show_more_button` et `scroll_to_bottom` doivent être définies pour gérer les interactions de base.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Fonction pour extraire les informations principales d'une vidéo YouTube à partir de son URL.\n",
    "def get_video_details(video_url):\n",
    "    try:\n",
    "        # Charger la page de la vidéo YouTube\n",
    "        driver.get(video_url)  # Ouvrir la page de la vidéo YouTube avec l'URL fournie.\n",
    "        time.sleep(5)  # Pause pour laisser le temps à la page de se charger.\n",
    "\n",
    "        # Refuser les cookies si le pop-up est présent\n",
    "        try:\n",
    "            refuse_video_cookies()  # Appeler la fonction pour refuser les cookies.\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors du refus des cookies : {str(e)}\")  # Gérer toute erreur liée au refus des cookies.\n",
    "\n",
    "        # Cliquer sur le bouton \"Afficher plus\" pour révéler la description complète\n",
    "        try:\n",
    "            click_show_more_button()  # Appeler la fonction pour afficher la description complète de la vidéo.\n",
    "        except TimeoutException:\n",
    "            print(\"Le bouton 'Afficher plus' n'a pas été trouvé. Passer à la suite.\")  # Gérer le cas où le bouton n'est pas visible.\n",
    "\n",
    "        # Faire défiler jusqu'en bas pour charger tout le contenu (comme les commentaires)\n",
    "        scroll_to_bottom()  # Effectuer un défilement complet de la page pour charger tous les éléments dynamiques.\n",
    "\n",
    "        # Extraire le titre de la vidéo\n",
    "        try:\n",
    "            title = WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, \"h1.style-scope.ytd-watch-metadata\"))  # Rechercher le titre par son sélecteur CSS.\n",
    "            ).text\n",
    "        except TimeoutException:\n",
    "            title = 'Titre non disponible'  # Définir le titre comme non disponible si l'élément n'est pas trouvé.\n",
    "\n",
    "        # Extraire le nom de la chaîne\n",
    "        try:\n",
    "            channel_name = driver.find_element(By.CSS_SELECTOR, \"a.yt-simple-endpoint.style-scope.yt-formatted-string\").text  # Sélectionner le nom de la chaîne par son sélecteur CSS.\n",
    "        except Exception:\n",
    "            channel_name = 'Chaîne non disponible'  # Définir la chaîne comme non disponible si l'élément n'est pas trouvé.\n",
    "\n",
    "        # Essayer d'extraire le nombre de likes\n",
    "        try:\n",
    "            likes = driver.find_element(By.XPATH, '/html/body/ytd-app/div[1]/ytd-page-manager/ytd-watch-flexy/div[5]/div[1]/div/div[2]/ytd-watch-metadata/div/div[2]/div[2]/div/div/ytd-menu-renderer/div[1]/segmented-like-dislike-button-view-model/yt-smartimation/div/div/like-button-view-model/toggle-button-view-model/button-view-model/button/div[2]').text\n",
    "        except Exception:\n",
    "            likes = \"Likes non disponibles\"  # Si l'élément n'est pas trouvé, indiquer que les likes ne sont pas disponibles.\n",
    "\n",
    "        # Extraire le nombre de vues\n",
    "        try:\n",
    "            views = driver.find_element(By.XPATH, \"(//yt-formatted-string[@id='info']//span[@dir='auto'])[1]\").text  # Rechercher le nombre de vues par XPath.\n",
    "        except Exception:\n",
    "            views = 'Vues non disponibles'  # Définir les vues comme non disponibles en cas d'erreur.\n",
    "\n",
    "        # Extraire la date de publication de la vidéo\n",
    "        try:\n",
    "            publication_date = driver.find_element(By.XPATH, \"(//yt-formatted-string[@id='info']//span[@dir='auto'])[3]\").text  # Rechercher la date de publication par XPath.\n",
    "        except Exception:\n",
    "            publication_date = 'Date non disponible'  # Définir la date comme non disponible en cas d'erreur.\n",
    "\n",
    "        # Extraire la description complète de la vidéo\n",
    "        try:\n",
    "            description = driver.find_element(By.CSS_SELECTOR, \"span.yt-core-attributed-string.yt-core-attributed-string--white-space-pre-wrap\").text  # Sélectionner la description par CSS.\n",
    "        except Exception:\n",
    "            description = 'Description non disponible'  # Définir la description comme non disponible en cas d'erreur.\n",
    "\n",
    "        # Essayer d'extraire le nombre de commentaires\n",
    "        try:\n",
    "            commentaire_desactive_element = driver.find_element(By.XPATH, \"//yt-formatted-string[contains(text(), 'Les commentaires sont désactivés')]\")  # Vérifier si les commentaires sont désactivés.\n",
    "            if commentaire_desactive_element:\n",
    "                comment_count = \"N/A\"  # Indiquer que les commentaires ne sont pas disponibles.\n",
    "                print(\"Les commentaires sont désactivés sur cette vidéo.\")\n",
    "        except Exception:\n",
    "            # Si les commentaires ne sont pas désactivés, essayer d'extraire le nombre de commentaires\n",
    "            try:\n",
    "                comment_count = driver.find_element(By.XPATH, '/html/body/ytd-app/div[1]/ytd-page-manager/ytd-watch-flexy/div[5]/div[1]/div/div[2]/ytd-comments/ytd-item-section-renderer/div[1]/ytd-comments-header-renderer/div[1]/div[1]/h2/yt-formatted-string').text\n",
    "            except Exception:\n",
    "                comment_count = \"N/A\"  # Indiquer que les commentaires ne sont pas disponibles.\n",
    "                print(\"Commentaires non disponibles\")\n",
    "\n",
    "        # Retourner toutes les informations collectées\n",
    "        return title, channel_name, likes, views, publication_date, description, comment_count\n",
    "\n",
    "    except Exception as e:\n",
    "        # Gérer toute autre exception rencontrée et retourner des valeurs par défaut\n",
    "        print(f\"Erreur lors de la récupération des détails de la vidéo : {str(e)}\")  # Afficher l'erreur si la collecte échoue.\n",
    "        return 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A'  # Retourner des valeurs par défaut si une erreur survient.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Extraction des liens de vidéos :\n",
    "\n",
    "La fonction `get_video_links_from_iframe` extrait les liens de vidéos à partir d'un iframe YouTube en utilisant Selenium. Elle navigue vers l'URL de l'iframe fournie, attend que les éléments vidéo apparaissent, puis collecte tous les liens disponibles. Cette approche est particulièrement utile pour récupérer les liens de vidéos suggérées ou intégrées dans des iframes sur des pages web tierces.\n",
    "\n",
    "- **Objectif** : Extraire les URLs de vidéos à partir d'un iframe YouTube et les retourner sous forme de liste.\n",
    "- **Contexte** : Utilisé dans des scénarios de scraping où des vidéos YouTube sont intégrées dans des iframes et où il est nécessaire de récupérer les liens directs de ces vidéos.\n",
    "  \n",
    "- **Approche** :\n",
    "  1. Charger l'URL de l'iframe spécifié.\n",
    "  2. Attendre que les éléments vidéos (`ytp-impression-link`) soient visibles.\n",
    "  3. Utiliser Selenium pour localiser tous les éléments correspondant et extraire leurs attributs `href`.\n",
    "  4. Retourner la liste des liens récupérés.\n",
    "  5. Gérer les erreurs potentielles et retourner une liste vide si la collecte échoue.\n",
    "\n",
    "- **Avantages** :\n",
    "  - Permet d'automatiser la collecte de liens dans des iframes YouTube.\n",
    "  - Gère automatiquement les délais de chargement grâce à `WebDriverWait` pour s'assurer que les éléments sont bien présents.\n",
    "\n",
    "#### Prérequis :\n",
    "- Le module `selenium` doit être installé (`pip install selenium`).\n",
    "- Le `driver` Selenium doit être initialisé avec un navigateur capable d'afficher les iframes.\n",
    "- La bibliothèque de gestion d'attente (`WebDriverWait`) doit être importée pour gérer les délais.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Fonction pour extraire les liens vidéo à partir d'un iframe YouTube\n",
    "def get_video_links_from_iframe(iframe_src):\n",
    "    # Naviguer vers l'URL de l'iframe fournie\n",
    "    driver.get(iframe_src)  # Charger l'URL de l'iframe pour accéder au contenu vidéo.\n",
    "\n",
    "    try:\n",
    "        # Attendre que les éléments vidéo (liens) soient visibles sur la page (jusqu'à 10 secondes d'attente)\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.visibility_of_element_located((By.CLASS_NAME, 'ytp-impression-link'))  # Rechercher les éléments vidéo par leur classe CSS.\n",
    "        )\n",
    "\n",
    "        # Extraire tous les éléments correspondant à la classe 'ytp-impression-link'\n",
    "        video_links = driver.find_elements(By.CLASS_NAME, 'ytp-impression-link')  # Récupérer tous les éléments correspondant aux vidéos.\n",
    "\n",
    "        # Récupérer l'attribut 'href' (URL) de chaque lien vidéo trouvé\n",
    "        hrefs = [link.get_attribute('href') for link in video_links]  # Extraire les URLs de chaque lien vidéo.\n",
    "\n",
    "        # Retourner la liste des liens vidéo récupérés\n",
    "        return hrefs  # Renvoie la liste des liens collectés.\n",
    "\n",
    "    except Exception as e:\n",
    "        # Gérer toute exception rencontrée et afficher un message d'erreur\n",
    "        print(f\"Erreur lors de la récupération des liens vidéo : {str(e)}\")  # Afficher l'erreur si la récupération échoue.\n",
    "\n",
    "        # Retourner une liste vide en cas d'erreur\n",
    "        return []  # Renvoie une liste vide si une erreur survient.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Extraction et organisation de toutes les informations :\n",
    "\n",
    "La fonction `get_info` extrait diverses informations détaillées à partir d'une page web donnée. Elle utilise la bibliothèque `requests` pour obtenir le contenu HTML de la page et `BeautifulSoup` pour analyser et extraire des informations spécifiques telles que le titre, le texte, la source, la catégorie, les thématiques, le lien vidéo, les statistiques de la vidéo, et les ressources supplémentaires comme les images et les fichiers PDF. Elle prend également en charge l'extraction de détails de vidéos intégrées en interagissant avec un iframe YouTube, et elle télécharge les images et les fichiers PDF trouvés sur la page.\n",
    "\n",
    "- **Objectif** : Extraire les informations textuelles, les images, les vidéos et les fichiers PDF d'une page web pour les structurer dans une liste.\n",
    "- **Contexte** : Utilisé dans des scripts de collecte de données pour créer un résumé détaillé de la page cible avec un ensemble d'informations structurées.\n",
    "  \n",
    "- **Approche** :\n",
    "  1. Récupérer le contenu HTML de la page à partir du lien fourni.\n",
    "  2. Analyser le contenu pour extraire les éléments requis (titre, texte, source, etc.).\n",
    "  3. Identifier et télécharger les images présentes dans la section `module-section-item`.\n",
    "  4. Extraire les liens de vidéos depuis les iframes et récupérer leurs détails.\n",
    "  5. Vérifier la présence de fichiers PDF et les télécharger si trouvés.\n",
    "  6. Structurer toutes les informations dans une liste pour un traitement ultérieur.\n",
    "\n",
    "- **Avantages** :\n",
    "  - Automatisation complète de la collecte d'informations depuis une page web avec une extraction de détails vidéo et de ressources supplémentaires.\n",
    "  - Gère les éléments dynamiques (iframe, vidéos, PDF) tout en conservant une structure cohérente des informations.\n",
    "\n",
    "#### Prérequis :\n",
    "- Les bibliothèques `requests` et `BeautifulSoup` doivent être installées (`pip install requests beautifulsoup4`).\n",
    "- Les fonctions `get_video_links_from_iframe`, `get_video_details`, `download_image`, et `download_pdf` doivent être définies pour gérer les vidéos, images, et fichiers PDF.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Fonction pour extraire diverses informations à partir d'un lien web\n",
    "def get_info(link):\n",
    "    try:\n",
    "        # Récupérer le contenu de la page web\n",
    "        page = requests.get(link)  # Envoyer une requête HTTP pour obtenir le contenu de la page.\n",
    "        soup = bs(page.content, 'html.parser')  # Analyser le contenu HTML avec BeautifulSoup.\n",
    "\n",
    "        # Extraire le titre de la page\n",
    "        Titre = soup.find('h1', class_=\"pt-3 mb-3 mb-md-5 text-white text-center pb-md-5\")  # Rechercher le titre par sa classe CSS.\n",
    "        Titre = Titre.string.strip() if Titre else 'N/A'  # Récupérer le texte du titre ou 'N/A' si non trouvé.\n",
    "\n",
    "        # Extraire le texte principal de la page\n",
    "        Texte = soup.find('div', class_=\"module-section-item default-module-section-item\")  # Rechercher la section de texte principal.\n",
    "        Texte_text = Texte.text.strip() if Texte else 'N/A'  # Extraire le texte ou 'N/A' si non disponible.\n",
    "\n",
    "        # Extraire la source du contenu\n",
    "        source = soup.find('div', class_=\"module-credits pt-3 mt-4\")  # Rechercher la source dans la section correspondante.\n",
    "        source_text = source.get_text(strip=True) if source else 'N/A'  # Extraire le texte de la source.\n",
    "\n",
    "        # Extraire la catégorie\n",
    "        categorie_div = soup.find('div', class_=\"mc-category d-flex justify-content-center\")  # Rechercher la catégorie de l'article.\n",
    "        categorie = categorie_div.find('div', class_='mcc-tag').get_text(strip=True) if categorie_div else 'N/A'  # Extraire le texte de la catégorie.\n",
    "\n",
    "        # Extraire les thématiques associées\n",
    "        themes = soup.find('div', class_=\"tags-list\")  # Rechercher la liste de thématiques.\n",
    "        thematic_list = [span.get_text(strip=True) for span in themes.find_all('span')] if themes else 'N/A'  # Créer une liste de thématiques.\n",
    "\n",
    "        # Extraire le lien de la vidéo depuis l'iframe\n",
    "        iframe_div = soup.find('div', class_='ratio ratio-16x9 mb-4')  # Rechercher la section iframe contenant la vidéo.\n",
    "        lien_video_src = iframe_div.find('iframe').get('src', 'N/A') if iframe_div else 'N/A'  # Récupérer l'URL de l'iframe.\n",
    "\n",
    "        # Initialiser les valeurs par défaut pour les détails de la vidéo\n",
    "        lien_video, video_title, channel_name, likes, views, publication_date, description, comment_count = 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A'\n",
    "\n",
    "        # Si une vidéo est présente, extraire ses informations\n",
    "        if lien_video_src != 'N/A':\n",
    "            lien_video_list = get_video_links_from_iframe(lien_video_src)  # Extraire les liens vidéo depuis l'iframe.\n",
    "            if lien_video_list:\n",
    "                lien_video = lien_video_list[0]  # Prendre le premier lien vidéo.\n",
    "                video_title, channel_name, likes, views, publication_date, description, comment_count = get_video_details(lien_video)  # Récupérer les détails de la vidéo.\n",
    "\n",
    "        # Télécharger les images présentes dans la section `module-section-item`\n",
    "        module_section_item = soup.find('div', class_=\"module-section-item default-module-section-item\")  # Rechercher la section contenant les images.\n",
    "        if module_section_item:\n",
    "            images = module_section_item.find_all('img')  # Récupérer toutes les balises d'image.\n",
    "            for index, img in enumerate(images):\n",
    "                img_url = img.get('src')  # Extraire l'URL de chaque image.\n",
    "                img_filename = f\"{Titre[:50]}_{index + 1}.jpg\"  # Générer un nom de fichier unique pour chaque image.\n",
    "                download_image(img_url, img_filename)  # Télécharger l'image.\n",
    "\n",
    "        # Extraire le nombre de consultations de l'article\n",
    "        Nb_consultation = soup.find('span', id=\"mf-nb-views\")  # Rechercher l'élément contenant le nombre de consultations.\n",
    "        Nb_consultation = Nb_consultation.string if Nb_consultation else 'N/A'  # Récupérer le texte ou 'N/A'.\n",
    "\n",
    "        # Extraire le nombre d'évaluations positives\n",
    "        evaluation_span = soup.find('span', class_=\"ur-link\")  # Rechercher l'élément contenant le nombre d'évaluations positives.\n",
    "        Nb_evaluation_positive = int(evaluation_span.text) if evaluation_span else 0  # Convertir le texte en nombre.\n",
    "\n",
    "        # Extraire les éléments à retenir et le sommaire\n",
    "        divs = soup.find_all('div', class_=\"module-item-content\")  # Rechercher toutes les sections de contenu.\n",
    "        A_retenir = []\n",
    "        Sommaire = []\n",
    "\n",
    "        if divs:\n",
    "            # Extraire les informations \"À retenir\"\n",
    "            first_div = divs[0]\n",
    "            p_elements = first_div.find_all('p')  # Rechercher toutes les balises <p>.\n",
    "            if p_elements:\n",
    "                A_retenir.extend([p.text.strip() for p in p_elements if p.text])  # Ajouter chaque texte à la liste.\n",
    "\n",
    "            # Extraire le sommaire\n",
    "            ul_element = first_div.find('ul')  # Rechercher une liste <ul>.\n",
    "            if ul_element:\n",
    "                li_elements = ul_element.find_all('li')  # Rechercher les éléments de liste <li>.\n",
    "                A_retenir.extend([li.text.strip() for li in li_elements if li.text])  # Ajouter chaque élément à la liste.\n",
    "\n",
    "        # Structurer les informations dans une liste pour export\n",
    "        line = [\n",
    "            Titre, ' '.join(A_retenir), ' '.join(Sommaire), Texte_text, source_text, categorie, ', '.join(thematic_list),\n",
    "            Nb_consultation, Nb_evaluation_positive, link, lien_video, video_title, channel_name, likes, views, publication_date, description, comment_count\n",
    "        ]\n",
    "\n",
    "        return line  # Retourner la ligne structurée contenant toutes les informations.\n",
    "\n",
    "    except Exception as e:\n",
    "        # Gérer toute exception et afficher un message d'erreur\n",
    "        print(f\"Une erreur est survenue lors de l'extraction des informations : {str(e)}\")\n",
    "        return None  # Retourner None en cas d'erreur.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Refus automatique de la newsletter :\n",
    "\n",
    "La fonction `wait_for_newsletter_modal_to_close` attend que le pop-up de la newsletter (élément modal) disparaisse de la page. Elle utilise Selenium pour surveiller la présence d'un élément spécifique (`newsletter-modal`) et continue d'attendre jusqu'à ce que cet élément devienne invisible. Cette technique est souvent utilisée sur des pages web qui affichent des fenêtres contextuelles (modals) telles que des demandes d'abonnement à une newsletter, des promotions, ou des annonces qui bloquent l'accès au contenu principal.\n",
    "\n",
    "- **Objectif** : Attendre que le pop-up de la newsletter disparaisse avant de continuer l'interaction avec le reste de la page.\n",
    "- **Contexte** : Utilisé dans des scripts d'automatisation où un pop-up de type modal empêche l'accès aux éléments de la page tant qu'il n'est pas fermé.\n",
    "  \n",
    "- **Approche** :\n",
    "  1. Utiliser `WebDriverWait` pour attendre jusqu'à 20 secondes que l'élément modal devienne invisible.\n",
    "  2. Vérifier la présence de l'élément par son identifiant (`ID`) spécifié.\n",
    "  3. Si l'élément devient invisible dans le délai imparti, afficher un message de confirmation.\n",
    "  4. Si l'élément ne devient pas invisible dans le temps imparti, afficher un message d'erreur.\n",
    "\n",
    "- **Avantages** :\n",
    "  - Assure que les interactions suivantes ne commencent qu'une fois que le pop-up est complètement fermé.\n",
    "  - Évite les erreurs d'éléments non cliquables ou invisibles causées par des modals superposés.\n",
    "\n",
    "#### Prérequis :\n",
    "- Le module `selenium` doit être installé (`pip install selenium`).\n",
    "- Le `driver` Selenium doit être correctement initialisé avec une page contenant le pop-up cible.\n",
    "- La bibliothèque de gestion d'attente (`WebDriverWait`) et les conditions (`EC`) doivent être importées pour gérer les délais.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Fonction pour attendre la fermeture du pop-up de la newsletter (élément modal)\n",
    "def wait_for_newsletter_modal_to_close():\n",
    "    try:\n",
    "        # Attendre jusqu'à 20 secondes que l'élément avec l'ID 'newsletter-modal' devienne invisible\n",
    "        WebDriverWait(driver, 20).until(\n",
    "            EC.invisibility_of_element_located((By.ID, 'newsletter-modal'))  # Vérifier que l'élément modal n'est plus visible.\n",
    "        )\n",
    "\n",
    "        # Afficher un message de confirmation si le modal est fermé\n",
    "        print(\"Newsletter modal is closed.\")  # Confirmation que le pop-up a été fermé.\n",
    "\n",
    "    except TimeoutException:\n",
    "        # Gérer le cas où le modal n'est pas fermé dans le temps imparti\n",
    "        print(\"Newsletter modal did not close in time.\")  # Afficher un message d'erreur si le délai est dépassé.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Clic sur un élément :\n",
    "\n",
    "La fonction `click_element_with_js` utilise JavaScript pour simuler un clic sur un élément Web spécifié dans un navigateur Selenium. Cette méthode est souvent utilisée lorsqu'un élément est visible mais ne peut pas être cliqué directement avec `element.click()` en raison de certaines restrictions du navigateur (par exemple, superposition d'éléments, transitions CSS, ou limitations d'élément interactif). En utilisant JavaScript, on contourne ces limitations en exécutant le clic au niveau du DOM (Document Object Model).\n",
    "\n",
    "- **Objectif** : Simuler un clic sur un élément Web en utilisant JavaScript pour contourner les limitations de clic direct.\n",
    "- **Contexte** : Utilisé lorsque le clic direct de Selenium (`element.click()`) ne fonctionne pas, notamment avec des éléments masqués partiellement ou recouverts par d'autres éléments.\n",
    "  \n",
    "- **Approche** :\n",
    "  1. Passer l'élément cible en paramètre à la fonction.\n",
    "  2. Utiliser `driver.execute_script` pour exécuter un clic JavaScript sur l'élément spécifié.\n",
    "  3. L'appel de `arguments[0]` dans le script fait référence à l'élément transmis à la fonction.\n",
    "\n",
    "- **Avantages** :\n",
    "  - Contourne les problèmes de clic sur des éléments interactifs qui ne répondent pas au clic direct.\n",
    "  - Permet de gérer les interactions complexes avec des éléments dynamiques ou recouverts.\n",
    "\n",
    "#### Prérequis :\n",
    "- Le module `selenium` doit être installé (`pip install selenium`).\n",
    "- Le `driver` Selenium doit être initialisé avec une page Web chargée.\n",
    "- L'élément doit être localisé correctement avant d'être passé à la fonction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Fonction pour simuler un clic sur un élément Web à l'aide de JavaScript\n",
    "def click_element_with_js(element):\n",
    "    # Utiliser JavaScript pour exécuter un clic sur l'élément spécifié\n",
    "    driver.execute_script(\"arguments[0].click();\", element)  # Simuler un clic en passant l'élément à JavaScript.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Automatisation de la collecte de données sur plusieurs thèmes\n",
    "\n",
    "La fonction `scrape_all_pages` permet d'automatiser la collecte de données sur plusieurs thèmes définis, en naviguant sur le site `https://tpdemain.com/ressources-pedagogiques/`. La fonction effectue une recherche sur chaque thème, récupère les liens des pages de résultats et gère la pagination pour atteindre la dernière page. Ensuite, elle collecte les informations de chaque lien trouvé et exporte les données vers un fichier Excel. Le script gère les pop-ups de la newsletter, les interactions avec les éléments de recherche, et les erreurs liées à l'extraction.\n",
    "\n",
    "- **Objectif** : Collecter des informations détaillées pour chaque thème spécifié en parcourant toutes les pages de résultats et en extrayant les détails de chaque ressource.\n",
    "- **Contexte** : Utilisé pour automatiser le scraping de ressources pédagogiques par thème, gérer les interactions complexes (recherche, pagination), et exporter les résultats sous forme de tableau.\n",
    "  \n",
    "- **Approche** :\n",
    "  1. Charger la page de ressources pédagogiques.\n",
    "  2. Attendre la fermeture du pop-up de la newsletter (`wait_for_newsletter_modal_to_close`).\n",
    "  3. Pour chaque thème :\n",
    "     - Effectuer une recherche par thème.\n",
    "     - Gérer la pagination pour parcourir tous les résultats.\n",
    "     - Extraire les liens de chaque ressource sur toutes les pages.\n",
    "     - Récupérer les informations détaillées de chaque lien.\n",
    "     - Exporter les informations collectées dans un fichier Excel.\n",
    "  4. Quitter le navigateur à la fin du processus.\n",
    "\n",
    "- **Avantages** :\n",
    "  - Automatisation complète de la recherche et de la collecte de données pour plusieurs thèmes.\n",
    "  - Gestion robuste des pop-ups, des interactions et de la pagination.\n",
    "\n",
    "#### Prérequis :\n",
    "- Le module `selenium` doit être installé (`pip install selenium`).\n",
    "- Les fonctions `wait_for_newsletter_modal_to_close`, `click_element_with_js`, `get_info`, et `export_to_excel` doivent être définies.\n",
    "- Le `driver` Selenium doit être initialisé correctement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Fonction pour automatiser la recherche et l'extraction des informations pour une liste de thèmes\n",
    "def scrape_all_pages(themes):\n",
    "    try:\n",
    "        # Naviguer vers la page des ressources pédagogiques\n",
    "        driver.get(\"https://tpdemain.com/ressources-pedagogiques/\")\n",
    "        \n",
    "        # Attendre la fermeture du pop-up de la newsletter\n",
    "        wait_for_newsletter_modal_to_close()\n",
    "\n",
    "        # Parcourir chaque thème de la liste\n",
    "        for theme in themes:\n",
    "            try:\n",
    "                # Recharger la page avant chaque nouvelle recherche\n",
    "                driver.get(\"https://tpdemain.com/ressources-pedagogiques/\")\n",
    "                \n",
    "                # Trouver et cliquer sur le bouton pour ouvrir le champ de recherche\n",
    "                toggle_button = WebDriverWait(driver, 20).until(\n",
    "                    EC.element_to_be_clickable((By.CLASS_NAME, 'search-input-toggler'))  # Attendre que le bouton de recherche soit cliquable.\n",
    "                )\n",
    "                click_element_with_js(toggle_button)  # Utiliser JS pour cliquer sur le bouton.\n",
    "                print(f\"Search input toggler clicked for theme: {theme}\")\n",
    "            except (TimeoutException, Exception) as e:\n",
    "                print(f\"Search input toggler not found for theme: {theme}. Exception: {e}\")\n",
    "\n",
    "            try:\n",
    "                # Entrer le thème dans la barre de recherche\n",
    "                search_bar = WebDriverWait(driver, 20).until(\n",
    "                    EC.visibility_of_element_located((By.CSS_SELECTOR, 'form.app-search-form.form-group input.form-control'))  # Attendre la visibilité de la barre de recherche.\n",
    "                )\n",
    "                print(f\"Search bar found for theme: {theme}\")\n",
    "                search_bar.clear()  # Effacer le contenu existant de la barre de recherche.\n",
    "                search_bar.send_keys(theme)  # Entrer le thème dans la barre de recherche.\n",
    "            except (TimeoutException, Exception) as e:\n",
    "                print(f\"Search bar not found for theme: {theme}. Exception: {e}\")\n",
    "\n",
    "            try:\n",
    "                # Cliquer sur le bouton de recherche\n",
    "                search_button = WebDriverWait(driver, 20).until(\n",
    "                    EC.element_to_be_clickable((By.CSS_SELECTOR, 'form.app-search-form.form-group button'))  # Attendre que le bouton de recherche soit cliquable.\n",
    "                )\n",
    "                click_element_with_js(search_button)  # Utiliser JS pour cliquer sur le bouton.\n",
    "                print(f\"Search button clicked for theme: {theme}\")\n",
    "            except (TimeoutException, Exception) as e:\n",
    "                print(f\"Search button not found for theme: {theme}. Exception: {e}\")\n",
    "\n",
    "            try:\n",
    "                # Attendre que les résultats de recherche soient visibles\n",
    "                WebDriverWait(driver, 30).until(\n",
    "                    EC.visibility_of_element_located((By.CLASS_NAME, 'content-area'))  # Attendre que la zone de contenu des résultats soit visible.\n",
    "                )\n",
    "                print(f\"Search results found for theme: {theme}\")\n",
    "            except (TimeoutException, Exception) as e:\n",
    "                print(f\"Search results not found for theme: {theme}. Exception: {e}\")\n",
    "\n",
    "            # Réinitialiser la liste des liens pour chaque thème\n",
    "            links_list.clear()\n",
    "\n",
    "            # Gestion de la pagination\n",
    "            has_next_page = True\n",
    "            while has_next_page:\n",
    "                try:\n",
    "                    # Extraire les liens des résultats actuels\n",
    "                    content_area = driver.find_element(By.CLASS_NAME, 'content-area')  # Trouver la zone de contenu.\n",
    "                    links = content_area.find_elements(By.TAG_NAME, 'a')  # Extraire tous les liens.\n",
    "\n",
    "                    for link in links:\n",
    "                        href = link.get_attribute('href')  # Récupérer l'attribut href de chaque lien.\n",
    "                        if href and href not in links_list:  # Ajouter les liens non dupliqués à la liste.\n",
    "                            links_list.append(href)\n",
    "\n",
    "                    # Vérifier l'existence d'une page suivante\n",
    "                    pagination_elements = driver.find_elements(By.CLASS_NAME, 'page-numbers')\n",
    "                    current_page_element = driver.find_element(By.CLASS_NAME, 'current')\n",
    "\n",
    "                    current_page = int(current_page_element.text)  # Récupérer le numéro de la page actuelle.\n",
    "                    last_page = current_page\n",
    "\n",
    "                    # Vérifier les autres éléments de pagination\n",
    "                    for elem in pagination_elements:\n",
    "                        try:\n",
    "                            page_number = int(elem.text)\n",
    "                            if page_number > last_page:\n",
    "                                last_page = page_number\n",
    "                        except ValueError:\n",
    "                            continue\n",
    "\n",
    "                    # Vérifier si la page actuelle est la dernière\n",
    "                    if current_page >= last_page:\n",
    "                        has_next_page = False\n",
    "                    else:\n",
    "                        # Aller à la page suivante\n",
    "                        next_button = driver.find_elements(By.CLASS_NAME, 'next')\n",
    "                        if next_button:\n",
    "                            click_element_with_js(next_button[0])  # Cliquer sur le bouton \"suivant\".\n",
    "                            WebDriverWait(driver, 30).until(\n",
    "                                EC.visibility_of_element_located((By.CLASS_NAME, 'content-area'))  # Attendre le chargement de la nouvelle page.\n",
    "                            )\n",
    "                        else:\n",
    "                            has_next_page = False  # Aucune page suivante trouvée.\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Erreur lors de la pagination pour le thème {theme}: {str(e)}\")\n",
    "                    has_next_page = False\n",
    "\n",
    "            # Extraction des informations pour tous les liens collectés\n",
    "            all_data = []\n",
    "            for link in links_list:\n",
    "                info = get_info(link)  # Extraire les informations pour chaque lien.\n",
    "                if info:\n",
    "                    all_data.append(info)\n",
    "\n",
    "            # Exporter les données dans un fichier Excel\n",
    "            export_to_excel(all_data)\n",
    "\n",
    "            # Afficher les résultats collectés\n",
    "            print(\"\\nTous les liens extraits pour le thème :\", theme)\n",
    "            for link in links_list:\n",
    "                print(link)\n",
    "\n",
    "            # Afficher les liens vidéo extraits\n",
    "            print(\"\\nTous les liens vidéo extraits pour le thème :\", theme)\n",
    "            for data in all_data:\n",
    "                lien_video = data[10]  # Vérifier si un lien vidéo est présent.\n",
    "                if lien_video != 'N/A':\n",
    "                    print(lien_video)\n",
    "\n",
    "    finally:\n",
    "        # Quitter le navigateur après la collecte des données\n",
    "        driver.quit()\n",
    "\n",
    "# Liste des thèmes à chercher\n",
    "themes = [\n",
    "    \"construction bas carbone\",\n",
    "    \"Transition environnementale\"\n",
    "]\n",
    "\n",
    "# Lancer le scraping pour tous les thèmes\n",
    "scrape_all_pages(themes)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
