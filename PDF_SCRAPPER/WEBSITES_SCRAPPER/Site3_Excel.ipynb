{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importation des bibliothèques nécessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Module intégré pour interagir avec le système d'exploitation, notamment pour manipuler des chemins de fichiers, accéder à des variables d'environnement, etc.\n",
    "\n",
    "import time\n",
    "# Module intégré pour gérer le temps, offrant des fonctions comme time.sleep() pour ajouter des pauses.\n",
    "\n",
    "import requests\n",
    "# Bibliothèque pour envoyer des requêtes HTTP (GET, POST, etc.), souvent utilisée pour extraire des données de pages web ou des API.\n",
    "\n",
    "from selenium import webdriver\n",
    "# Module Selenium pour automatiser des navigateurs web, ici pour lancer et contrôler un navigateur (Chrome, Firefox, etc.) programmé.\n",
    "\n",
    "from selenium.webdriver.common.by import By\n",
    "# Fournit un moyen de localiser les éléments dans une page web (par ID, CSS_SELECTOR, XPATH, etc.) lors de l'automatisation.\n",
    "\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "# Utilisé pour attendre la présence d'éléments sur la page avant d'interagir avec eux, en réglant un temps d’attente maximal.\n",
    "\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "# Module définissant les conditions à attendre dans une page, comme la visibilité d’un élément, utilisé avec WebDriverWait.\n",
    "\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "# Exceptions de Selenium : TimeoutException est levée lorsque l’attente dépasse le délai imparti, NoSuchElementException lorsque l'élément n'est pas trouvé.\n",
    "\n",
    "from openpyxl import Workbook, load_workbook\n",
    "# Bibliothèque pour manipuler des fichiers Excel (.xlsx). Workbook crée un fichier, load_workbook charge un fichier existant.\n",
    "\n",
    "from bs4 import BeautifulSoup as bs\n",
    "# Bibliothèque BeautifulSoup pour extraire les données HTML, ici importée sous l’alias 'bs' pour simplifier son appel.\n",
    "\n",
    "from urllib.parse import urljoin\n",
    "# Fonction pour combiner les URL relatives et absolues, souvent utilisée pour compléter les URL partielles extraites de pages web.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration des fichiers\n",
    "\n",
    "Ce script configure la structure de dossiers nécessaires pour organiser les fichiers dans un projet. Il crée un dossier principal nommé Fichiers_Excel avec deux sous-dossiers : PDFs pour stocker les fichiers PDF et Audios pour les fichiers audio.\n",
    "\n",
    "- **dossier_excel** : Nom du dossier principal Fichiers_Excel pour contenir tous les fichiers de projet.\n",
    "- **dossier_pdfs** : Sous-dossier PDFs pour les fichiers PDF, créé à l'intérieur de Fichiers_Excel.\n",
    "- **dossier_audios** : Sous-dossier Audios pour les fichiers audio, créé également à l'intérieur de Fichiers_Excel.\n",
    "\n",
    "Prérequis :\n",
    "\n",
    "Les dossiers sont créés uniquement s'ils n'existent pas déjà, grâce à l'argument exist_ok=True, ce qui évite de générer des erreurs si les dossiers sont déjà présents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration des dossiers\n",
    "\n",
    "dossier_excel = 'Fichiers_Excel'\n",
    "# Définition du nom du dossier principal 'Fichiers_Excel' où seront stockés les différents fichiers.\n",
    "os.makedirs(dossier_excel, exist_ok=True)\n",
    "# Création du dossier principal 'Fichiers_Excel' s'il n'existe pas encore.\n",
    "# L'argument 'exist_ok=True' permet d'éviter une erreur si le dossier est déjà présent.\n",
    "\n",
    "dossier_pdfs = os.path.join(dossier_excel, 'PDFs')\n",
    "# Création du chemin pour le sous-dossier 'PDFs' à l'intérieur de 'Fichiers_Excel'.\n",
    "# Ce sous-dossier est destiné à contenir les fichiers PDF.\n",
    "os.makedirs(dossier_pdfs, exist_ok=True)\n",
    "# Création du sous-dossier 'PDFs' dans 'Fichiers_Excel' s'il n'existe pas déjà.\n",
    "\n",
    "dossier_audios = os.path.join(dossier_excel, 'Audios')\n",
    "# Création du chemin pour le sous-dossier 'Audios' dans 'Fichiers_Excel'.\n",
    "# Ce sous-dossier est dédié au stockage des fichiers audio.\n",
    "os.makedirs(dossier_audios, exist_ok=True)\n",
    "# Création du sous-dossier 'Audios' dans 'Fichiers_Excel' s'il n'existe pas encore.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Options du navigateur\n",
    "\n",
    "Ce script configure les options du navigateur Chrome pour une automatisation sans interruption, en désactivant certaines fonctionnalités et en maximisant la fenêtre pour une meilleure visibilité.\n",
    "\n",
    "- **chrome_options** : Objet permettant de définir diverses options de démarrage pour Chrome.\n",
    "- **Désactivation des notifications et des pop-ups** : Empêche les interruptions lors de la navigation automatisée en désactivant les notifications et en autorisant les pop-ups nécessaires.\n",
    "- **Désactivation des fonctionnalités non essentielles** : Réduit la charge sur le navigateur en désactivant l’utilisation du GPU et les extensions.\n",
    "-**Maximisation et invisibilité de l'automatisation** : Lance le navigateur en plein écran et masque les messages ou éléments révélant l'automatisation pour une expérience plus fluide.\n",
    "\n",
    "Prérequis :\n",
    "\n",
    "Ces options sont particulièrement utiles pour des environnements de test ou des scripts de web scraping, où l'interaction humaine est absente et où une stabilité maximale est recherchée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration des options du navigateur Chrome\n",
    "\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "# Initialisation de l'objet ChromeOptions pour configurer les paramètres du navigateur.\n",
    "\n",
    "chrome_options.add_argument(\"--disable-notifications\")\n",
    "# Désactive les notifications du navigateur (pop-ups de notifications du site), pour éviter les interruptions lors de la navigation automatisée.\n",
    "\n",
    "chrome_options.add_argument(\"--disable-popup-blocking\")\n",
    "# Désactive le blocage des pop-ups, ce qui peut être nécessaire si certains éléments déclenchent des pop-ups importants pour l'automatisation.\n",
    "\n",
    "chrome_options.add_argument(\"--disable-gpu\")\n",
    "# Désactive l'utilisation du GPU, utile pour réduire la charge sur le processeur graphique dans certains environnements.\n",
    "\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "# Désactive le mode sandbox de Chrome, souvent requis pour éviter certains conflits d'autorisation dans des environnements serveurs.\n",
    "\n",
    "chrome_options.add_argument(\"--disable-infobars\")\n",
    "# Supprime la barre d'information \"Chrome est contrôlé par un logiciel de test automatisé\" qui peut apparaître en haut de la fenêtre du navigateur.\n",
    "\n",
    "chrome_options.add_argument(\"--disable-extensions\")\n",
    "# Désactive toutes les extensions de Chrome, ce qui peut accélérer le chargement et limiter les interférences potentielles avec les extensions installées.\n",
    "\n",
    "chrome_options.add_argument(\"--disable-features=IsolateOrigins,site-per-process\")\n",
    "# Désactive certaines fonctionnalités d'isolation de sites qui peuvent empêcher l'automatisation de fonctionner correctement sur certains sites.\n",
    "\n",
    "chrome_options.add_argument(\"--start-maximized\")\n",
    "# Démarre le navigateur en plein écran pour garantir que tous les éléments de la page sont visibles sans défilement.\n",
    "\n",
    "chrome_options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "# Exclut le commutateur \"enable-automation\" pour masquer le message \"Chrome est contrôlé par un logiciel de test automatisé\".\n",
    "\n",
    "chrome_options.add_experimental_option(\"useAutomationExtension\", False)\n",
    "# Désactive l'extension d'automatisation de Chrome pour limiter les détecteurs d'automatisation qui pourraient bloquer le script.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonction pour générer un chemin unique pour les fichiers téléchargés\n",
    "\n",
    "La fonction `generer_chemin_fichier` permet de générer un chemin de fichier unique dans un dossier donné en évitant les conflits de noms. Si un fichier avec le même nom existe déjà dans le dossier, elle ajoute un compteur numérique au nom de fichier pour le différencier.\n",
    "\n",
    "Paramètres :\n",
    "\n",
    "- **dossier**: Le chemin du dossier où le fichier doit être créé.\n",
    "- **original_filename** : Le nom de fichier initial souhaité.\n",
    "\n",
    "Retour : Renvoie un chemin de fichier unique dans le dossier spécifié.\n",
    "\n",
    "Processus :\n",
    "\n",
    "Vérifie si un fichier avec le nom donné existe déjà dans le dossier.\n",
    "Si oui, ajoute un suffixe numérique pour différencier le fichier tout en conservant l'extension d'origine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generer_chemin_fichier(dossier, original_filename):\n",
    "    # Génère un chemin de fichier unique dans le dossier spécifié en évitant les conflits de noms de fichiers.\n",
    "\n",
    "    filename = os.path.join(dossier, original_filename)\n",
    "    # Crée le chemin complet pour le fichier en combinant le dossier et le nom de fichier d'origine.\n",
    "\n",
    "    if os.path.exists(filename):\n",
    "        # Vérifie si le fichier existe déjà dans le dossier pour éviter d'écraser un fichier existant.\n",
    "\n",
    "        base, extension = os.path.splitext(original_filename)\n",
    "        # Sépare le nom de fichier de son extension pour pouvoir ajouter un compteur en cas de doublon.\n",
    "        \n",
    "        counter = 1\n",
    "        # Initialise un compteur pour différencier les fichiers ayant le même nom de base.\n",
    "\n",
    "        while os.path.exists(os.path.join(dossier, f\"{base}_{counter}{extension}\")):\n",
    "            # Tant qu'un fichier avec le nom modifié existe déjà, incrémente le compteur pour générer un nom unique.\n",
    "\n",
    "            counter += 1\n",
    "            # Incrémente le compteur de 1 pour chaque itération afin d'essayer un nouveau nom unique.\n",
    "\n",
    "        filename = os.path.join(dossier, f\"{base}_{counter}{extension}\")\n",
    "        # Génère un nom de fichier final en ajoutant le compteur au nom de base, suivi de l'extension d'origine.\n",
    "\n",
    "    return filename\n",
    "    # Retourne le chemin du fichier, garanti unique dans le dossier spécifié.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonction pour refuser les cookies\n",
    "\n",
    "La fonction `click_refuse_cookies` utilise Selenium pour interagir avec une page web et cliquer sur un bouton permettant de refuser les cookies. Elle est conçue pour gérer les paramètres de cookies automatiquement sur des sites web.\n",
    "\n",
    "Paramètres :\n",
    "\n",
    "- `driver`: Instance du navigateur (Selenium WebDriver) utilisée pour contrôler la page web.\n",
    "\n",
    "Processus :\n",
    "\n",
    "- Attente de l'apparition du bouton \"Tout refuser\" (20 secondes maximum).\n",
    "- Défilement pour rendre le bouton visible dans la fenêtre, puis nouvelle attente pour s'assurer qu'il est cliquable.\n",
    "- Clique sur le bouton pour refuser l'utilisation des cookies.\n",
    "- En cas d'échec, affiche un message d'erreur contenant la raison de l'exception.\n",
    "\n",
    "Cas d'usage : Cette fonction est utile pour automatiser la gestion des cookies lors de l'extraction de données ou des tests automatisés sur des sites web, en refusant systématiquement les cookies pour éviter les pop-ups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def click_refuse_cookies(driver):\n",
    "    # Tente de localiser et de cliquer sur le bouton \"Tout refuser\" pour refuser les cookies sur un site web.\n",
    "\n",
    "    try:\n",
    "        print(\"Recherche du bouton 'Tout refuser' des cookies\")\n",
    "        # Message pour indiquer le début de la recherche du bouton de refus des cookies.\n",
    "\n",
    "        refuse_button = WebDriverWait(driver, 20).until(\n",
    "            EC.presence_of_element_located((By.XPATH, \"//button[@aria-label=\\\"Refuser l'utilisation de cookies et d'autres données aux fins décrites\\\"]\"))\n",
    "        )\n",
    "        # Attente explicite de 20 secondes pour que le bouton \"Refuser\" apparaisse sur la page.\n",
    "        # Utilisation d'un sélecteur XPath pour localiser le bouton basé sur son attribut aria-label.\n",
    "\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView(true);\", refuse_button)\n",
    "        # Scrolle jusqu'au bouton \"Refuser\" pour s'assurer qu'il est visible dans la fenêtre avant d'essayer de cliquer.\n",
    "\n",
    "        WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, \"//button[@aria-label=\\\"Refuser l'utilisation de cookies et d'autres données aux fins décrites\\\"]\")))\n",
    "        # Attente supplémentaire de 10 secondes pour s'assurer que le bouton est cliquable.\n",
    "\n",
    "        refuse_button.click()\n",
    "        # Clique sur le bouton \"Refuser\" pour désactiver les cookies.\n",
    "\n",
    "        print(\"Bouton 'Tout refuser' des cookies cliqué\")\n",
    "        # Message de confirmation indiquant que le bouton a été cliqué avec succès.\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors du refus des cookies : {str(e)}\")\n",
    "        # Gestion des exceptions en cas d'erreur, avec affichage du message d'erreur pour faciliter le débogage.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonction pour télécharger les fichiers audio\n",
    "\n",
    "La fonction `telecharger_audio` télécharge des fichiers audio depuis une liste d'URLs et les enregistre localement dans un dossier désigné. Elle assure que chaque fichier a un nom unique pour éviter tout conflit et compte le nombre de téléchargements réussis.\n",
    "\n",
    "Paramètres :\n",
    "\n",
    "- `liens_audio` : Liste d'URLs (chaînes de caractères) pointant vers les fichiers audio à télécharger.\n",
    "\n",
    "Retour : Renvoie un entier représentant le nombre de fichiers audio téléchargés avec succès.\n",
    "\n",
    "Processus :\n",
    "\n",
    "Pour chaque URL, la fonction :\n",
    "\n",
    "- Télécharge le fichier en envoyant une requête GET.\n",
    "- Vérifie que la requête est réussie (pas d'erreur HTTP).\n",
    "- Génère un nom de fichier unique en utilisant generer_chemin_fichier.\n",
    "- Enregistre le fichier dans le dossier dossier_audios.\n",
    "- Incrémente un compteur pour chaque téléchargement réussi.\n",
    "- Gère les exceptions en affichant un message d'erreur pour les URLs qui échouent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def telecharger_audio(liens_audio):\n",
    "    # Télécharge une liste de fichiers audio depuis les URLs fournies et les enregistre dans un dossier spécifié.\n",
    "\n",
    "    count = 0  # Compteur pour les audios téléchargés avec succès\n",
    "\n",
    "    for url in liens_audio:\n",
    "        # Parcourt chaque URL dans la liste 'liens_audio'.\n",
    "\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            # Envoie une requête HTTP GET pour télécharger le contenu de l'URL.\n",
    "            \n",
    "            response.raise_for_status()\n",
    "            # Vérifie que la requête a réussi (status code 200). \n",
    "            # Si une erreur survient (ex : 404, 500), une exception sera levée.\n",
    "\n",
    "            filename = generer_chemin_fichier(dossier_audios, url.split('/')[-1])\n",
    "            # Génère un chemin de fichier unique pour éviter d'écraser des fichiers existants.\n",
    "            # Utilise le nom de fichier provenant de l'URL.\n",
    "\n",
    "            print(f\"Téléchargement de l'audio depuis {url} et sauvegarde sous : {filename}\")\n",
    "            # Affiche un message indiquant le début du téléchargement et le chemin de sauvegarde.\n",
    "\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "            # Ouvre le fichier en mode binaire et écrit le contenu téléchargé dans le fichier local.\n",
    "\n",
    "            count += 1  # Incrémente le compteur pour chaque téléchargement réussi\n",
    "            print(f\"Audio téléchargé : {filename}\")\n",
    "            # Affiche un message de confirmation pour chaque fichier téléchargé.\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors du téléchargement de l'audio {url} : {e}\")\n",
    "            # En cas d'exception (connexion échouée, URL invalide, etc.), affiche un message d'erreur.\n",
    "\n",
    "    print(f\"{count} fichiers audio ont été téléchargés.\")\n",
    "    # Affiche le nombre total de fichiers téléchargés après la fin de la boucle.\n",
    "\n",
    "    return count  # Retourne le nombre de fichiers audio téléchargés avec succès.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonction pour télécharger les fichiers PDF\n",
    "\n",
    "La fonction `telecharger_pdfs` télécharge des fichiers PDF depuis une liste d'URLs et les enregistre localement dans un dossier désigné. Elle garantit un nom de fichier unique pour chaque téléchargement et compte le nombre de téléchargements réussis.\n",
    "\n",
    "Paramètres :\n",
    "\n",
    "- `liens_pdf` : Liste d'URLs (chaînes de caractères) pointant vers les fichiers PDF à télécharger.\n",
    "\n",
    "Retour :\n",
    "\n",
    "Renvoie un entier représentant le nombre de fichiers PDF téléchargés avec succès.\n",
    "\n",
    "Processus :\n",
    "\n",
    "Pour chaque URL, la fonction :\n",
    "\n",
    "- Télécharge le fichier en envoyant une requête GET.\n",
    "- Vérifie que la requête est réussie (pas d'erreur HTTP).\n",
    "- Génère un nom de fichier unique en utilisant generer_chemin_fichier.\n",
    "- Enregistre le fichier dans le dossier dossier_pdfs.\n",
    "- Incrémente un compteur pour chaque téléchargement réussi.\n",
    "- Gère les exceptions en affichant un message d'erreur pour les URLs qui échouent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def telecharger_pdfs(liens_pdf):\n",
    "    # Télécharge une liste de fichiers PDF depuis les URLs fournies et les enregistre dans un dossier spécifié.\n",
    "\n",
    "    count = 0  # Compteur pour les PDF téléchargés avec succès\n",
    "\n",
    "    for url in liens_pdf:\n",
    "        # Parcourt chaque URL dans la liste 'liens_pdf'.\n",
    "\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            # Envoie une requête HTTP GET pour télécharger le contenu de l'URL.\n",
    "            \n",
    "            response.raise_for_status()\n",
    "            # Vérifie que la requête a réussi (status code 200).\n",
    "            # Si une erreur survient (ex : 404, 500), une exception sera levée.\n",
    "\n",
    "            filename = generer_chemin_fichier(dossier_pdfs, url.split('/')[-1])\n",
    "            # Génère un chemin de fichier unique pour éviter d'écraser des fichiers existants.\n",
    "            # Utilise le nom de fichier provenant de l'URL.\n",
    "\n",
    "            print(f\"Téléchargement du PDF depuis {url} et sauvegarde sous : {filename}\")\n",
    "            # Affiche un message indiquant le début du téléchargement et le chemin de sauvegarde.\n",
    "\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "            # Ouvre le fichier en mode binaire et écrit le contenu téléchargé dans le fichier local.\n",
    "\n",
    "            count += 1  # Incrémente le compteur pour chaque téléchargement réussi\n",
    "            print(f\"PDF téléchargé : {filename}\")\n",
    "            # Affiche un message de confirmation pour chaque fichier téléchargé.\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors du téléchargement du PDF {url} : {e}\")\n",
    "            # En cas d'exception (connexion échouée, URL invalide, etc.), affiche un message d'erreur.\n",
    "\n",
    "    print(f\"{count} fichiers PDF ont été téléchargés.\")\n",
    "    # Affiche le nombre total de fichiers téléchargés après la fin de la boucle.\n",
    "\n",
    "    return count  # Retourne le nombre de fichiers PDF téléchargés avec succès.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonction pour exporter les données vers un fichier Excel sans écraser les anciennes données\n",
    "\n",
    "La fonction `exporter_vers_excel` exporte une liste de données dans un fichier Excel nommé `data_proreno.xlsx`, situé dans un dossier spécifié. Elle crée le fichier avec des en-têtes si celui-ci n'existe pas encore ou ajoute simplement les données si le fichier est déjà présent.\n",
    "\n",
    "Paramètres :\n",
    "\n",
    "- `donnees`: Liste de listes, où chaque sous-liste représente une ligne de données à ajouter au fichier Excel.\n",
    "\n",
    "Processus :\n",
    "\n",
    "- Vérifie si le fichier Excel `data_proreno.xlsx` existe.\n",
    "- Si oui, le charge et utilise la feuille active.\n",
    "- Sinon, crée un nouveau fichier avec une feuille nommée \"Informations complètes\" et y ajoute une ligne d'en-têtes.\n",
    "- Pour chaque ligne de donnees, ajoute les informations au fichier, en remplaçant les valeurs None par des chaînes vides.\n",
    "- Sauvegarde le fichier une fois toutes les lignes ajoutées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exporter_vers_excel(donnees):\n",
    "    # Exporte les données fournies dans un fichier Excel nommé 'data_proreno.xlsx' situé dans le dossier spécifié.\n",
    "\n",
    "    try:\n",
    "        # Chemin vers le fichier Excel\n",
    "        excel_path = os.path.join(dossier_excel, 'data_proreno.xlsx')\n",
    "        # Détermine le chemin complet du fichier Excel où les données seront exportées.\n",
    "\n",
    "        # Si le fichier existe déjà, on le charge, sinon on en crée un nouveau\n",
    "        if os.path.exists(excel_path):\n",
    "            wb = load_workbook(excel_path)  # Charger le fichier existant\n",
    "            ws = wb.active  # Sélectionner la feuille active\n",
    "        else:\n",
    "            wb = Workbook()  # Créer un nouveau fichier Excel\n",
    "            ws = wb.active\n",
    "            ws.title = 'Informations complètes'\n",
    "            # Initialise une nouvelle feuille de calcul et définit son titre.\n",
    "\n",
    "            # Définition des en-têtes (uniquement pour un nouveau fichier)\n",
    "            en_tetes = [\n",
    "                'Titre', 'Description', 'Résumé', 'Nombre de téléchargements', \n",
    "                \"Nombre de likes\", \"Nombre d'avis\", 'Nombre d’écoutes', 'Nombre de vues', \n",
    "                'Nombre de pages', 'Type de chantier', 'Type de bâtiment', 'Lots impliqués', \n",
    "                'Sujets techniques associés', 'Étape de chantier', 'Contributeur', \n",
    "                'Lien', 'Lien vidéo', 'Titre vidéo', 'Description vidéo', \n",
    "                'Propriétaire vidéo', 'Nombre de vues vidéo', 'Nombre de commentaires vidéo', \n",
    "                'Date de publication', 'Nombre de likes vidéo'\n",
    "            ]\n",
    "            ws.append(en_tetes)  # Ajouter les en-têtes si le fichier est nouveau\n",
    "            # Ajoute une ligne d'en-têtes pour structurer les colonnes, seulement si le fichier est créé.\n",
    "\n",
    "        # Ajouter chaque ligne de données au fichier Excel\n",
    "        for info in donnees:\n",
    "            print(f\"Ajout des données suivantes à Excel : {info}\")\n",
    "            # Affiche chaque ligne de données ajoutée pour un suivi visuel.\n",
    "\n",
    "            cleaned_info = [str(item) if item is not None else '' for item in info]\n",
    "            # Remplace les valeurs 'None' par des chaînes vides pour éviter les erreurs de format.\n",
    "\n",
    "            ws.append(cleaned_info)  # Ajouter la ligne au fichier Excel\n",
    "            # Ajoute la ligne de données au fichier Excel.\n",
    "\n",
    "        # Sauvegarder le fichier Excel\n",
    "        wb.save(excel_path)\n",
    "        # Sauvegarde le fichier Excel avec toutes les données ajoutées.\n",
    "\n",
    "        print(f\"Données exportées avec succès vers : {excel_path}\")\n",
    "        # Message de confirmation pour indiquer que l'exportation a réussi.\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Une erreur est survenue lors de l'exportation vers Excel : {str(e)}\")\n",
    "        # Gère les exceptions en affichant un message d'erreur pour faciliter le débogage.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonction pour extraire les informations d'une vidéo YouTube\n",
    "\n",
    "La fonction `extraire_infos_youtube` utilise Selenium pour extraire des informations d'une vidéo YouTube, telles que le titre, la description, le nombre de vues, le propriétaire, la date de publication, le nombre de likes et le nombre de commentaires. Elle scrolle la page, clique sur \"Afficher plus\" pour charger toutes les informations, et gère les pop-ups de cookies.\n",
    "\n",
    "Paramètres :\n",
    "\n",
    "- **navigateur** : Instance du WebDriver Selenium, utilisée pour naviguer et interagir avec la page YouTube.\n",
    "- **lien_video** : URL de la vidéo YouTube à analyser.\n",
    "\n",
    "Retour :\n",
    "\n",
    "Renvoie une liste avec les informations de la vidéo, ou ['N/A'] * 7 en cas d'échec.\n",
    "\n",
    "Étapes de l'extraction :\n",
    "\n",
    "- Charge la page et refuse les cookies (si le pop-up est présent).\n",
    "- Scrolle la page pour afficher tous les éléments nécessaires.\n",
    "- Clique sur \"Afficher plus\" pour révéler la description complète.\n",
    "- Extrait les informations du titre, de la description, du propriétaire, du nombre de vues, de la date de publication, du nombre de likes, et du nombre de commentaires (ou indique \"N/A\" si les commentaires sont désactivés)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour extraire les informations d'une vidéo YouTube\n",
    "def extraire_infos_youtube(navigateur, lien_video):\n",
    "    # Extrait les informations d'une vidéo YouTube en chargeant la page et en récupérant le titre, \n",
    "    # la description, le nombre de vues, le propriétaire, la date de publication, le nombre de likes, \n",
    "    # et le nombre de commentaires (si disponibles).\n",
    "\n",
    "    try:\n",
    "        # Charger la page YouTube\n",
    "        navigateur.get(lien_video)\n",
    "        time.sleep(10)  # Pause pour laisser la page se charger complètement\n",
    "\n",
    "        # Refuser les cookies si le pop-up est présent\n",
    "        try:\n",
    "            bouton_refuser_cookies = WebDriverWait(navigateur, 10).until(\n",
    "                EC.element_to_be_clickable((By.XPATH, '/html/body/c-wiz/div/div/div/div[2]/div[1]/div[3]/div[1]/form[1]/div/div/button/span'))\n",
    "            )\n",
    "            bouton_refuser_cookies.click()\n",
    "            print(\"Pop-up des cookies refusé\")\n",
    "        except TimeoutException:\n",
    "            print(\"Pas de pop-up de cookies ou déjà refusé\")\n",
    "\n",
    "        # Scroller pour charger tous les éléments de la page\n",
    "        navigateur.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(2)\n",
    "\n",
    "        # Cliquer sur \"Afficher plus\" pour révéler la description complète\n",
    "        try:\n",
    "            bouton_afficher_plus = WebDriverWait(navigateur, 10).until(\n",
    "                EC.element_to_be_clickable((By.ID, 'expand'))\n",
    "            )\n",
    "            bouton_afficher_plus.click()\n",
    "            print(\"Bouton 'Afficher plus' cliqué\")\n",
    "        except TimeoutException:\n",
    "            print(\"Le bouton 'Afficher plus' n'a pas été trouvé ou n'est pas cliquable.\")\n",
    "\n",
    "        # Extraction du titre de la vidéo\n",
    "        try:\n",
    "            titre_video = WebDriverWait(navigateur, 20).until(\n",
    "                EC.presence_of_element_located((By.XPATH, '/html/body/ytd-app/div[1]/ytd-page-manager/ytd-watch-flexy/div[5]/div[1]/div/div[2]/ytd-watch-metadata/div/div[1]/h1/yt-formatted-string'))\n",
    "            ).text\n",
    "            print(f\"Titre de la vidéo récupéré : {titre_video}\")\n",
    "        except Exception as e:\n",
    "            titre_video = \"N/A\"\n",
    "            print(f\"Erreur lors de l'extraction du titre de la vidéo : {str(e)}\")\n",
    "\n",
    "        # Extraction de la description complète de la vidéo\n",
    "        try:\n",
    "            description_video = WebDriverWait(navigateur, 10).until(\n",
    "                EC.presence_of_element_located((By.XPATH, '/html/body/ytd-app/div[1]/ytd-page-manager/ytd-watch-flexy/div[5]/div[1]/div/div[2]/ytd-watch-metadata/div/div[4]/div[1]/div/ytd-text-inline-expander/yt-attributed-string'))\n",
    "            ).text\n",
    "            print(f\"Description de la vidéo récupérée : {description_video}\")\n",
    "        except Exception as e:\n",
    "            description_video = \"N/A\"\n",
    "            print(f\"Erreur lors de l'extraction de la description de la vidéo : {str(e)}\")\n",
    "\n",
    "        # Extraction du propriétaire de la vidéo\n",
    "        try:\n",
    "            proprietaire_video = WebDriverWait(navigateur, 20).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, 'yt-formatted-string.style-scope.ytd-channel-name'))\n",
    "            ).text\n",
    "            print(f\"Propriétaire de la vidéo récupéré : {proprietaire_video}\")\n",
    "        except Exception as e:\n",
    "            proprietaire_video = \"N/A\"\n",
    "            print(f\"Erreur lors de l'extraction du propriétaire de la vidéo : {str(e)}\")\n",
    "\n",
    "        # Extraction du nombre de vues\n",
    "        try:\n",
    "            vues_video = WebDriverWait(navigateur, 20).until(\n",
    "                EC.presence_of_element_located((By.XPATH, '/html/body/ytd-app/div[1]/ytd-page-manager/ytd-watch-flexy/div[5]/div[1]/div/div[2]/ytd-watch-metadata/div/div[4]/div[1]/div/ytd-watch-info-text/div/yt-formatted-string/span[1]'))\n",
    "            ).text\n",
    "            print(f\"Nombre de vues récupéré : {vues_video}\")\n",
    "        except Exception as e:\n",
    "            vues_video = \"N/A\"\n",
    "            print(f\"Erreur lors de l'extraction du nombre de vues : {str(e)}\")\n",
    "\n",
    "        # Extraction de la date de publication\n",
    "        try:\n",
    "            date_publication = WebDriverWait(navigateur, 20).until(\n",
    "                EC.presence_of_element_located((By.XPATH, '/html/body/ytd-app/div[1]/ytd-page-manager/ytd-watch-flexy/div[5]/div[1]/div/div[2]/ytd-watch-metadata/div/div[4]/div[1]/div/ytd-watch-info-text/div/yt-formatted-string/span[3]'))\n",
    "            ).text\n",
    "            print(f\"Date de publication récupérée : {date_publication}\")\n",
    "        except Exception as e:\n",
    "            date_publication = \"N/A\"\n",
    "            print(f\"Erreur lors de l'extraction de la date de publication : {str(e)}\")\n",
    "\n",
    "        # Extraction du nombre de commentaires\n",
    "        try:\n",
    "            commentaire_desactive_element = WebDriverWait(navigateur, 20).until(\n",
    "                EC.presence_of_element_located((By.XPATH, \"//yt-formatted-string[contains(text(), 'Les commentaires sont désactivés')]\"))\n",
    "            )\n",
    "            if commentaire_desactive_element:\n",
    "                nombre_commentaires = \"N/A\"\n",
    "                print(\"Les commentaires sont désactivés sur cette vidéo.\")\n",
    "        except TimeoutException:\n",
    "            try:\n",
    "                nombre_commentaires = WebDriverWait(navigateur, 20).until(\n",
    "                    EC.presence_of_element_located((By.CSS_SELECTOR, 'yt-formatted-string.count-text.style-scope.ytd-comments-header-renderer'))\n",
    "                ).text\n",
    "                print(f\"Nombre de commentaires récupéré : {nombre_commentaires}\")\n",
    "            except Exception as e:\n",
    "                nombre_commentaires = \"N/A\"\n",
    "                print(f\"Erreur lors de l'extraction du nombre de commentaires : {str(e)}\")\n",
    "\n",
    "        # Extraction du nombre de likes\n",
    "        try:\n",
    "            nombre_likes = WebDriverWait(navigateur, 10).until(\n",
    "                EC.presence_of_element_located((By.XPATH, '/html/body/ytd-app/div[1]/ytd-page-manager/ytd-watch-flexy/div[5]/div[1]/div/div[2]/ytd-watch-metadata/div/div[2]/div[2]/div/div/ytd-menu-renderer/div[1]/segmented-like-dislike-button-view-model/yt-smartimation/div/div/like-button-view-model/toggle-button-view-model/button-view-model/button/div[2]'))\n",
    "            ).text\n",
    "        except TimeoutException:\n",
    "            nombre_likes = \"N/A\"\n",
    "            print(\"Erreur lors de l'extraction du nombre de likes\")\n",
    "\n",
    "        # Compilation des informations extraites\n",
    "        infos_video = [\n",
    "            titre_video, description_video, proprietaire_video, vues_video, nombre_commentaires,\n",
    "            date_publication, nombre_likes\n",
    "        ]\n",
    "\n",
    "        print(f\"Informations de la vidéo YouTube extraites : {infos_video}\")\n",
    "        return infos_video\n",
    "\n",
    "    except Exception as e:\n",
    "        # En cas d'erreur, afficher l'erreur et renvoyer 'N/A' pour toutes les informations\n",
    "        print(f\"Erreur lors de l'extraction des informations de la vidéo YouTube : {str(e)}\")\n",
    "        return ['N/A'] * 7\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonction pour récupérer les informations d'une page à partir du lien\n",
    "\n",
    "La fonction `recuperer_info_de_page` utilise un navigateur Selenium pour accéder à une page web et BeautifulSoup pour extraire des informations spécifiques telles que le titre, la description, les métriques, et les liens vers des fichiers PDF, audio et vidéo.\n",
    "\n",
    "Paramètres :\n",
    "\n",
    "- **lien** : URL de la page web à analyser.\n",
    "- **navigateur** : Instance du navigateur Selenium (WebDriver) utilisée pour charger et interagir avec la page.\n",
    "\n",
    "Retour :\n",
    "\n",
    "Renvoie une liste d'informations extraites et trois listes de liens (PDF, audio, vidéo).\n",
    "\n",
    "Processus :\n",
    "\n",
    "- Charge la page via Selenium et extrait le contenu HTML.\n",
    "- Utilise BeautifulSoup pour extraire des informations spécifiques (titre, description, métriques, etc.).\n",
    "- Récupère les liens vers les fichiers PDF, audio et les vidéos YouTube intégrées.\n",
    "- Gère les erreurs pour assurer la robustesse du code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def recuperer_info_de_page(lien, navigateur):\n",
    "    try:\n",
    "        # Charger la page dans le navigateur\n",
    "        navigateur.get(lien)\n",
    "        time.sleep(5)  # Pause pour laisser la page charger\n",
    "\n",
    "        # Extraire le HTML de la page\n",
    "        page_html = navigateur.page_source\n",
    "        soup = bs(page_html, 'html.parser')\n",
    "\n",
    "        # Extraire les informations nécessaires\n",
    "        titre = soup.find('h1', class_='title-1 relative z-10').get_text(strip=True) if soup.find('h1', class_='title-1 relative z-10') else 'N/A'\n",
    "        description_element = soup.find('h2', class_='w-full lg:w-[90%] font-light')\n",
    "        description = description_element.string.strip() if description_element else 'N/A'\n",
    "\n",
    "        resume_element = soup.find('p', class_='font-light leading-[1.8] whitespace-pre-line')\n",
    "        resume = resume_element.string.strip() if resume_element else 'N/A'\n",
    "\n",
    "        # Vérifier que chaque champ contient une valeur pour éviter les désalignements\n",
    "        telechargements = 'N/A'\n",
    "        div_telechargements = soup.find('div', class_='flex justify-between items-center lg:justify-start lg:gap-40')\n",
    "        if div_telechargements:\n",
    "            divs_internes = div_telechargements.find_all('div', class_='flex items-center gap-5')\n",
    "            for div_interne in divs_internes:\n",
    "                element_telechargements = div_interne.find('span', class_='text-14 font-semibold')\n",
    "                if element_telechargements:\n",
    "                    sibling_texte = element_telechargements.find_next_sibling('span', class_='text-11')\n",
    "                    if sibling_texte and sibling_texte.text.strip() == 'téléchargements':\n",
    "                        telechargements = element_telechargements.text.strip()\n",
    "                        break\n",
    "\n",
    "        likes = 'N/A'\n",
    "        if div_telechargements:\n",
    "            for div_interne in divs_internes:\n",
    "                element_likes = div_interne.find('span', class_='text-14 font-semibold')\n",
    "                if element_likes:\n",
    "                    sibling_texte = element_likes.find_next_sibling('span', class_='text-11')\n",
    "                    if sibling_texte and sibling_texte.text.strip() == \"J'aime\":\n",
    "                        likes = element_likes.text.strip()\n",
    "                        break\n",
    "\n",
    "        avis = 'N/A'\n",
    "        lien_avis = soup.find('a', class_='flex items-center gap-5 no-underline group')\n",
    "        if lien_avis:\n",
    "            element_avis = lien_avis.find('span', class_='text-14 font-semibold')\n",
    "            if element_avis:\n",
    "                avis = element_avis.string.strip()\n",
    "\n",
    "        ecoutes = 'N/A'\n",
    "        ecoutes_element = soup.find('span', class_='icon-sound text-white text-20 mr-[3px]')\n",
    "        if ecoutes_element:\n",
    "            ecoutes_span = ecoutes_element.find_next('span', class_='text-14 font-semibold')\n",
    "            if ecoutes_span:\n",
    "                text_sibling = ecoutes_span.find_next_sibling('span', class_='text-11')\n",
    "                if text_sibling and text_sibling.text.strip() == 'écoutes':\n",
    "                    ecoutes = ecoutes_span.text.strip()\n",
    "\n",
    "        vues = 'N/A'\n",
    "        vues_element = soup.find('span', class_='icon-play text-white text-20 mr-[3px]')\n",
    "        if vues_element:\n",
    "            vues_span = vues_element.find_next('span', class_='text-14 font-semibold')\n",
    "            if vues_span:\n",
    "                text_sibling = vues_span.find_next_sibling('span', class_='text-11')\n",
    "                if text_sibling and text_sibling.text.strip() == 'vues':\n",
    "                    vues = vues_span.text.strip()\n",
    "\n",
    "        nombre_de_pages = 'N/A'\n",
    "        div_nombre_de_pages = soup.find('div', class_='flex items-center gap-5')\n",
    "        if div_nombre_de_pages:\n",
    "            spans = div_nombre_de_pages.find_all('span', class_='text-14 font-semibold')\n",
    "            for span in spans:\n",
    "                sibling_texte = span.find_next_sibling('span', class_='text-11')\n",
    "                if sibling_texte and sibling_texte.text.strip() == 'pages':\n",
    "                    nombre_de_pages = span.text.strip()\n",
    "                    break\n",
    "\n",
    "        type_de_chantier = 'N/A'\n",
    "        div_type_de_chantier = soup.find('div', class_='flex items-center gap-10 flex-wrap')\n",
    "        if div_type_de_chantier:\n",
    "            liens_chantier = div_type_de_chantier.find_all('a', class_='no-underline')\n",
    "            type_de_chantier = ', '.join([lien.text.strip() for lien in liens_chantier]) if liens_chantier else 'N/A'\n",
    "\n",
    "        type_de_batiment = 'N/A'\n",
    "        divs_type_de_batiment = soup.find_all('div', class_='flex items-center gap-10 flex-wrap')\n",
    "        if len(divs_type_de_batiment) > 1:\n",
    "            liens_batiment = divs_type_de_batiment[1].find_all('a', class_='no-underline')\n",
    "            type_de_batiment = ', '.join([lien.text.strip() for lien in liens_batiment]) if liens_batiment else 'N/A'\n",
    "\n",
    "        lots_impliques = 'N/A'\n",
    "        if len(divs_type_de_batiment) > 2:\n",
    "            liens_lots = divs_type_de_batiment[2].find_all('a', class_='no-underline')\n",
    "            lots_impliques = ', '.join([lien.text.strip() for lien in liens_lots]) if liens_lots else 'N/A'\n",
    "\n",
    "        sujets_techniques_associes = 'N/A'\n",
    "        if len(divs_type_de_batiment) > 3:\n",
    "            liens_sujets = divs_type_de_batiment[3].find_all('a', class_='no-underline')\n",
    "            sujets_techniques_associes = ', '.join([lien.text.strip() for lien in liens_sujets]) if liens_sujets else 'N/A'\n",
    "\n",
    "        etape_de_chantier = 'N/A'\n",
    "        ul_etape_de_chantier = soup.find('ul', class_='flex justify-start items-center gap-30 flex-wrap')\n",
    "        if ul_etape_de_chantier:\n",
    "            p_etapes = ul_etape_de_chantier.find_all('p')\n",
    "            etape_de_chantier = ', '.join([p.text.strip() for p in p_etapes]) if p_etapes else 'N/A'\n",
    "\n",
    "        contributeur = 'N/A'\n",
    "        div_contributeur = soup.find('div', class_='flex flex-col gap-10 py-10')\n",
    "        if div_contributeur:\n",
    "            p_elements = div_contributeur.find_all('p')\n",
    "            contributeur = '\\n'.join([p.text.strip() for p in p_elements]) if p_elements else 'N/A'\n",
    "\n",
    "        # Liens PDF et audio\n",
    "        liens_pdf = []\n",
    "        pdf_link = soup.find('a', id='downloadLink')\n",
    "        if pdf_link and pdf_link['href'].lower().endswith('.pdf'):\n",
    "            full_url = urljoin(lien, pdf_link['href'])\n",
    "            liens_pdf.append(full_url)\n",
    "\n",
    "        liens_audio = []\n",
    "        audio_elements = soup.find_all('audio', preload=\"metadata\")\n",
    "        for audio in audio_elements:\n",
    "            if 'src' in audio.attrs:\n",
    "                full_url = urljoin(lien, audio['src'])\n",
    "                liens_audio.append(full_url)\n",
    "\n",
    "        # Récupérer les informations vidéo (si disponibles)\n",
    "        infos_video = []\n",
    "        liens_video = []\n",
    "        div_videos = soup.find('dialog', id='video-popin')\n",
    "        if div_videos:\n",
    "            iframe_elements = div_videos.find_all('iframe', src=True)\n",
    "            for iframe in iframe_elements:\n",
    "                src = iframe['src']\n",
    "                full_url = urljoin(lien, src)\n",
    "                if 'youtube-nocookie.com/embed/' in full_url:\n",
    "                    video_id = full_url.split('youtube-nocookie.com/embed/')[1]\n",
    "                    youtube_url = f'https://www.youtube.com/watch?v={video_id}'\n",
    "                    liens_video.append(youtube_url)\n",
    "                    # Extraire les infos de la vidéo YouTube\n",
    "                    infos_video.append(extraire_infos_youtube(navigateur, youtube_url))\n",
    "        \n",
    "        # Si une vidéo est trouvée mais sans détails, la marquer comme \"N/A\"\n",
    "        if not infos_video:\n",
    "            infos_video = [[\"N/A\"] * 7]  # Si aucune vidéo n'est trouvée, définir toutes les infos vidéo à \"N/A\"\n",
    "\n",
    "        infos_video = infos_video[0] if infos_video else ['N/A'] * 7\n",
    "\n",
    "        # Ajouter cette ligne pour traiter les liens vidéo\n",
    "        if not liens_video:\n",
    "            liens_video = [\"N/A\"]\n",
    "\n",
    "        # Afficher toutes les informations extraites dans la console\n",
    "        print(f\"\\nExtraction des informations pour le lien {lien}\")\n",
    "\n",
    "        # Retourner les informations, les liens PDF et les liens audio\n",
    "        info = [\n",
    "            titre,\n",
    "            description,\n",
    "            resume,\n",
    "            telechargements,\n",
    "            likes,\n",
    "            avis,\n",
    "            ecoutes,\n",
    "            vues,\n",
    "            nombre_de_pages,\n",
    "            type_de_chantier,\n",
    "            type_de_batiment,\n",
    "            lots_impliques,\n",
    "            sujets_techniques_associes,\n",
    "            etape_de_chantier,\n",
    "            contributeur,\n",
    "            lien, \n",
    "            ', '.join(liens_video),  # Liens vidéo\n",
    "            infos_video[0],  # Titre vidéo\n",
    "            infos_video[1],  # Description vidéo\n",
    "            infos_video[2],  # Propriétaire vidéo\n",
    "            infos_video[3],  # Vues vidéo\n",
    "            infos_video[4],  # Nombre de commentaires vidéo\n",
    "            infos_video[5],  # Date de publication\n",
    "            infos_video[6],  # Nombre de likes vidéo\n",
    "        ]\n",
    "        \n",
    "        return info, liens_pdf, liens_audio, liens_video\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Une erreur est survenue lors de l'extraction des informations : {str(e)}\")\n",
    "        return None, [], [], []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonction pour récupérer les liens de la section spécifique pour chaque page\n",
    "\n",
    "La fonction `recuperer_liens_de_page` extrait les liens de la section spécifique d'une page web en analysant le contenu HTML avec BeautifulSoup. Elle cible uniquement les liens présents dans une section de mise en page prédéfinie.\n",
    "\n",
    "Paramètres :\n",
    "\n",
    "- `recuperer_liens_de_page` : Instance du WebDriver Selenium utilisée pour accéder à la page et obtenir son contenu HTML.\n",
    "Retour :\n",
    "\n",
    "Renvoie une liste de liens complets (URL) extraits de la section spécifique de la page. Si une erreur survient, elle renvoie une liste vide.\n",
    "\n",
    "Étapes de l'extraction :\n",
    "\n",
    "- Récupère le code source HTML de la page et le parse avec BeautifulSoup.\n",
    "- Cible une section spécifique définie par des classes CSS particulières (`div.grid.gap-20.grid-cols-2.sm\\\\:grid-cols-3.xl\\\\:gap-30)`).\n",
    "- Extrait tous les liens (`<a href=\"...\">`) de cette section et les transforme en URLs complètes avec `urljoin`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour récupérer les liens de la section spécifique pour chaque page\n",
    "def recuperer_liens_de_page(navigateur):\n",
    "    # Extrait les liens de la section spécifique d'une page web, en utilisant Selenium et BeautifulSoup pour l'analyse.\n",
    "\n",
    "    try:\n",
    "        # Extraire le HTML de la page\n",
    "        page_html = navigateur.page_source\n",
    "        soup = bs(page_html, 'html.parser')\n",
    "        # Utilise BeautifulSoup pour parser le contenu HTML de la page et faciliter l'extraction des données.\n",
    "\n",
    "        # Récupérer uniquement les liens dans la section spécifique\n",
    "        section = soup.select_one('div.grid.gap-20.grid-cols-2.sm\\\\:grid-cols-3.xl\\\\:gap-30')\n",
    "        liens = []\n",
    "        \n",
    "        if section:\n",
    "            # Récupérer tous les liens 'a' dans cette section spécifique\n",
    "            elements_liens = section.find_all('a', href=True)\n",
    "            for element in elements_liens:\n",
    "                url = element['href']\n",
    "                full_url = urljoin(navigateur.current_url, url)  # Construire l'URL complète\n",
    "                liens.append(full_url)\n",
    "                # Ajoute chaque URL complète à la liste des liens extraits.\n",
    "\n",
    "        return liens  # Retourner uniquement les liens de cette page\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la récupération des liens sur la page : {str(e)}\")\n",
    "        return []\n",
    "        # En cas d'erreur, retourne une liste vide pour éviter l'interruption du processus.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonction pour gérer la pagination et récupérer les liens de toutes les pages\n",
    "\n",
    "La fonction `extraire_tous_les_liens` gère la pagination d'une section de résultats pour extraire les liens présents sur chaque page. Elle utilise une boucle pour avancer d’une page à l’autre jusqu’à la dernière page disponible.\n",
    "\n",
    "Paramètres :\n",
    "\n",
    "- `navigateur` : Instance du WebDriver Selenium, utilisée pour naviguer et interagir avec la page.\n",
    "\n",
    "Retour :\n",
    "\n",
    "Renvoie une liste contenant tous les liens extraits de toutes les pages disponibles.\n",
    "\n",
    "Processus de pagination :\n",
    "\n",
    "- Charge chaque page et attend que la section de résultats soit visible.\n",
    "- Utilise la fonction `recuperer_liens_de_page` pour extraire les liens de la page courante et les ajoute à la liste `tous_liens`.\n",
    "- Tente de trouver le bouton \"Suivant\" pour passer à la page suivante :\n",
    "- Si le bouton est désactivé (fin de la pagination), arrête la boucle.\n",
    "- Sinon, navigue vers le lien de la page suivante et continue le processus.\n",
    "- Arrête la boucle en cas de dépassement du temps d'attente ou si le bouton \"Suivant\" est introuvable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour gérer la pagination et récupérer les liens de toutes les pages\n",
    "def extraire_tous_les_liens(navigateur):\n",
    "    # Parcourt toutes les pages d'une section paginée pour extraire les liens en utilisant une boucle\n",
    "    # de pagination. \n",
    "\n",
    "    tous_liens = []  # Liste pour stocker tous les liens extraits\n",
    "    page = 1  # Compteur de page pour le suivi\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            # Attendre que la section de résultats soit chargée avant de récupérer les liens\n",
    "            WebDriverWait(navigateur, 40).until(\n",
    "                EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'div.grid.gap-20.grid-cols-2.sm\\\\:grid-cols-3.xl\\\\:gap-30'))\n",
    "            )\n",
    "            print(f\"Résultats de la page {page} visibles\")\n",
    "\n",
    "            # Extraire les liens de cette page spécifique\n",
    "            liens_page = recuperer_liens_de_page(navigateur)\n",
    "            tous_liens.extend(liens_page)  # Ajouter les liens de cette page à la liste totale\n",
    "            print(f\"Liens récupérés pour la page {page} : {liens_page}\")\n",
    "\n",
    "            # Passer à la page suivante si possible\n",
    "            try:\n",
    "                bouton_suivant = WebDriverWait(navigateur, 20).until(\n",
    "                    EC.presence_of_element_located((By.CSS_SELECTOR, 'nav.flex.gap-10 a:last-child'))\n",
    "                )\n",
    "                if \"disabled\" in bouton_suivant.get_attribute(\"class\"):\n",
    "                    print(\"Dernière page atteinte.\")\n",
    "                    break  # Arrêter la boucle si le bouton 'Suivant' est désactivé (dernière page)\n",
    "                else:\n",
    "                    lien_suivant = bouton_suivant.get_attribute('href')\n",
    "                    navigateur.get(lien_suivant)  # Charger la page suivante\n",
    "                    page += 1  # Incrémenter le numéro de page\n",
    "                    time.sleep(3)  # Attendre que la page se charge\n",
    "\n",
    "            except (TimeoutException, NoSuchElementException):\n",
    "                print(\"Erreur : Impossible de trouver ou cliquer sur le bouton 'Suivant'.\")\n",
    "                break  # Arrêter la boucle si le bouton 'Suivant' n'est pas trouvé\n",
    "\n",
    "        except TimeoutException:\n",
    "            print(f\"Temps d'attente dépassé pour la page {page}\")\n",
    "            break  # Arrêter la boucle si le chargement de la page prend trop de temps\n",
    "\n",
    "    return tous_liens  # Retourner tous les liens récupérés\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonction principale pour extraire les données après avoir récupéré tous les liens\n",
    "\n",
    "La fonction `extraire_donnees_apres_liens` gère l’extraction complète des données et des fichiers associés (PDF, audio) pour une liste de liens. Elle procède en extrayant les informations et les fichiers à partir de chaque lien, puis en exportant les données vers Excel et en téléchargeant les fichiers collectés.\n",
    "\n",
    "Paramètres :\n",
    "\n",
    "- `navigateur` : Instance du WebDriver Selenium utilisée pour charger et interagir avec chaque page.\n",
    "- `tous_liens` : Liste de liens URL à partir desquels les informations et les fichiers seront extraits.\n",
    "\n",
    "Retour :\n",
    "\n",
    "Aucun retour, mais la fonction génère des sorties comme un fichier Excel contenant les données extraites et des téléchargements de fichiers PDF et audio.\n",
    "\n",
    "Processus :\n",
    "\n",
    "Pour chaque lien de la liste `tous_liens` :\n",
    "\n",
    "- Utilise `recuperer_info_de_page` pour extraire les informations de la page ainsi que les liens vers les fichiers PDF et audio.\n",
    "- Ajoute les informations extraites à `toutes_donnees`, les liens PDF à `tous_liens_pdf`, et les liens audio à `tous_liens_audio`.\n",
    "- Exporte les données extraites dans un fichier Excel si `toutes_donnees`contient des enregistrements.\n",
    "- Télécharge tous les fichiers PDF et audio collectés si les listes correspondantes contiennent des liens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction principale pour extraire les données après avoir récupéré tous les liens\n",
    "def extraire_donnees_apres_liens(navigateur, tous_liens):\n",
    "    # Parcourt chaque lien pour extraire les informations et les fichiers associés,\n",
    "    # puis exporte les données vers Excel et télécharge les fichiers PDF et audio collectés.\n",
    "\n",
    "    toutes_donnees = []  # Liste pour stocker les informations extraites de chaque lien\n",
    "    tous_liens_pdf = []  # Liste pour collecter les liens PDF à télécharger\n",
    "    tous_liens_audio = []  # Liste pour collecter les liens audio à télécharger\n",
    "\n",
    "    for lien in tous_liens:\n",
    "        # Récupérer les informations et les fichiers associés pour chaque lien\n",
    "        info, liens_pdf, liens_audio, _ = recuperer_info_de_page(lien, navigateur)\n",
    "        \n",
    "        if info:\n",
    "            toutes_donnees.append(info)  # Ajouter les informations extraites à la liste des données\n",
    "\n",
    "        tous_liens_pdf.extend(liens_pdf)  # Ajouter les liens PDF extraits à la liste totale\n",
    "        tous_liens_audio.extend(liens_audio)  # Ajouter les liens audio extraits à la liste totale\n",
    "\n",
    "    # Exporter toutes les données extraites vers un fichier Excel\n",
    "    if toutes_donnees:\n",
    "        print(f\"{len(toutes_donnees)} enregistrements prêts à être exportés.\")\n",
    "        exporter_vers_excel(toutes_donnees)  # Appel de la fonction pour exporter les données dans un fichier Excel\n",
    "\n",
    "    # Télécharger les fichiers PDF collectés\n",
    "    if tous_liens_pdf:\n",
    "        nombre_pdfs = telecharger_pdfs(tous_liens_pdf)\n",
    "        print(f\"Nombre total de PDF téléchargés : {nombre_pdfs}\")\n",
    "\n",
    "    # Télécharger les fichiers audio collectés\n",
    "    if tous_liens_audio:\n",
    "        nombre_audios = telecharger_audio(tous_liens_audio)\n",
    "        print(f\"Nombre total d'audios téléchargés : {nombre_audios}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonction pour effectuer une recherche pour un thème donné\n",
    "\n",
    "Ce code effectue une recherche pour plusieurs thèmes sur le site de Proreno, extrait les liens et données associés, puis exporte les résultats dans un fichier Excel. La structure de traitement garantit que chaque recherche est effectuée de manière séquentielle pour chaque thème, en enregistrant les données et en téléchargeant les fichiers associés.\n",
    "\n",
    "- Fonction `effectuer_recherche` : Exécute une recherche sur le site en utilisant Selenium pour interagir avec la barre de recherche et le bouton de validation.\n",
    "\n",
    "Paramètres :\n",
    "\n",
    "- `navigateur` : Instance du WebDriver Selenium utilisée pour charger la page et interagir avec les éléments.\n",
    "- `theme` : Thème de recherche, une chaîne de caractères saisie dans la barre de recherche.\n",
    "\n",
    "Bloc principal :\n",
    "\n",
    "- Initialise le navigateur avec les options spécifiées.\n",
    "- Définit les thèmes à rechercher et le chemin pour stocker les données.\n",
    "- Supprime le fichier Excel précédent pour éviter tout conflit de données.\n",
    "\n",
    "Pour chaque thème de la liste `themes` :\n",
    "\n",
    "Utilise `effectuer_recherche` pour chercher le thème sur le site.\n",
    "Utilise `extraire_tous_les_liens` pour récupérer tous les liens de la section paginée de résultats.\n",
    "Utilise `extraire_donnees_apres_liens` pour extraire et enregistrer les données en fonction des liens.\n",
    "Ferme le navigateur après la fin du traitement pour chaque thème."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour effectuer une recherche pour un thème donné\n",
    "def effectuer_recherche(navigateur, theme):\n",
    "    # Charge la page d'accueil, localise la barre de recherche, et effectue une recherche pour le thème donné.\n",
    "\n",
    "    try:\n",
    "        navigateur.get(\"https://www.proreno.fr/\")\n",
    "        # Charger la page d'accueil de Proreno\n",
    "\n",
    "        barre_recherche = WebDriverWait(navigateur, 20).until(\n",
    "            EC.visibility_of_element_located((By.ID, 'autocomplete-input'))\n",
    "        )\n",
    "        # Localiser la barre de recherche et attendre qu'elle soit visible\n",
    "\n",
    "        barre_recherche.clear()  # Effacer la barre de recherche avant de saisir le nouveau thème\n",
    "        time.sleep(1)  # Pause pour une meilleure stabilité du script\n",
    "        barre_recherche.send_keys(theme)  # Saisir le thème dans la barre de recherche\n",
    "\n",
    "        bouton_recherche = WebDriverWait(navigateur, 20).until(\n",
    "            EC.element_to_be_clickable((By.CSS_SELECTOR, 'button[data-v-89374d9f][class*=btn-rounded][class*=search-btn]'))\n",
    "        )\n",
    "        # Localiser le bouton de recherche et attendre qu'il soit cliquable\n",
    "\n",
    "        navigateur.execute_script(\"arguments[0].click();\", bouton_recherche)\n",
    "        # Utiliser JavaScript pour cliquer sur le bouton de recherche\n",
    "        time.sleep(3)  # Attendre que la page des résultats se charge\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la recherche pour le thème '{theme}' : {str(e)}\")\n",
    "        # Afficher un message d'erreur en cas de problème lors de la recherche\n",
    "\n",
    "# Initialiser le navigateur\n",
    "navigateur = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "# Liste des thèmes à rechercher\n",
    "themes = [\"Transition environnementale\", \"Métiers de l'encadrement\"]\n",
    "\n",
    "# Chemin vers le fichier Excel de données\n",
    "excel_path = os.path.join(dossier_excel, 'data_proreno.xlsx')\n",
    "\n",
    "# Supprimer l'ancien fichier Excel s'il existe avant de traiter le premier thème\n",
    "if os.path.exists(excel_path):\n",
    "   os.remove(excel_path)\n",
    "\n",
    "# Boucle principale pour traiter les thèmes\n",
    "try:\n",
    "    for theme in themes:\n",
    "        effectuer_recherche(navigateur, theme)\n",
    "        # Effectuer la recherche pour le thème actuel\n",
    "\n",
    "        # Étape 1: Récupérer tous les liens pour toutes les pages\n",
    "        tous_liens = extraire_tous_les_liens(navigateur)\n",
    "        print(f\"Nombre total de liens récupérés pour le thème '{theme}' : {len(tous_liens)}\")\n",
    "\n",
    "        # Étape 2: Extraire les données après avoir récupéré tous les liens\n",
    "        extraire_donnees_apres_liens(navigateur, tous_liens)\n",
    "\n",
    "finally:\n",
    "    navigateur.quit()\n",
    "    print(\"Navigateur fermé.\")\n",
    "    # Fermer le navigateur après l'exécution de toutes les recherches et extractions de données\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
