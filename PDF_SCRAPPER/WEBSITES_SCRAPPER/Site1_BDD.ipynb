{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importation des bibliothèques nécessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation du module Selenium qui permet d'automatiser le contrôle des navigateurs web.\n",
    "from selenium import webdriver\n",
    "\n",
    "# Importation de 'By' de Selenium, utilisé pour localiser les éléments sur une page web (par exemple par ID, nom, classe, etc.).\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# Importation de WebDriverWait de Selenium, utilisé pour spécifier des attentes explicites pour un élément (ex. attendre que l'élément soit visible).\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "\n",
    "# Importation de expected_conditions de Selenium, contient des conditions prédéfinies (ex. attendre que l'élément soit cliquable ou visible).\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# Importation de TimeoutException de Selenium, utilisé pour gérer les exceptions d'attente (lorsqu'un élément n'apparaît pas dans un délai imparti).\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "\n",
    "# Importation du module BeautifulSoup de la bibliothèque bs4, utilisé pour le parsing (analyse et extraction) de contenu HTML et XML.\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "# Importation de la bibliothèque requests pour effectuer des requêtes HTTP (obtenir le contenu d'une page web, envoyer des formulaires, etc.).\n",
    "import requests\n",
    "\n",
    "# Importation du module os, utilisé pour interagir avec le système d'exploitation (accès aux fichiers, navigation dans les répertoires, etc.).\n",
    "import os\n",
    "\n",
    "# Importation de la bibliothèque time, utilisée pour gérer les délais d'attente ou effectuer des pauses dans le script.\n",
    "import time\n",
    "\n",
    "# Importation de la bibliothèque pymongo et de la classe MongoClient, utilisée pour interagir avec une base de données MongoDB.\n",
    "from pymongo import MongoClient\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connexion à la base de données\n",
    "\n",
    "Ce script établit une connexion à une base de données MongoDB hébergée sur MongoDB Atlas.\n",
    "Il sélectionne ensuite une base de données spécifique et une collection.\n",
    "MongoDB est une base de données NoSQL qui stocke les données sous forme de documents JSON.\n",
    "\n",
    "- **Connexion** : Utilise l'URI pour se connecter au cluster MongoDB en ligne.\n",
    "- **Base de données** : Une base de données MongoDB est sélectionnée pour stocker les informations.\n",
    "- **Collection** : Une collection appelée `Tp-demain` est créée ou sélectionnée. C'est dans cette collection que les documents seront stockés.\n",
    "\n",
    "Prérequis :\n",
    "- Avoir `pymongo` installé (`pip install pymongo`)\n",
    "- Disposer d'un cluster MongoDB avec les identifiants de connexion appropriés\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connexion au cluster MongoDB Atlas en utilisant l'URI de connexion\n",
    "client = MongoClient('mongodb+srv://serginemengue46:tu3uF7Ap0g2RQDou@cluster0.7xuvx.mongodb.net')\n",
    "\n",
    "# Sélection de la base de données souhaitée\n",
    "db = client['nom_de_ta_base']  # À remplacer par le nom de ta base de données\n",
    "\n",
    "# Accès à la collection spécifique dans la base de données\n",
    "collection = db['Tp-demain']  # Utilisation de la collection nommée 'Tp-demain'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Options du navigateur\n",
    "Ce bloc de code configure les options du navigateur Chrome pour gérer les pop-ups et notifications indésirables.\n",
    "Les options de navigation permettent de contrôler divers aspects du comportement du navigateur lors de l'automatisation avec Selenium.\n",
    "\n",
    "- **Objectif** : Empêcher les notifications pop-up (souvent des demandes de permissions ou des publicités) de perturber l'automatisation.\n",
    "- **Approche** : Utiliser `ChromeOptions` pour définir des préférences spécifiques, comme la désactivation des notifications.\n",
    "\n",
    "Étapes : \n",
    "1. Créer une instance `ChromeOptions` pour personnaliser le comportement du navigateur.\n",
    "2. Ajouter une préférence (`prefs`) pour désactiver les notifications.\n",
    "3. Associer les préférences au navigateur via `add_experimental_option`.\n",
    "\n",
    "Avantages :\n",
    "- Évite les interruptions lors du scraping ou des tests automatisés.\n",
    "- Assure un fonctionnement fluide du script.\n",
    "\n",
    "Prérequis :\n",
    "- Avoir Selenium installé (`pip install selenium`)\n",
    "- Utiliser le bon pilote pour Chrome (par exemple, `chromedriver` compatible avec la version de Chrome installée)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation des options de configuration pour le navigateur Chrome\n",
    "options = webdriver.ChromeOptions()  # Crée un objet pour définir les options de démarrage de Chrome\n",
    "\n",
    "# Désactiver les notifications (pop-ups) qui pourraient interrompre l'exécution du script\n",
    "prefs = {\"profile.default_content_setting_values.notifications\": 2}\n",
    "\n",
    "# Ajout des préférences à l'objet options\n",
    "options.add_experimental_option(\"prefs\", prefs)  # Applique les préférences pour désactiver les notifications\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialisation du navigateur web\n",
    "\n",
    "Ce bloc initialise le navigateur Chrome en tenant compte des options spécifiées précédemment.\n",
    "Il permet de lancer une instance du navigateur Chrome configurée pour les besoins spécifiques de l'automatisation.\n",
    "\n",
    "- **Objectif** : Démarrer Chrome avec des options personnalisées (par exemple, désactivation des notifications).\n",
    "- **Contexte** : Utilisé dans les scripts Selenium pour s'assurer que le navigateur fonctionne selon les paramètres définis.\n",
    "- **Approche** : Créer un objet `driver` qui pilote Chrome, en passant l'objet `options` contenant les préférences configurées.\n",
    "\n",
    "**Étapes** :\n",
    "1. Initialiser le navigateur avec `webdriver.Chrome()` et y associer les options.\n",
    "2. Le `driver` est l'interface principale pour interagir avec le navigateur (ouverture de page, clics, etc.).\n",
    "3. S'assurer que le `chromedriver` correspondant à la version de Chrome est présent dans le PATH.\n",
    "\n",
    "**Avantages** :\n",
    "- Le navigateur se lance automatiquement avec les paramètres préconfigurés, évitant les interventions manuelles.\n",
    "- Réduit le risque de problèmes d'interactions (par exemple, fenêtres contextuelles intempestives)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialisation du navigateur Chrome avec les options personnalisées définies précédemment\n",
    "driver = webdriver.Chrome(options=options)  # Crée une instance du navigateur avec les préférences définies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création de répertoires locaux\n",
    "\n",
    "Ce bloc de code crée des répertoires (dossiers) locaux pour stocker les fichiers image et PDF.\n",
    "Il utilise le module `os` pour créer les dossiers nécessaires s'ils n'existent pas déjà.\n",
    "\n",
    "- **Objectif** : Organiser le stockage local des données en créant des dossiers séparés pour les images et les fichiers PDF.\n",
    "- **Contexte** : Lors du téléchargement ou de l'extraction de fichiers (par exemple, web scraping), il est crucial de les structurer dans des répertoires distincts.\n",
    "- **Approche** :\n",
    "  1. Utiliser la fonction `os.makedirs` pour créer des répertoires.\n",
    "  2. Activer l'option `exist_ok=True` pour éviter les erreurs si les dossiers existent déjà.\n",
    "  \n",
    "- **Avantages** :\n",
    "  - Évite les erreurs lors de l'exécution si les répertoires sont déjà présents.\n",
    "  - Assure que les fichiers téléchargés ou générés sont bien organisés, ce qui facilite l'accès et la maintenance.\n",
    "\n",
    "**Prérequis** :\n",
    "- Le module `os` est inclus par défaut dans Python, il n'y a donc pas besoin d'installation supplémentaire.\n",
    "- Les droits d'accès en écriture doivent être accordés sur le répertoire courant.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Créer le dossier 'Images' s'il n'existe pas déjà\n",
    "os.makedirs('Images', exist_ok=True)  # Stockage des fichiers image\n",
    "\n",
    "# Créer le dossier 'PDFs' s'il n'existe pas déjà\n",
    "os.makedirs('PDFs', exist_ok=True)  # Stockage des fichiers PDF\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Génération de fichier unique\n",
    "\n",
    "Cette fonction permet de générer un nom de fichier unique si un fichier portant le même nom existe déjà dans le dossier spécifié.\n",
    "Elle est utile pour éviter les conflits de noms lors de la sauvegarde de fichiers dans un répertoire.\n",
    "\n",
    "- **Objectif** : Prévenir l'écrasement de fichiers existants en créant une version unique du nom.\n",
    "- **Contexte** : Lors du téléchargement ou de la génération de fichiers, il est courant de rencontrer des fichiers portant le même nom. Cette fonction génère un nouveau nom avec un compteur incrémenté.\n",
    "  \n",
    "**Approche** :\n",
    "1. Séparer le nom de fichier et son extension (par exemple, `rapport.pdf` devient `rapport` et `.pdf`).\n",
    "2. Vérifier si le fichier existe déjà dans le dossier spécifié.\n",
    "3. Si oui, ajouter un compteur incrémental (`_1`, `_2`, etc.) jusqu'à ce que le nom devienne unique.\n",
    "4. Retourner le nom de fichier modifié.\n",
    "\n",
    "- **Avantages** :\n",
    "  - Évite la perte de données en prévenant l'écrasement de fichiers existants.\n",
    "  - Génère automatiquement des versions distinctes de chaque fichier (par exemple, `rapport.pdf`, `rapport_1.pdf`, `rapport_2.pdf`).\n",
    "\n",
    "**Prérequis** :\n",
    "- Le module `os` doit être importé (`import os`).\n",
    "- Le dossier de destination (`folder`) doit exister.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Fonction pour générer un nom de fichier unique si un fichier portant le même nom existe déjà dans le dossier\n",
    "def get_unique_filename(folder, filename):\n",
    "    # Sépare le nom de base du fichier et son extension (par exemple, 'rapport.pdf' devient 'rapport' et '.pdf')\n",
    "    base, extension = os.path.splitext(filename)\n",
    "\n",
    "    # Initialise le compteur à 1 pour créer des versions uniques (ex. 'rapport_1.pdf')\n",
    "    counter = 1\n",
    "\n",
    "    # Le nom de fichier de départ est le même que l'original\n",
    "    new_filename = filename\n",
    "\n",
    "    # Boucle tant qu'un fichier portant le même nom existe dans le dossier spécifié\n",
    "    while os.path.exists(os.path.join(folder, new_filename)):\n",
    "        # Génère un nouveau nom en ajoutant un suffixe numérique (ex. 'rapport_1.pdf')\n",
    "        new_filename = f\"{base}_{counter}{extension}\"\n",
    "        counter += 1  # Incrémente le compteur pour la prochaine vérification\n",
    "\n",
    "    # Retourne le nom de fichier unique généré\n",
    "    return new_filename\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Téléchargement d'images\n",
    "\n",
    "Cette fonction télécharge une image à partir d'une URL spécifiée, l'enregistre localement et stocke son lien d'accès dans une base de données MongoDB.\n",
    "Elle est conçue pour gérer le téléchargement d'images de manière sécurisée tout en évitant les conflits de noms de fichiers.\n",
    "\n",
    "- **Objectif** : Télécharger une image depuis une URL, s'assurer que le nom du fichier est unique, et enregistrer le lien local dans MongoDB.\n",
    "- **Contexte** : Utilisé lors de l'extraction de données ou du web scraping pour stocker et référencer localement des images associées à des documents dans MongoDB.\n",
    "  \n",
    "- **Approche** :\n",
    "  1. Générer un nom de fichier unique à l'aide de `get_unique_filename`.\n",
    "  2. Envoyer une requête HTTP pour télécharger l'image.\n",
    "  3. Sauvegarder le contenu de l'image localement dans le dossier `Images`.\n",
    "  4. Créer un lien relatif vers le fichier image (par exemple, `Images/nom_image.jpg`).\n",
    "  5. Mettre à jour le document MongoDB correspondant en ajoutant le lien d'accès dans le champ `images_paths`.\n",
    "\n",
    "- **Avantages** :\n",
    "  - Évite l'écrasement des fichiers en local grâce à la gestion automatique des noms.\n",
    "  - Associe chaque image à un document MongoDB spécifique pour une récupération simplifiée.\n",
    "  \n",
    "Prérequis :\n",
    "- Le module `requests` pour envoyer des requêtes HTTP doit être installé (`pip install requests`).\n",
    "- Le module `pymongo` doit être configuré pour interagir avec MongoDB (`pip install pymongo`).\n",
    "- Le dossier `Images` doit exister ou être créé au préalable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Fonction pour télécharger une image depuis une URL et stocker le lien d'accès dans MongoDB\n",
    "def download_image(url, filename, doc_id):\n",
    "    try:\n",
    "        # Générer un nom de fichier unique s'il existe déjà dans le dossier 'Images'\n",
    "        filename = get_unique_filename('Images', filename)\n",
    "\n",
    "        # Envoyer une requête HTTP pour télécharger le contenu de l'image\n",
    "        response = requests.get(url)\n",
    "\n",
    "        # Vérifier si la requête a réussi (code 200)\n",
    "        if response.status_code == 200:\n",
    "            # Créer le chemin complet où l'image sera enregistrée localement\n",
    "            full_path = os.path.join('Images', filename)\n",
    "\n",
    "            # Enregistrer le contenu de l'image dans un fichier local en mode binaire ('wb')\n",
    "            with open(full_path, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "            print(f\"Image téléchargée avec succès : {full_path}\")\n",
    "\n",
    "            # Générer un lien d'accès relatif pour l'image à stocker dans MongoDB\n",
    "            link_access = f\"Images/{filename}\"\n",
    "\n",
    "            # Mettre à jour le document MongoDB correspondant (identifié par `doc_id`) en ajoutant le lien d'accès dans le champ `images_paths`\n",
    "            collection.update_one(\n",
    "                {'_id': doc_id},  # Sélectionner le document par son identifiant unique\n",
    "                {'$push': {'images_paths': link_access}}  # Ajouter le lien dans le champ `images_paths` (type liste)\n",
    "            )\n",
    "            print(f\"Lien d'accès de l'image enregistré dans MongoDB pour le document {doc_id}: {link_access}\")\n",
    "        else:\n",
    "            print(f\"Échec du téléchargement de l'image : {filename}\")\n",
    "\n",
    "    # Gérer les exceptions (erreurs) survenant lors du téléchargement ou de la sauvegarde de l'image\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors du téléchargement de l'image {filename} : {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Téléchargement de PDF\n",
    "\n",
    "Cette fonction télécharge un fichier PDF à partir d'une URL donnée, l'enregistre localement dans le dossier `PDFs`, \n",
    "et stocke le chemin d'accès relatif dans un document MongoDB correspondant.\n",
    "\n",
    "- **Objectif** : Télécharger un fichier PDF depuis une URL, s'assurer que le nom du fichier est unique, et enregistrer le chemin d'accès dans MongoDB.\n",
    "- **Contexte** : Utilisé dans des applications où les fichiers PDF doivent être téléchargés, stockés localement, et référencés dans une base de données MongoDB.\n",
    "  \n",
    "- **Approche** :\n",
    "  1. Générer un nom de fichier unique dans le dossier `PDFs` pour éviter tout conflit de noms.\n",
    "  2. Envoyer une requête HTTP pour récupérer le PDF.\n",
    "  3. Sauvegarder le fichier PDF localement en mode binaire.\n",
    "  4. Créer un lien d'accès relatif pour stocker la référence dans la base de données MongoDB.\n",
    "  5. Mettre à jour le document MongoDB avec ce lien, en l'ajoutant dans le champ `pdf_paths`.\n",
    "\n",
    "- **Avantages** :\n",
    "  - Évite l'écrasement des fichiers PDF existants en gérant automatiquement les noms de fichiers.\n",
    "  - Facilite la gestion des fichiers PDF en associant chaque document téléchargé à un enregistrement MongoDB spécifique.\n",
    "\n",
    "Prérequis :\n",
    "- Le module `requests` doit être installé (`pip install requests`).\n",
    "- Le module `pymongo` doit être configuré pour interagir avec MongoDB (`pip install pymongo`).\n",
    "- Le dossier `PDFs` doit exister ou être créé au préalable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Fonction pour télécharger un fichier PDF depuis une URL et enregistrer son lien d'accès dans MongoDB\n",
    "def download_pdf(url, filename, doc_id):\n",
    "    try:\n",
    "        # Générer un nom de fichier unique s'il existe déjà dans le dossier 'PDFs'\n",
    "        filename = get_unique_filename('PDFs', filename)  # Gérer les conflits de noms pour les fichiers PDF\n",
    "\n",
    "        # Envoyer une requête HTTP pour récupérer le contenu du PDF\n",
    "        response = requests.get(url)\n",
    "\n",
    "        # Vérifier si la requête a réussi (code 200)\n",
    "        if response.status_code == 200:\n",
    "            # Créer le chemin complet où le PDF sera enregistré localement\n",
    "            full_path = os.path.join('PDFs', filename)\n",
    "\n",
    "            # Enregistrer le contenu du PDF dans un fichier local en mode binaire ('wb')\n",
    "            with open(full_path, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "            print(f\"PDF téléchargé avec succès : {full_path}\")\n",
    "\n",
    "            # Générer un lien d'accès relatif pour le PDF à stocker dans MongoDB\n",
    "            link_access = f\"PDFs/{filename}\"\n",
    "\n",
    "            # Mettre à jour le document MongoDB correspondant (identifié par `doc_id`) en ajoutant le lien d'accès dans le champ `pdf_paths`\n",
    "            collection.update_one(\n",
    "                {'_id': doc_id},  # Sélectionner le document par son identifiant unique\n",
    "                {'$push': {'pdf_paths': link_access}}  # Ajouter le lien dans le champ `pdf_paths` (type liste)\n",
    "            )\n",
    "            print(f\"Lien d'accès du PDF enregistré dans MongoDB pour le document {doc_id}: {link_access}\")\n",
    "        else:\n",
    "            # Si le téléchargement échoue (code de statut différent de 200), afficher un message d'erreur\n",
    "            print(f\"Échec du téléchargement du PDF : {filename}\")\n",
    "\n",
    "    # Gérer les exceptions (erreurs) survenant lors du téléchargement ou de la sauvegarde du PDF\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors du téléchargement du PDF {filename} : {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enregistrement de données par thème dans la BDD\n",
    "\n",
    "Cette fonction enregistre un nouveau thème dans une base de données MongoDB avec ses données associées.\n",
    "Elle permet d'organiser les informations extraites sous forme de documents structurés, chaque thème étant stocké individuellement.\n",
    "\n",
    "- **Objectif** : Créer un document MongoDB pour chaque thème, y ajouter les informations extraites et les chemins de fichiers (images et PDFs).\n",
    "- **Contexte** : Utilisé pour stocker des informations catégorisées par thème, comme les détails d'articles, vidéos, et documents associés à partir d'une extraction de données.\n",
    "\n",
    "- **Approche** :\n",
    "  1. Créer un document initial avec le champ `theme` et une liste vide `Données`.\n",
    "  2. Insérer ce document dans MongoDB et récupérer l'ID du document (`theme_doc_id`).\n",
    "  3. Ajouter les informations de chaque article, vidéo, et document associé à ce thème.\n",
    "  4. Mettre à jour le document en ajoutant chaque ligne de données à la liste `Données`.\n",
    "\n",
    "- **Avantages** :\n",
    "  - Organise les informations de manière structurée pour chaque thème dans MongoDB.\n",
    "  - Facile à rechercher et à exploiter pour des requêtes ou des analyses ultérieures.\n",
    "\n",
    "Prérequis :\n",
    "- Le module `pymongo` doit être installé (`pip install pymongo`).\n",
    "- La connexion à MongoDB et la collection MongoDB (`collection`) doivent être définies.\n",
    "\n",
    "Paramètres :\n",
    "- `theme` (str) : Le nom du thème à enregistrer.\n",
    "- `data` (list) : Une liste de tuples contenant les informations extraites pour chaque lien. Chaque tuple suit cette structure :\n",
    "  - `(line, images, pdfs)` :\n",
    "    - `line` (list) : Détail des informations extraites pour chaque lien.\n",
    "    - `images` (list) : Chemins d'accès des images associées.\n",
    "    - `pdfs` (list) : Chemins d'accès des fichiers PDF associés.\n",
    "\n",
    "Retour :\n",
    "- L'ID du document inséré (`theme_doc_id`) en cas de succès.\n",
    "- `None` en cas d'erreur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def save_theme_to_mongodb(theme, data):\n",
    "    try:\n",
    "        # Créer un nouveau document avec le champ 'theme' et une liste vide pour stocker les données associées\n",
    "        theme_doc = {\n",
    "            'theme': theme,  # Nom du thème\n",
    "            'Données': []  # Liste vide qui contiendra les informations associées à ce thème\n",
    "        }\n",
    "\n",
    "        # Insérer le document dans MongoDB et récupérer son identifiant unique\n",
    "        theme_doc_id = collection.insert_one(theme_doc).inserted_id\n",
    "\n",
    "        # Afficher le message de confirmation pour l'insertion réussie du nouveau document\n",
    "        print(f\"Nouveau document pour le thème '{theme}' inséré avec ID {theme_doc_id}\")\n",
    "\n",
    "        # Parcourir chaque élément de la liste `data` pour ajouter les informations au document\n",
    "        # `line` contient les détails de chaque lien, `images` contient les chemins des images, et `pdfs` contient les chemins des PDFs.\n",
    "        for line, images, pdfs in data:\n",
    "            # Mettre à jour le document MongoDB avec les informations extraites et les chemins d'accès associés\n",
    "            collection.update_one(\n",
    "                {'_id': theme_doc_id},  # Sélectionner le document par son ID unique\n",
    "                {'$push': {  # Utiliser l'opérateur `$push` pour ajouter un nouvel élément dans la liste `Données`\n",
    "                    'Données': {  # Chaque entrée représente un élément du thème, avec divers attributs détaillés\n",
    "                        'Titre': line[0],  # Titre de l'élément\n",
    "                        'A_retenir': line[1],  # Points à retenir\n",
    "                        'Sommaire': line[2],  # Sommaire de l'article ou de la vidéo\n",
    "                        'Texte': line[3],  # Contenu textuel principal\n",
    "                        'Source': line[4],  # Source de l'information\n",
    "                        'Catégorie': line[5],  # Catégorie (par exemple, actualité, tutoriel, etc.)\n",
    "                        'Thématique': line[6],  # Thème associé (peut différer du thème principal)\n",
    "                        'Nb_consultation': line[7],  # Nombre de consultations ou de vues\n",
    "                        'Nb_evaluation_positive': line[8],  # Nombre de mentions positives\n",
    "                        'Lien': line[9],  # Lien vers l'article ou la vidéo\n",
    "                        'Lien_video': line[10],  # Lien vers la vidéo si disponible\n",
    "                        'Titre_video': line[11],  # Titre de la vidéo si pertinent\n",
    "                        'Nom_chaine': line[12],  # Nom de la chaîne ou du créateur de contenu\n",
    "                        'Likes': line[13],  # Nombre de likes sur la vidéo ou l'article\n",
    "                        'Vues': line[14],  # Nombre de vues de la vidéo\n",
    "                        'Date_publication': line[15],  # Date de publication de l'élément\n",
    "                        'Description': line[16],  # Brève description de l'élément\n",
    "                        'Nombre_de_commentaires': line[17],  # Nombre de commentaires si applicable\n",
    "                        'images_paths': images,  # Chemins d'accès des images associées à l'élément\n",
    "                        'pdf_paths': pdfs  # Chemins d'accès des fichiers PDF associés\n",
    "                    }\n",
    "                }}\n",
    "            )\n",
    "\n",
    "        # Retourner l'identifiant du document inséré en cas de succès\n",
    "        return theme_doc_id\n",
    "\n",
    "    # Gérer les exceptions et afficher un message d'erreur en cas de problème\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de l'enregistrement du thème '{theme}' dans MongoDB : {str(e)}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Défilement automatique \n",
    "\n",
    "Cette fonction gère le défilement automatique à l'intérieur d'un pop-up vidéo sur une page web.\n",
    "Elle est conçue pour permettre d'accéder à des contenus cachés ou chargés dynamiquement dans un conteneur de type pop-up.\n",
    "\n",
    "- **Objectif** : Effectuer un défilement (scroll) vers le bas dans un conteneur pop-up de vidéos afin de révéler des éléments supplémentaires.\n",
    "- **Contexte** : Utilisé dans des projets d'automatisation web avec Selenium, par exemple pour accéder à des vidéos ou du contenu affiché dans une fenêtre modale (pop-up).\n",
    "  \n",
    "- **Approche** :\n",
    "  1. Localiser le conteneur pop-up à l'aide d'un sélecteur CSS spécifique (`tp-yt-iron-overlay-backdrop`).\n",
    "  2. Utiliser JavaScript pour faire défiler verticalement le contenu du conteneur.\n",
    "  3. Gérer les erreurs potentielles (par exemple, si le pop-up n'apparaît pas).\n",
    "\n",
    "- **Avantages** :\n",
    "  - Permet de révéler et d'interagir avec des éléments qui ne sont pas visibles au chargement initial de la page.\n",
    "  - Utile pour les pages qui chargent du contenu de manière asynchrone ou utilisent des fenêtres modales.\n",
    "\n",
    "Prérequis :\n",
    "- Le module `selenium` doit être installé (`pip install selenium`).\n",
    "- Le driver du navigateur doit être initialisé et connecté à la page avant d'appeler cette fonction (`driver` doit être défini).\n",
    "- Un sélecteur CSS correct pour identifier le conteneur pop-up.\n",
    "\n",
    "Retour :\n",
    "- Affiche un message de confirmation si le défilement est réussi.\n",
    "- Gère et affiche les erreurs en cas d'échec du défilement.\n",
    "\n",
    "Cas d'utilisation :\n",
    "- Permet de charger et d'extraire des données supplémentaires cachées dans des pop-ups.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Fonction pour effectuer un défilement dans un pop-up de vidéos sur la page\n",
    "def scroll_in_video_popup():\n",
    "    try:\n",
    "        # Attendre jusqu'à 10 secondes que le conteneur du pop-up de vidéos apparaisse sur la page\n",
    "        popup_container = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, \"tp-yt-iron-overlay-backdrop\"))  # Localiser l'élément avec un sélecteur CSS\n",
    "        )\n",
    "\n",
    "        # Exécuter un script JavaScript pour faire défiler le contenu du pop-up vers le bas\n",
    "        driver.execute_script(\"arguments[0].scrollTop = arguments[0].scrollHeight;\", popup_container)\n",
    "        \n",
    "        # Afficher un message de confirmation une fois le défilement terminé\n",
    "        print(\"Scroll dans le pop-up des vidéos effectué.\")\n",
    "\n",
    "    # Gérer les exceptions en cas de problème avec la recherche de l'élément ou le défilement\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors du scroll dans le pop-up des vidéos : {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Intéraction avec le  pop-up de cookies\n",
    "\n",
    "Cette fonction interagit avec un pop-up de cookies dans une fenêtre vidéo, fait défiler le pop-up si nécessaire, \n",
    "et clique sur le bouton \"Tout refuser\" pour refuser les cookies. Elle est utilisée pour automatiser l'interaction \n",
    "avec les notifications de cookies qui apparaissent dans les vidéos, afin de poursuivre l'automatisation sans interruptions.\n",
    "\n",
    "- **Objectif** : Refuser les cookies dans un pop-up de vidéos pour éviter les interruptions pendant l'automatisation.\n",
    "- **Contexte** : Utilisé lors de l'automatisation de la navigation sur des sites web, notamment ceux qui affichent des vidéos dans des pop-ups avec des politiques de cookies.\n",
    "  \n",
    "- **Approche** :\n",
    "  1. Effectuer un défilement dans le pop-up de vidéos pour s'assurer que le bouton de refus des cookies est visible.\n",
    "  2. Attendre que le bouton \"Tout refuser\" soit cliquable.\n",
    "  3. Cliquer sur le bouton \"Tout refuser\" pour fermer le pop-up.\n",
    "  4. Gérer les erreurs et les cas où le bouton n'apparaît pas.\n",
    "\n",
    "- **Avantages** :\n",
    "  - Évite les interruptions pendant les interactions automatisées avec les vidéos.\n",
    "  - Assure une continuité dans l'exécution du script même si le bouton de cookies n'est pas trouvé.\n",
    "\n",
    "Prérequis :\n",
    "- Le module `selenium` doit être installé (`pip install selenium`).\n",
    "- Le driver du navigateur doit être initialisé (`driver`) et configuré pour accéder à la page cible.\n",
    "\n",
    "Cas d'utilisation :\n",
    "- Refuser les cookies de manière automatique sur des plateformes vidéo avant de procéder à d'autres actions d'automatisation.\n",
    "\n",
    "Retour :\n",
    "- Affiche un message de confirmation en cas de succès.\n",
    "- Gère les erreurs si le bouton de cookies n'est pas trouvé.\n",
    "\n",
    "Améliorations potentielles :\n",
    "- Adapter le sélecteur XPath pour différents langages ou variantes de boutons (par exemple, \"Reject All\" en anglais).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Fonction pour refuser les cookies dans un pop-up de vidéos\n",
    "def refuse_video_cookies():\n",
    "    try:\n",
    "        # Faire défiler le contenu du pop-up vidéo pour révéler les boutons (si nécessaire)\n",
    "        scroll_in_video_popup()  # Appel à la fonction `scroll_in_video_popup` pour gérer le défilement\n",
    "\n",
    "        # Temporisation de 2 secondes pour laisser le temps au défilement de s'effectuer\n",
    "        time.sleep(2)\n",
    "\n",
    "        # Attendre jusqu'à 5 secondes que le bouton \"Tout refuser\" soit cliquable\n",
    "        refuse_button = WebDriverWait(driver, 5).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, \"//button//span[text()='Tout refuser']\"))  # Sélectionner le bouton par XPath basé sur le texte \"Tout refuser\"\n",
    "        )\n",
    "\n",
    "        # Cliquer sur le bouton \"Tout refuser\" en utilisant JavaScript pour éviter les interférences de couche CSS\n",
    "        driver.execute_script(\"arguments[0].click();\", refuse_button)\n",
    "        \n",
    "        # Afficher un message de confirmation une fois que les cookies ont été refusés\n",
    "        print(\"Cookies des vidéos refusés avec succès.\")\n",
    "\n",
    "    # Gérer le cas où le bouton de refus n'est pas trouvé dans le temps imparti\n",
    "    except TimeoutException:\n",
    "        print(\"Aucun bouton de cookies trouvé dans la vidéo, passage à l'étape suivante.\")\n",
    "    \n",
    "    # Gérer toute autre erreur éventuelle lors de l'interaction avec le bouton de refus des cookies\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors du clic sur 'Tout refuser' dans les vidéos : {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Afficher la totalité de la description de la vidéo\n",
    "\n",
    "Cette fonction clique automatiquement sur le bouton \"Afficher plus\" sur une page YouTube pour révéler la description complète d'une vidéo.\n",
    "Elle est utilisée pour étendre la section de description qui est initialement tronquée, permettant ainsi d'accéder à l'intégralité du contenu.\n",
    "\n",
    "- **Objectif** : Interagir avec le bouton \"Afficher plus\" pour déplier la section de description d'une vidéo.\n",
    "- **Contexte** : Utilisé dans les scripts de scraping ou d'automatisation YouTube où la description complète est nécessaire pour une analyse plus approfondie.\n",
    "  \n",
    "- **Approche** :\n",
    "  1. Localiser le bouton \"Afficher plus\" à l'aide d'un sélecteur XPath spécifique.\n",
    "  2. Attendre que le bouton soit cliquable avant d'interagir avec lui.\n",
    "  3. Cliquer sur le bouton à l'aide de JavaScript pour éviter les restrictions de clic.\n",
    "  4. Gérer les exceptions si le bouton n'est pas trouvé ou si d'autres erreurs surviennent.\n",
    "\n",
    "- **Avantages** :\n",
    "  - Permet d'accéder à des informations supplémentaires qui ne sont pas visibles par défaut.\n",
    "  - Facilite l'extraction des descriptions complètes pour un traitement ou une analyse plus approfondie.\n",
    "\n",
    "Prérequis :\n",
    "- Le module `selenium` doit être installé (`pip install selenium`).\n",
    "- Le driver du navigateur (`driver`) doit être initialisé et configuré pour accéder à la page cible.\n",
    "- Le sélecteur XPath doit être ajusté en fonction de la structure de la page.\n",
    "\n",
    "Cas d'utilisation :\n",
    "- Extraction des descriptions complètes des vidéos YouTube pour des projets de web scraping ou d'analyse de contenu.\n",
    "\n",
    "Retour :\n",
    "- Affiche un message de confirmation en cas de succès.\n",
    "- Gère et affiche les erreurs en cas d'échec du clic ou d'absence du bouton.\n",
    "\n",
    "Améliorations potentielles :\n",
    "- Ajouter des temporisations ou des vérifications pour les variations de structure de la page.\n",
    "- Adapter le sélecteur XPath pour différentes langues ou variantes de boutons.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Fonction pour cliquer sur le bouton \"Afficher plus\" et révéler la description complète d'une vidéo YouTube\n",
    "def click_show_more_button():\n",
    "    try:\n",
    "        # Localiser le bouton \"Afficher plus\" sur la page YouTube et attendre qu'il devienne cliquable\n",
    "        show_more_button = WebDriverWait(driver, 15).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, '/html/body/ytd-app/div[1]/ytd-page-manager/ytd-watch-flexy/div[5]/div[1]/div/div[2]/ytd-watch-metadata/div/div[4]/div[1]/div/ytd-text-inline-expander/tp-yt-paper-button[1]'))\n",
    "        )\n",
    "\n",
    "        # Cliquer sur le bouton \"Afficher plus\" en utilisant JavaScript pour contourner les restrictions CSS\n",
    "        driver.execute_script(\"arguments[0].click();\", show_more_button)\n",
    "\n",
    "        # Afficher un message de confirmation une fois le clic effectué\n",
    "        print(\"Le bouton 'Afficher plus' a été cliqué pour révéler la description complète.\")\n",
    "\n",
    "    # Gérer le cas où le bouton n'est pas trouvé dans le délai imparti\n",
    "    except TimeoutException:\n",
    "        print(\"Aucun bouton 'Afficher plus' trouvé.\")\n",
    "    \n",
    "    # Gérer toute autre erreur éventuelle lors de l'interaction avec le bouton \"Afficher plus\"\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors du clic sur 'Afficher plus' : {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Défilement automatique \n",
    "\n",
    "Cette fonction effectue un défilement automatique vers le bas de la page jusqu'à ce que tout le contenu soit chargé.\n",
    "Elle est utile pour les pages à chargement dynamique (par exemple, des pages avec un contenu infini), \n",
    "où le contenu supplémentaire est révélé au fur et à mesure que l'utilisateur défile vers le bas.\n",
    "\n",
    "- **Objectif** : Dérouler automatiquement la page jusqu'à la fin pour charger tout le contenu.\n",
    "- **Contexte** : Utilisé lors de l'extraction de données (web scraping) sur des sites avec des listes déroulantes infinies ou du contenu paginé qui nécessite un défilement pour être affiché.\n",
    "  \n",
    "- **Approche** :\n",
    "  1. Récupérer la hauteur actuelle de la page (`scrollHeight`).\n",
    "  2. Effectuer un défilement vers le bas de la page.\n",
    "  3. Attendre que le contenu soit chargé avant de vérifier la nouvelle hauteur de la page.\n",
    "  4. Répéter l'opération jusqu'à ce que la hauteur de la page n'augmente plus (fin de la page atteinte).\n",
    "\n",
    "- **Avantages** :\n",
    "  - Permet de charger dynamiquement tout le contenu d'une page sans intervention manuelle.\n",
    "  - Utile pour les pages qui ne chargent pas tout le contenu initialement (par exemple, les réseaux sociaux ou les boutiques en ligne).\n",
    "\n",
    "Prérequis :\n",
    "- Le module `selenium` doit être installé (`pip install selenium`).\n",
    "- Le driver du navigateur (`driver`) doit être initialisé et configuré pour accéder à la page cible.\n",
    "\n",
    "Cas d'utilisation :\n",
    "- Web scraping de sites à contenu infini (ex. Twitter, Facebook).\n",
    "- Défilement sur des sites d'actualités ou de commerce en ligne avec des sections de chargement dynamique.\n",
    "\n",
    "Retour :\n",
    "- Arrête le défilement lorsqu'il n'y a plus de nouveau contenu à charger.\n",
    "- Ne retourne aucune valeur.\n",
    "\n",
    "Améliorations potentielles :\n",
    "- Ajouter un compteur de boucles pour limiter le nombre de défilements et éviter les boucles infinies.\n",
    "- Adapter le temps d'attente entre les défilements selon la vitesse de chargement du site.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Fonction pour faire défiler automatiquement la page jusqu'à la fin\n",
    "def scroll_to_bottom():\n",
    "    # Récupérer la hauteur actuelle de la page\n",
    "    last_height = driver.execute_script(\"return document.documentElement.scrollHeight\")  # Obtenir la hauteur initiale de la page\n",
    "\n",
    "    # Début de la boucle de défilement\n",
    "    while True:\n",
    "        # Dérouler la page jusqu'à la fin actuelle de la page\n",
    "        driver.execute_script(\"window.scrollTo(0, document.documentElement.scrollHeight);\")\n",
    "\n",
    "        # Attendre 2 secondes pour laisser le contenu se charger après le défilement\n",
    "        WebDriverWait(driver, 2).until(\n",
    "            EC.presence_of_element_located((By.TAG_NAME, 'body'))  # Vérifier que le corps de la page est bien présent\n",
    "        )\n",
    "\n",
    "        # Obtenir la nouvelle hauteur de la page après le défilement\n",
    "        new_height = driver.execute_script(\"return document.documentElement.scrollHeight\")\n",
    "\n",
    "        # Si la nouvelle hauteur est égale à l'ancienne, cela signifie que le bas de la page a été atteint\n",
    "        if new_height == last_height:\n",
    "            break  # Sortir de la boucle si plus de nouveau contenu n'est chargé\n",
    "\n",
    "        # Mettre à jour la hauteur de la page pour le prochain cycle de défilement\n",
    "        last_height = new_height\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction des informations de la vidéo\n",
    "\n",
    "Cette fonction extrait les détails d'une vidéo YouTube à partir de son URL. Elle collecte le titre, le nom de la chaîne, \n",
    "le nombre de vues, le nombre de likes, la date de publication, la description et le nombre de commentaires.\n",
    "\n",
    "- **Objectif** : Extraire les informations clés d'une vidéo YouTube pour analyse ou archivage.\n",
    "- **Contexte** : Utilisé dans les projets d'automatisation ou de scraping pour collecter des informations détaillées sur une vidéo donnée.\n",
    "  \n",
    "- **Approche** :\n",
    "  1. Accéder à l'URL de la vidéo.\n",
    "  2. Gérer le pop-up de cookies et dérouler la section de description si nécessaire.\n",
    "  3. Dérouler la page pour s'assurer que tous les éléments sont chargés.\n",
    "  4. Extraire les détails de la vidéo : titre, nom de la chaîne, nombre de vues, nombre de likes, date de publication, description, et nombre de commentaires.\n",
    "  5. Gérer les exceptions en fournissant des valeurs par défaut lorsque les éléments ne sont pas trouvés.\n",
    "\n",
    "- **Avantages** :\n",
    "  - Permet de capturer des informations précises sur les vidéos YouTube de manière automatisée.\n",
    "  - Gère les cas où certains éléments ne sont pas disponibles, garantissant une continuité dans le processus.\n",
    "\n",
    "Prérequis :\n",
    "- Le module `selenium` doit être installé (`pip install selenium`).\n",
    "- Le driver du navigateur (`driver`) doit être initialisé et configuré pour accéder à la page cible.\n",
    "\n",
    "Cas d'utilisation :\n",
    "- Analyse des vidéos YouTube pour créer des rapports ou des bases de données.\n",
    "- Extraction de métadonnées pour évaluer la popularité et l'engagement des vidéos.\n",
    "\n",
    "Retour :\n",
    "- Un tuple contenant le titre, le nom de la chaîne, le nombre de likes, le nombre de vues, la date de publication, la description, et le nombre de commentaires.\n",
    "- Valeurs par défaut ('N/A') en cas d'échec de l'extraction.\n",
    "\n",
    "Améliorations potentielles :\n",
    "- Adapter les sélecteurs pour prendre en charge différentes langues ou mises à jour de la structure de la page YouTube.\n",
    "- Ajouter des vérifications pour des informations supplémentaires (par exemple, les tags ou les liens dans la description).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Fonction pour extraire les détails d'une vidéo YouTube à partir de son URL\n",
    "def get_video_details(video_url):\n",
    "    try:\n",
    "        # Ouvrir l'URL de la vidéo\n",
    "        driver.get(video_url)\n",
    "\n",
    "        # Attendre 5 secondes pour s'assurer que la page est bien chargée\n",
    "        time.sleep(5)\n",
    "\n",
    "        # Refuser les cookies si le pop-up est présent\n",
    "        try:\n",
    "            refuse_video_cookies()\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors du refus des cookies : {str(e)}\")\n",
    "\n",
    "        # Cliquer sur le bouton \"Afficher plus\" pour révéler la description complète\n",
    "        try:\n",
    "            click_show_more_button()\n",
    "        except TimeoutException:\n",
    "            print(\"Le bouton 'Afficher plus' n'a pas été trouvé. Passer à la suite.\")\n",
    "\n",
    "        # Faire défiler jusqu'en bas de la page pour charger les commentaires et autres informations\n",
    "        scroll_to_bottom()\n",
    "\n",
    "        # Extraction du titre de la vidéo\n",
    "        try:\n",
    "            title = WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, \"h1.style-scope.ytd-watch-metadata\"))  # Sélecteur CSS pour le titre\n",
    "            ).text\n",
    "        except TimeoutException:\n",
    "            title = 'Titre non disponible'\n",
    "\n",
    "        # Extraction du nom de la chaîne\n",
    "        try:\n",
    "            channel_name = driver.find_element(By.CSS_SELECTOR, \"a.yt-simple-endpoint.style-scope.yt-formatted-string\").text\n",
    "        except Exception:\n",
    "            channel_name = 'Chaîne non disponible'\n",
    "\n",
    "        # Extraction du nombre de likes\n",
    "        try:\n",
    "            likes = driver.find_element(By.XPATH, '/html/body/ytd-app/div[1]/ytd-page-manager/ytd-watch-flexy/div[5]/div[1]/div/div[2]/ytd-watch-metadata/div/div[2]/div[2]/div/div/ytd-menu-renderer/div[1]/segmented-like-dislike-button-view-model/yt-smartimation/div/div/like-button-view-model/toggle-button-view-model/button-view-model/button/div[2]').text\n",
    "        except Exception:\n",
    "            likes = \"Likes non disponibles\"\n",
    "\n",
    "        # Extraction du nombre de vues\n",
    "        try:\n",
    "            views = driver.find_element(By.XPATH, \"(//yt-formatted-string[@id='info']//span[@dir='auto'])[1]\").text\n",
    "        except Exception:\n",
    "            views = 'Vues non disponibles'\n",
    "\n",
    "        # Extraction de la date de publication\n",
    "        try:\n",
    "            publication_date = driver.find_element(By.XPATH, \"(//yt-formatted-string[@id='info']//span[@dir='auto'])[3]\").text\n",
    "        except Exception:\n",
    "            publication_date = 'Date non disponible'\n",
    "\n",
    "        # Extraction de la description de la vidéo\n",
    "        try:\n",
    "            description = driver.find_element(By.CSS_SELECTOR, \"span.yt-core-attributed-string.yt-core-attributed-string--white-space-pre-wrap\").text\n",
    "        except Exception:\n",
    "            description = 'Description non disponible'\n",
    "\n",
    "        # Vérification de l'état des commentaires (désactivés ou non)\n",
    "        try:\n",
    "            # Chercher un élément indiquant que les commentaires sont désactivés\n",
    "            commentaire_desactive_element = driver.find_element(By.XPATH, \"//yt-formatted-string[contains(text(), 'Les commentaires sont désactivés')]\")\n",
    "            if commentaire_desactive_element:\n",
    "                comment_count = \"N/A\"\n",
    "                print(\"Les commentaires sont désactivés sur cette vidéo.\")\n",
    "        except Exception:\n",
    "            # Si le message n'est pas trouvé, on essaie d'extraire le nombre de commentaires\n",
    "            try:\n",
    "                comment_count = driver.find_element(By.XPATH, '/html/body/ytd-app/div[1]/ytd-page-manager/ytd-watch-flexy/div[5]/div[1]/div/div[2]/ytd-comments/ytd-item-section-renderer/div[1]/ytd-comments-header-renderer/div[1]/div[1]/h2/yt-formatted-string').text\n",
    "            except Exception:\n",
    "                comment_count = \"N/A\"\n",
    "                print(\"Commentaires non disponibles\")\n",
    "\n",
    "        # Retourner les informations extraites sous forme de tuple\n",
    "        return title, channel_name, likes, views, publication_date, description, comment_count\n",
    "\n",
    "    # Gérer les erreurs globales lors de la récupération des détails de la vidéo\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la récupération des détails de la vidéo : {str(e)}\")\n",
    "        return 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction des liens de vidéos\n",
    "\n",
    "Cette fonction extrait les liens de vidéos à partir d'un iframe YouTube intégré sur une page.\n",
    "Les iframes (inline frames) sont souvent utilisés pour intégrer du contenu YouTube dans d'autres pages web. Cette fonction accède à l'URL de l'iframe, \n",
    "attend que les liens vidéo soient visibles, puis les collecte pour les retourner sous forme de liste.\n",
    "\n",
    "- **Objectif** : Collecter tous les liens de vidéos présents dans un iframe YouTube intégré.\n",
    "- **Contexte** : Utilisé pour extraire automatiquement les liens de vidéos recommandées ou associées dans un iframe YouTube affiché sur une autre page.\n",
    "  \n",
    "- **Approche** :\n",
    "  1. Accéder à l'URL de l'iframe avec `driver.get`.\n",
    "  2. Attendre que les éléments vidéo soient visibles sur la page.\n",
    "  3. Récupérer les éléments correspondant aux liens de vidéos (`ytp-impression-link`).\n",
    "  4. Extraire l'attribut `href` de chaque élément et les stocker dans une liste.\n",
    "  5. Retourner la liste des liens de vidéos ou une liste vide en cas d'erreur.\n",
    "\n",
    "- **Avantages** :\n",
    "  - Permet de collecter facilement les liens de vidéos associées dans un iframe sans naviguer sur la page principale de YouTube.\n",
    "  - Utile pour automatiser la découverte de vidéos recommandées sur des sites tiers.\n",
    "\n",
    "Prérequis :\n",
    "- Le module `selenium` doit être installé (`pip install selenium`).\n",
    "- Le driver du navigateur (`driver`) doit être initialisé et configuré pour accéder à la page cible.\n",
    "\n",
    "Paramètres :\n",
    "- `iframe_src` (str) : L'URL de l'iframe YouTube intégré, à partir duquel les liens de vidéos seront extraits.\n",
    "\n",
    "Retour :\n",
    "- Une liste de chaînes de caractères (`hrefs`) représentant les liens de vidéos trouvés.\n",
    "- Une liste vide (`[]`) en cas d'erreur ou si aucun lien n'est trouvé.\n",
    "\n",
    "Améliorations potentielles :\n",
    "- Ajouter des vérifications pour s'assurer que les liens correspondent bien à des vidéos YouTube.\n",
    "- Gérer les différents types de contenus dans les iframes (par exemple, playlists ou vidéos individuelles).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Fonction pour extraire les liens vidéo présents dans un iframe YouTube\n",
    "def get_video_links_from_iframe(iframe_src):\n",
    "    # Accéder à l'URL de l'iframe contenant les vidéos\n",
    "    driver.get(iframe_src)\n",
    "\n",
    "    try:\n",
    "        # Attendre que les liens de vidéos soient visibles dans l'iframe (jusqu'à 10 secondes)\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.visibility_of_element_located((By.CLASS_NAME, 'ytp-impression-link'))  # Vérifier que l'élément avec la classe `ytp-impression-link` est visible\n",
    "        )\n",
    "\n",
    "        # Récupérer tous les éléments correspondant aux liens de vidéos dans l'iframe\n",
    "        video_links = driver.find_elements(By.CLASS_NAME, 'ytp-impression-link')\n",
    "\n",
    "        # Extraire les attributs `href` (liens) de chaque élément récupéré\n",
    "        hrefs = [link.get_attribute('href') for link in video_links]\n",
    "\n",
    "        # Retourner la liste des liens de vidéos\n",
    "        return hrefs\n",
    "\n",
    "    # Gérer les exceptions lors de l'accès ou de l'extraction des liens dans l'iframe\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la récupération des liens vidéo : {str(e)}\")\n",
    "        return []  # Retourner une liste vide en cas d'erreur\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction et organisation de toutes les informations\n",
    "\n",
    "Cette fonction extrait et organise les informations détaillées d'une page web à partir de son lien. Elle collecte les informations principales \n",
    "comme le titre, le texte, la source, la catégorie, les thèmes associés, les vidéos intégrées, les images, et les fichiers PDF. \n",
    "Les informations sont ensuite structurées pour être enregistrées dans une base de données MongoDB.\n",
    "\n",
    "- **Objectif** : Extraire les informations d'une page de contenu et les organiser pour un stockage dans MongoDB.\n",
    "- **Contexte** : Utilisé pour des projets de scraping ou d'archivage de contenus à partir de sites web comme des articles, des tutoriels, ou des ressources éducatives.\n",
    "  \n",
    "- **Approche** :\n",
    "  1. Accéder à la page web et extraire le contenu avec BeautifulSoup.\n",
    "  2. Extraire les informations clés (titre, texte, source, catégories, etc.).\n",
    "  3. Télécharger les ressources multimédias (images et PDFs) et enregistrer les chemins d'accès.\n",
    "  4. Organiser les données dans une liste structurée, incluant le titre de la vidéo, le nombre de vues, les likes, la date de publication, etc.\n",
    "  5. Retourner les informations sous forme de liste structurée avec les chemins d'images et de PDFs.\n",
    "\n",
    "- **Avantages** :\n",
    "  - Automatise l'extraction des informations détaillées d'une page web.\n",
    "  - Télécharge et organise les ressources multimédias pour un archivage local.\n",
    "\n",
    "Prérequis :\n",
    "- Le module `requests` pour récupérer le contenu de la page (`pip install requests`).\n",
    "- Le module `beautifulsoup4` pour analyser le contenu HTML (`pip install beautifulsoup4`).\n",
    "- Le module `pymongo` pour interagir avec MongoDB (`pip install pymongo`).\n",
    "\n",
    "Paramètres :\n",
    "- `link` (str) : L'URL de la page à extraire.\n",
    "- `doc_id` (ObjectId) : L'ID du document MongoDB associé pour enregistrer les chemins des fichiers téléchargés.\n",
    "\n",
    "Retour :\n",
    "- Une liste structurée (`line`) contenant toutes les informations extraites.\n",
    "- Les chemins d'accès des images (`images`) et des fichiers PDF (`pdfs`).\n",
    "- Valeurs par défaut (`None`, `[]`, `[]`) en cas d'erreur.\n",
    "\n",
    "Améliorations potentielles :\n",
    "- Adapter les sélecteurs CSS ou XPath selon la structure HTML de la page cible.\n",
    "- Ajouter des fonctionnalités pour capturer d'autres types de contenus (par exemple, vidéos hébergées localement).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Fonction pour extraire les informations d'une page web, y compris les vidéos, images et PDFs associés\n",
    "def get_info(link, doc_id):\n",
    "    try:\n",
    "        # Envoyer une requête pour récupérer le contenu de la page\n",
    "        page = requests.get(link)\n",
    "        soup = bs(page.content, 'html.parser')  # Analyser le contenu HTML avec BeautifulSoup\n",
    "\n",
    "        # Extraction du titre de la page\n",
    "        Titre = soup.find('h1', class_=\"pt-3 mb-3 mb-md-5 text-white text-center pb-md-5\")\n",
    "        Titre = Titre.string.strip() if Titre else 'N/A'  # Nettoyer le titre ou mettre 'N/A' s'il n'existe pas\n",
    "\n",
    "        # Extraction du texte principal de la page\n",
    "        Texte = soup.find('div', class_=\"module-section-item default-module-section-item\")\n",
    "        Texte_text = Texte.text.strip() if Texte else 'N/A'\n",
    "\n",
    "        # Extraction de la source de l'article\n",
    "        source = soup.find('div', class_=\"module-credits pt-3 mt-4\")\n",
    "        source_text = source.get_text(strip=True) if source else 'N/A'\n",
    "\n",
    "        # Extraction de la catégorie\n",
    "        categorie_div = soup.find('div', class_=\"mc-category d-flex justify-content-center\")\n",
    "        categorie = categorie_div.find('div', class_='mcc-tag').get_text(strip=True) if categorie_div else 'N/A'\n",
    "\n",
    "        # Extraction des thèmes associés\n",
    "        themes = soup.find('div', class_=\"tags-list\")\n",
    "        thematic_list = [span.get_text(strip=True) for span in themes.find_all('span')] if themes else 'N/A'\n",
    "\n",
    "        # Extraction de l'URL de la vidéo intégrée dans un iframe, le cas échéant\n",
    "        iframe_div = soup.find('div', class_='ratio ratio-16x9 mb-4')\n",
    "        lien_video_src = iframe_div.find('iframe').get('src', 'N/A') if iframe_div else 'N/A'\n",
    "\n",
    "        # Initialiser les valeurs par défaut pour les détails de la vidéo\n",
    "        lien_video, video_title, channel_name, likes, views, publication_date, description, comment_count = 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A'\n",
    "        \n",
    "        # Si une vidéo est présente, récupérer les détails de cette vidéo\n",
    "        if lien_video_src != 'N/A':\n",
    "            lien_video_list = get_video_links_from_iframe(lien_video_src)  # Extraire les liens vidéo depuis l'iframe\n",
    "            if lien_video_list:\n",
    "                lien_video = lien_video_list[0]  # Prendre le premier lien de la liste\n",
    "                video_title, channel_name, likes, views, publication_date, description, comment_count = get_video_details(lien_video)  # Extraire les détails de la vidéo\n",
    "\n",
    "        # Extraction et téléchargement des images de la page\n",
    "        module_section_item = soup.find('div', class_=\"module-section-item default-module-section-item\")\n",
    "        images = []\n",
    "        if module_section_item:\n",
    "            img_elements = module_section_item.find_all('img')\n",
    "            for index, img in enumerate(img_elements):\n",
    "                img_url = img.get('src')  # Récupérer l'URL de chaque image\n",
    "                if img_url:\n",
    "                    img_filename = f\"{Titre[:50]}_{index + 1}.jpg\"  # Générer un nom de fichier unique\n",
    "                    download_image(img_url, img_filename, doc_id)  # Télécharger l'image\n",
    "                    images.append(f\"images/{img_filename}\")  # Ajouter le chemin local de l'image\n",
    "\n",
    "        # Extraction du nombre de consultations de l'article\n",
    "        Nb_consultation = soup.find('span', id=\"mf-nb-views\")\n",
    "        Nb_consultation = Nb_consultation.string if Nb_consultation else 'N/A'\n",
    "\n",
    "        # Extraction du nombre d'évaluations positives\n",
    "        evaluation_span = soup.find('span', class_=\"ur-link\")\n",
    "        Nb_evaluation_positive = int(evaluation_span.text) if evaluation_span else 0\n",
    "\n",
    "        # Extraction des sections \"À retenir\" et \"Sommaire\"\n",
    "        A_retenir = []\n",
    "        Sommaire = []\n",
    "        divs = soup.find_all('div', class_=\"module-item-content\")\n",
    "\n",
    "        # Si des sections sont trouvées, les extraire\n",
    "        if divs:\n",
    "            first_div = divs[0]\n",
    "            p_elements = first_div.find_all('p')\n",
    "            if p_elements:\n",
    "                A_retenir.extend([p.text.strip() for p in p_elements if p.text])  # Extraire les paragraphes de la première section\n",
    "\n",
    "            # Extraction des listes de la deuxième section (Sommaire)\n",
    "            if len(divs) > 1:\n",
    "                second_div = divs[1]\n",
    "                ul_element = second_div.find('ul')\n",
    "                if ul_element:\n",
    "                    li_elements = ul_element.find_all('li')\n",
    "                    Sommaire = [li.string for li in li_elements if li.string]\n",
    "                else:\n",
    "                    Sommaire = 'N/A'\n",
    "            else:\n",
    "                Sommaire = 'N/A'\n",
    "\n",
    "        # Extraction et téléchargement des fichiers PDF associés\n",
    "        aller_plus_loin_div = soup.find('div', class_=\"encadre encadre-allerPlusLoin\")\n",
    "        pdfs = []\n",
    "        if aller_plus_loin_div:\n",
    "            content_html_div = aller_plus_loin_div.find('div', class_=\"content content-html\")\n",
    "            if content_html_div:\n",
    "                ul_element = content_html_div.find('ul')\n",
    "                if ul_element:\n",
    "                    li_elements = ul_element.find_all('li')\n",
    "                    for li in li_elements:\n",
    "                        a_tag = li.find('a')\n",
    "                        if a_tag and a_tag.get('href').endswith('.pdf'):\n",
    "                            pdf_url = a_tag.get('href')\n",
    "                            if not pdf_url.startswith('http'):\n",
    "                                pdf_url = 'https://tpdemain.com' + pdf_url\n",
    "                            pdf_filename = f\"{Titre[:50]}_{os.path.basename(pdf_url)}\"\n",
    "                            download_pdf(pdf_url, pdf_filename, doc_id)\n",
    "                            pdfs.append(f\"PDFs/{pdf_filename}\")  # Ajouter le chemin local du PDF\n",
    "\n",
    "        # Structurer toutes les informations extraites dans une liste\n",
    "        line = [\n",
    "            Titre,\n",
    "            ' '.join(A_retenir),\n",
    "            ' '.join(Sommaire),\n",
    "            Texte_text,\n",
    "            source_text,\n",
    "            categorie,\n",
    "            ', '.join(thematic_list) if thematic_list != 'N/A' else 'N/A',\n",
    "            Nb_consultation,\n",
    "            Nb_evaluation_positive,\n",
    "            link,\n",
    "            lien_video,\n",
    "            video_title,\n",
    "            channel_name,\n",
    "            likes,\n",
    "            views,\n",
    "            publication_date,\n",
    "            description,\n",
    "            comment_count,\n",
    "            images,\n",
    "            pdfs\n",
    "        ]\n",
    "\n",
    "        return line, images, pdfs\n",
    "\n",
    "    # Gérer les erreurs lors de l'extraction\n",
    "    except Exception as e:\n",
    "        print(f\"Une erreur est survenue lors de l'extraction des informations : {str(e)}\")\n",
    "        return None, [], []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping de toutes les pages pour chaque thème\n",
    "\n",
    "Cette fonction effectue un scraping de toutes les pages de résultats pour chaque thème donné sur le site \"https://tpdemain.com/ressources-pedagogiques/\".\n",
    "Elle recherche chaque thème, collecte tous les liens trouvés, puis extrait les informations détaillées de chaque lien avant de sauvegarder ces données dans MongoDB.\n",
    "\n",
    "- **Objectif** : Scraper le site pour récupérer toutes les ressources pédagogiques associées à chaque thème et les organiser dans des documents MongoDB.\n",
    "- **Contexte** : Utilisé pour automatiser la collecte de contenus sur des thèmes spécifiques (ex. \"construction bas carbone\", \"transition environnementale\").\n",
    "  \n",
    "- **Approche** :\n",
    "  1. Accéder à la page de recherche principale.\n",
    "  2. Pour chaque thème, effectuer une recherche en saisissant le thème dans la barre de recherche.\n",
    "  3. Récupérer tous les liens de la première page de résultats, puis parcourir toutes les pages suivantes.\n",
    "  4. Extraire les informations détaillées de chaque lien (titre, texte, fichiers multimédias, etc.).\n",
    "  5. Sauvegarder les données de chaque thème dans un document MongoDB distinct.\n",
    "\n",
    "- **Avantages** :\n",
    "  - Automatisation complète de la recherche et de l'extraction des données pour plusieurs thèmes.\n",
    "  - Organisation structurée des informations dans une base de données pour une exploitation ultérieure.\n",
    "\n",
    "Prérequis :\n",
    "- Le module `selenium` doit être installé (`pip install selenium`).\n",
    "- Le driver du navigateur (`driver`) doit être initialisé pour automatiser la navigation.\n",
    "- La connexion à MongoDB doit être configurée.\n",
    "\n",
    "Paramètres :\n",
    "- `themes` (list) : Liste des thèmes à rechercher (ex. [\"construction bas carbone\", \"transition environnementale\"]).\n",
    "\n",
    "Retour :\n",
    "- Les informations de chaque lien sont extraites et sauvegardées dans MongoDB.\n",
    "\n",
    "Améliorations potentielles :\n",
    "- Adapter la gestion des erreurs pour des pages de résultats avec des structures différentes.\n",
    "- Optimiser le temps de recherche en ajustant les temporisations (`WebDriverWait`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Fonction pour scraper toutes les pages associées aux thèmes donnés\n",
    "def scrape_all_pages(themes):\n",
    "    # Liste pour stocker les liens de chaque thème\n",
    "    links_list = []\n",
    "\n",
    "    try:\n",
    "        # Accéder à la page principale de recherche de ressources pédagogiques\n",
    "        driver.get(\"https://tpdemain.com/ressources-pedagogiques/\")\n",
    "\n",
    "        # Parcourir chaque thème spécifié dans la liste\n",
    "        for theme in themes:\n",
    "            try:\n",
    "                # Recharger la page de recherche avant chaque nouvelle requête\n",
    "                driver.get(\"https://tpdemain.com/ressources-pedagogiques/\")\n",
    "\n",
    "                # Rechercher et cliquer sur le bouton de recherche pour afficher la barre de recherche\n",
    "                toggle_button = WebDriverWait(driver, 20).until(\n",
    "                    EC.element_to_be_clickable((By.CLASS_NAME, 'search-input-toggler'))\n",
    "                )\n",
    "                driver.execute_script(\"arguments[0].click();\", toggle_button)\n",
    "                print(f\"Bouton de recherche cliqué pour le thème : {theme}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Erreur lors de la recherche du bouton de recherche pour le thème : {theme}. Exception : {e}\")\n",
    "\n",
    "            try:\n",
    "                # Localiser la barre de recherche, la vider et saisir le nom du thème\n",
    "                search_bar = WebDriverWait(driver, 20).until(\n",
    "                    EC.visibility_of_element_located((By.CSS_SELECTOR, 'form.app-search-form.form-group input.form-control'))\n",
    "                )\n",
    "                search_bar.clear()\n",
    "                search_bar.send_keys(theme)\n",
    "            except Exception as e:\n",
    "                print(f\"Barre de recherche non trouvée pour le thème : {theme}. Exception : {e}\")\n",
    "\n",
    "            try:\n",
    "                # Cliquer sur le bouton de recherche pour lancer la requête\n",
    "                search_button = WebDriverWait(driver, 20).until(\n",
    "                    EC.element_to_be_clickable((By.CSS_SELECTOR, 'form.app-search-form.form-group button'))\n",
    "                )\n",
    "                driver.execute_script(\"arguments[0].click();\", search_button)\n",
    "            except Exception as e:\n",
    "                print(f\"Bouton de recherche non trouvé pour le thème : {theme}. Exception : {e}\")\n",
    "\n",
    "            try:\n",
    "                # Attendre que les résultats de la recherche soient visibles\n",
    "                WebDriverWait(driver, 30).until(\n",
    "                    EC.visibility_of_element_located((By.CLASS_NAME, 'content-area'))\n",
    "                )\n",
    "                print(f\"Résultats de recherche trouvés pour le thème : {theme}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Résultats de recherche non trouvés pour le thème : {theme}. Exception : {e}\")\n",
    "\n",
    "            # Initialiser la liste de liens pour ce thème\n",
    "            links_list.clear()\n",
    "\n",
    "            # Début de la boucle pour parcourir toutes les pages de résultats\n",
    "            has_next_page = True\n",
    "            while has_next_page:\n",
    "                try:\n",
    "                    # Localiser la zone de contenu contenant les liens\n",
    "                    content_area = driver.find_element(By.CLASS_NAME, 'content-area')\n",
    "                    links = content_area.find_elements(By.TAG_NAME, 'a')\n",
    "\n",
    "                    # Ajouter chaque lien unique à la liste `links_list`\n",
    "                    for link in links:\n",
    "                        href = link.get_attribute('href')\n",
    "                        if href and href not in links_list:\n",
    "                            links_list.append(href)\n",
    "\n",
    "                    # Gestion de la pagination : identifier la page actuelle et la dernière page\n",
    "                    pagination_elements = driver.find_elements(By.CLASS_NAME, 'page-numbers')\n",
    "                    current_page_element = driver.find_element(By.CLASS_NAME, 'current')\n",
    "                    current_page = int(current_page_element.text)\n",
    "                    last_page = current_page\n",
    "\n",
    "                    # Parcourir tous les éléments de pagination pour déterminer la dernière page disponible\n",
    "                    for elem in pagination_elements:\n",
    "                        try:\n",
    "                            page_number = int(elem.text)\n",
    "                            if page_number > last_page:\n",
    "                                last_page = page_number\n",
    "                        except ValueError:\n",
    "                            continue\n",
    "\n",
    "                    # Si la page actuelle est la dernière, arrêter la boucle\n",
    "                    if current_page >= last_page:\n",
    "                        has_next_page = False\n",
    "                    else:\n",
    "                        # Cliquer sur le bouton \"Suivant\" pour passer à la page suivante\n",
    "                        next_button = driver.find_elements(By.CLASS_NAME, 'next')\n",
    "                        if next_button:\n",
    "                            driver.execute_script(\"arguments[0].click();\", next_button[0])\n",
    "                            WebDriverWait(driver, 30).until(\n",
    "                                EC.visibility_of_element_located((By.CLASS_NAME, 'content-area'))\n",
    "                            )\n",
    "                        else:\n",
    "                            has_next_page = False\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Erreur lors de la pagination pour le thème {theme} : {str(e)}\")\n",
    "                    has_next_page = False\n",
    "\n",
    "            # Liste pour stocker les données de chaque page du thème\n",
    "            all_data = []\n",
    "\n",
    "            # Parcourir tous les liens extraits pour récupérer les informations détaillées\n",
    "            for link in links_list:\n",
    "                # Extraire les informations de chaque lien\n",
    "                info, images, pdfs = get_info(link, None)  # Ne passe pas l'ID MongoDB ici\n",
    "                if info:\n",
    "                    all_data.append((info, images, pdfs))  # Ajouter les données extraites à la liste `all_data`\n",
    "\n",
    "            # Sauvegarder toutes les données extraites pour le thème dans MongoDB\n",
    "            save_theme_to_mongodb(theme, all_data)\n",
    "            print(f\"Données du thème '{theme}' sauvegardées dans MongoDB.\\n\")\n",
    "\n",
    "    finally:\n",
    "        # Fermer le navigateur une fois le scraping terminé\n",
    "        driver.quit()\n",
    "\n",
    "# Liste des thèmes à rechercher\n",
    "themes = [\n",
    "    \"construction bas carbone\",\n",
    "    \"Transition environnementale\"\n",
    "]\n",
    "\n",
    "# Lancer le scraping pour tous les thèmes spécifiés\n",
    "scrape_all_pages(themes)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
