{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importation des bibliothèques nécessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation de la bibliothèque BeautifulSoup, renommée ici en 'bs' pour faciliter son utilisation\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "# Importation de la bibliothèque 'os' pour interagir avec le système de fichiers et gérer les opérations liées aux chemins\n",
    "import os\n",
    "\n",
    "# Importation de la bibliothèque 'Workbook' pour créer et manipuler des fichiers Excel\n",
    "from openpyxl import Workbook\n",
    "\n",
    "# Importation de la bibliothèque Selenium pour automatiser le navigateur Web\n",
    "from selenium import webdriver\n",
    "\n",
    "# Importation de la classe 'By' de Selenium pour identifier les éléments HTML à travers différents sélecteurs (id, classe, nom, etc.)\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# Importation de la classe 'WebDriverWait' de Selenium pour implémenter une attente explicite jusqu'à ce qu'une condition soit remplie\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "\n",
    "# Importation de la classe 'expected_conditions' pour spécifier les conditions d'attente (ex: présence d'un élément sur la page)\n",
    "from selenium.webdriver.support import expected_conditions as EC \n",
    "\n",
    "# Importation de 'TimeoutException' pour gérer les exceptions liées aux dépassements de temps lors de l'attente d'un élément\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "\n",
    "# Importation de la bibliothèque 'time' pour gérer les pauses et temporisations dans l'exécution du script\n",
    "import time\n",
    "\n",
    "# Importation de la bibliothèque 'requests' pour effectuer des requêtes HTTP (GET, POST, etc.)\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création de répertoire\n",
    "\n",
    "Ce segment de code est utilisé pour initialiser deux répertoires dans le système de fichiers : `PDFs` et `Fichiers_Excel`.\n",
    "Le premier est destiné à stocker les fichiers PDF, et le second pour les fichiers Excel générés ou utilisés par le script.\n",
    "Cette étape garantit que les dossiers sont créés au début de l'exécution du programme, afin d'éviter toute erreur lors de la tentative de sauvegarde ou de manipulation de fichiers.\n",
    "\n",
    "**Objectif** :\n",
    "- Créer des répertoires spécifiques pour organiser et gérer les fichiers PDF et Excel générés par le script.\n",
    "- Prévenir les erreurs liées à l'absence de dossiers.\n",
    "\n",
    "**Prérequis** :\n",
    "- Avoir les permissions nécessaires pour créer des dossiers dans le répertoire courant.\n",
    "- Le module `os` est inclus dans Python par défaut, donc aucune installation supplémentaire n'est requise.\n",
    "\n",
    "**Explications détaillées** :\n",
    "- `os.makedirs(folder, exist_ok=True)` :\n",
    "  - **`folder`** : Spécifie le nom ou le chemin du répertoire à créer.\n",
    "  - **`exist_ok=True`** : Permet de ne pas générer d'erreur si le répertoire existe déjà. Cela empêche le programme de planter en cas de réexécution.\n",
    "\n",
    "**Avantages** :\n",
    "- **Robustesse** : Assure que les dossiers nécessaires existent avant tout traitement.\n",
    "- **Gestion facilitée** : Centralise le stockage des fichiers pour une récupération et une organisation plus simples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Utilisé pour stocker tous les fichiers PDF générés ou récupérés pendant l'exécution du programme\n",
    "pdf_folder = 'PDFs'\n",
    "\n",
    "# Création du dossier 'PDFs' s'il n'existe pas déjà.\n",
    "# 'exist_ok=True' permet d'éviter une erreur si le dossier est déjà présent dans le répertoire courant.\n",
    "os.makedirs(pdf_folder, exist_ok=True)\n",
    "\n",
    "\n",
    "# Ce dossier est utilisé pour stocker les fichiers Excel créés ou modifiés par le script\n",
    "excel_folder = 'Fichiers_Excel'\n",
    "\n",
    "# Création du dossier 'Fichiers_Excel' s'il n'existe pas déjà.\n",
    "# 'exist_ok=True' a le même effet qu'auparavant : il permet d'éviter une exception si le dossier existe déjà.\n",
    "os.makedirs(excel_folder, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refus de cookies\n",
    "\n",
    "Cette fonction `click_refuse_youtube_cookies(driver)` est conçue pour automatiser le processus de refus des cookies sur YouTube à l'aide de Selenium.\n",
    "Lorsqu'une fenêtre contextuelle de consentement apparaît, elle clique sur le bouton 'Tout refuser' pour éviter le stockage de cookies non désirés. \n",
    "\n",
    "**Objectif** :\n",
    "- Éviter l'enregistrement des cookies en refusant systématiquement toutes les options proposées par YouTube.\n",
    "\n",
    "**Contexte** :\n",
    "- Utilisé principalement dans des scripts de web scraping ou d'automatisation où l'on souhaite naviguer sur YouTube sans accepter les cookies.\n",
    "- Cette fonction est appelée chaque fois qu'une fenêtre de consentement apparaît, ce qui est typique lors de la première connexion à YouTube.\n",
    "\n",
    "**Approche** :\n",
    "1. Mettre en pause le script pendant 2 secondes pour laisser le temps à la page de se charger.\n",
    "2. Localiser le bouton 'Tout refuser' en utilisant son chemin XPath et attendre qu'il soit cliquable.\n",
    "3. Exécuter un clic JavaScript pour contourner les éventuels masques de superposition.\n",
    "4. Attendre que le bouton soit cliqué correctement.\n",
    "5. Gérer les exceptions en cas de problèmes (élément non trouvé, timeout, etc.).\n",
    "\n",
    "**Avantages** :\n",
    "- Assure que les cookies ne seront pas enregistrés sans le consentement de l'utilisateur.\n",
    "- Permet de continuer l'automatisation sans être interrompu par les fenêtres de consentement.\n",
    "\n",
    "**Prérequis** :\n",
    "- Le module `selenium` doit être installé (`pip install selenium`).\n",
    "- Le pilote correspondant au navigateur utilisé (`chromedriver` pour Chrome, par exemple) doit être configuré.\n",
    "- Cette fonction doit être appelée avec un objet `driver` déjà initialisé pour YouTube.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Définition de la fonction pour refuser les cookies sur YouTube\n",
    "def click_refuse_youtube_cookies(driver):\n",
    "    try:\n",
    "        # Mettre en pause le script pendant 2 secondes pour laisser le temps à la page de charger le bouton\n",
    "        time.sleep(2)\n",
    "\n",
    "        # Localiser le bouton 'Tout refuser' avec un XPath et attendre qu'il soit cliquable\n",
    "        refuse_button = WebDriverWait(driver, 5).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, \"//button//span[text()='Tout refuser']\"))\n",
    "        )\n",
    "\n",
    "        # Exécuter un clic JavaScript pour éviter les masques de superposition qui pourraient empêcher le clic normal\n",
    "        driver.execute_script(\"arguments[0].click();\", refuse_button)\n",
    "\n",
    "        # Attendre jusqu'à ce qu'un autre élément (lié au refus de consentement) soit cliquable pour confirmer que le clic a réussi\n",
    "        WebDriverWait(driver, 10).until(EC.element_to_be_clickable(\n",
    "            (By.XPATH, '/html/body/ytd-app/ytd-consent-bump-v2-lightbox/tp-yt-paper-dialog/div[4]/div[2]/div[6]/div[1]/ytd-button-renderer[1]/yt-button-shape/button/yt-touch-feedback-shape/div/div[2]')\n",
    "        ))\n",
    "\n",
    "        # Cliquer sur le bouton 'Tout refuser' après avoir vérifié qu'il est bien présent et actif\n",
    "        refuse_button.click()\n",
    "\n",
    "        # Afficher un message de succès dans la console\n",
    "        print(\"Bouton 'Tout refuser' cliqué sur YouTube.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        # Afficher un message d'erreur si le refus des cookies échoue, ainsi que le message de l'exception\n",
    "        print(f\"Erreur lors du refus des cookies sur YouTube : {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recherhche par thème\n",
    "\n",
    "La fonction `search_by_theme(driver, theme)` effectue une recherche sur un site web en fonction d'un thème ou mot-clé fourni en paramètre. \n",
    "Elle utilise Selenium pour interagir avec les champs de recherche et les boutons du site. Cette fonction est utile pour automatiser \n",
    "des recherches basées sur des mots-clés thématiques, que ce soit pour l'extraction de données, la navigation automatisée ou pour tester des fonctionnalités.\n",
    "\n",
    "**Objectif** :\n",
    "- Automatiser la saisie et la recherche de mots-clés dans un champ de recherche d'un site web.\n",
    "\n",
    "**Contexte** :\n",
    "- Typiquement utilisée dans le cadre de l'automatisation des tests ou du scraping de contenu basé sur des thèmes spécifiques.\n",
    "- Permet d'interagir avec un champ de recherche et de lancer la recherche pour naviguer vers la page de résultats.\n",
    "\n",
    "**Approche** :\n",
    "1. Utiliser `WebDriverWait` pour attendre que le champ de recherche soit visible.\n",
    "2. Saisir le thème dans le champ de recherche après l'avoir vidé pour s'assurer qu'aucun texte résiduel n'interfère.\n",
    "3. Localiser le bouton de recherche et attendre qu'il soit cliquable.\n",
    "4. Lancer la recherche en cliquant sur le bouton.\n",
    "5. Afficher un message de succès ou gérer les erreurs si l'un des éléments n'est pas trouvé.\n",
    "\n",
    "**Avantages** :\n",
    "- Évite les erreurs d'interaction (par exemple, cliquer trop tôt sur le bouton).\n",
    "- Assure que les interactions sont synchronisées avec le chargement de la page.\n",
    "\n",
    "**Prérequis** :\n",
    "- Le module `selenium` doit être installé (`pip install selenium`).\n",
    "- La page sur laquelle le driver navigue doit contenir un champ de recherche avec le nom `mot_cle`.\n",
    "- Le driver doit être initialisé et pointé vers la bonne page avant l'appel de cette fonction.\n",
    "\n",
    "**Arguments** :\n",
    "- `driver` : Instance de Selenium WebDriver contrôlant le navigateur.\n",
    "- `theme` : Thème ou mot-clé à rechercher (chaîne de caractères).\n",
    "\n",
    "**Exceptions gérées** :\n",
    "- `TimeoutException` : Levée si le champ de recherche ou le bouton n'apparaissent pas dans le délai imparti.\n",
    "- `NoSuchElementException` : Levée si l'un des éléments n'est pas présent sur la page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Définition de la fonction pour effectuer une recherche par thème sur un site web donné\n",
    "def search_by_theme(driver, theme):\n",
    "    try:\n",
    "        # Attendre que le champ de recherche soit présent sur la page avec un délai maximum de 20 secondes\n",
    "        search_input = WebDriverWait(driver, 20).until(\n",
    "            EC.presence_of_element_located((By.NAME, \"mot_cle\"))  # Identification du champ de recherche par son nom\n",
    "        )\n",
    "\n",
    "        # Effacer le contenu existant du champ de recherche pour éviter tout conflit avec le nouveau texte\n",
    "        search_input.clear()\n",
    "\n",
    "        # Saisir le mot-clé (thème) dans le champ de recherche\n",
    "        search_input.send_keys(theme)\n",
    "\n",
    "        # Attendre que le bouton de recherche soit cliquable avec un délai de 20 secondes\n",
    "        search_button = WebDriverWait(driver, 20).until(\n",
    "            EC.element_to_be_clickable((By.CSS_SELECTOR, \"input[title='Lancer la recherche'][type='submit']\"))  # Sélection par attribut CSS\n",
    "        )\n",
    "\n",
    "        # Cliquer sur le bouton pour lancer la recherche\n",
    "        search_button.click()\n",
    "\n",
    "        # Afficher un message dans la console pour indiquer le succès de l'opération\n",
    "        print(f\"Recherche lancée pour le thème : {theme}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        # Afficher un message d'erreur en cas de problème, avec les détails de l'exception capturée\n",
    "        print(f\"Erreur lors de la recherche : {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vérification des résulats\n",
    "\n",
    "La fonction `check_no_results(driver)` permet de vérifier si aucun résultat n'est trouvé après avoir effectué un défilement sur une page de résultats. \n",
    "Elle utilise Selenium pour contrôler le défilement et inspecter le contenu de la page à la recherche d'un message ou de l'absence d'éléments indiquant qu'aucun résultat n'est disponible.\n",
    "\n",
    "**Objectif** :\n",
    "- Détecter et signaler l'absence de résultats après un défilement sur une page web.\n",
    "\n",
    "**Contexte** :\n",
    "- Utilisé lors de l'exploration de pages web comportant des résultats paginés ou chargés dynamiquement (scroll infini).\n",
    "- Permet de s'arrêter automatiquement lors d'un scraping lorsqu'aucun résultat n'est trouvé, optimisant ainsi les ressources et le temps d'exécution.\n",
    "\n",
    "**Approche** :\n",
    "1. Effectuer un seul défilement de la page pour charger les nouveaux contenus.\n",
    "2. Vérifier la présence d'un message indiquant qu'il n'y a pas de résultats.\n",
    "3. Si le message n'est pas présent, vérifier s'il n'y a aucun élément correspondant aux résultats attendus sur la page.\n",
    "4. Retourner `True` si aucun résultat n'est trouvé, sinon `False`.\n",
    "\n",
    "**Avantages** :\n",
    "- Simplifie la gestion des pages sans résultats, évitant ainsi des traitements inutiles.\n",
    "- Améliore la robustesse du script en gérant les pages sans contenu ou partiellement chargées.\n",
    "\n",
    "**Prérequis** :\n",
    "- Le module `selenium` doit être installé (`pip install selenium`).\n",
    "- Le driver doit être initialisé et pointé vers une page de résultats avant l'appel de cette fonction.\n",
    "\n",
    "**Arguments** :\n",
    "- `driver` : Instance de Selenium WebDriver contrôlant le navigateur.\n",
    "\n",
    "**Exceptions gérées** :\n",
    "- `NoSuchElementException` : Levée si les éléments recherchés ne sont pas présents sur la page.\n",
    "- `TimeoutException` : Levée si le chargement ou l'exécution du JavaScript prend trop de temps.\n",
    "\n",
    "**Retour** :\n",
    "- `True` : Si aucun résultat n'est trouvé après le défilement.\n",
    "- `False` : Si des résultats sont présents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Définition de la fonction pour vérifier la présence ou l'absence de résultats après un défilement\n",
    "def check_no_results(driver):\n",
    "    # Définir le texte indicatif de l'absence de résultats sur la page\n",
    "    no_results_text = \"Nous n'avons pas de ressources disponibles avec ces critères\"\n",
    "\n",
    "    try:\n",
    "        # Effectuer un défilement vers le bas pour charger plus de contenu (scroll vers le bas d'une hauteur de fenêtre)\n",
    "        driver.execute_script(\"window.scrollBy(0, window.innerHeight);\")\n",
    "\n",
    "        # Attendre 2 secondes pour laisser le temps au contenu de se charger après le défilement\n",
    "        time.sleep(2)\n",
    "\n",
    "        # Rechercher un élément de type div qui contient un message indiquant qu'il n'y a pas de résultats\n",
    "        header = driver.find_elements(By.CSS_SELECTOR, \"div.views-empty\")\n",
    "\n",
    "        # Vérifier si le message d'absence de résultats est présent dans l'élément trouvé\n",
    "        if header and no_results_text in header[0].text:\n",
    "            # Si le message est trouvé, afficher un message et retourner True\n",
    "            print(\"Aucun résultat trouvé pour ce thème.\")\n",
    "            return True\n",
    "\n",
    "        # Rechercher les éléments correspondant aux résultats (ex: éléments de type div avec la classe 'views-row')\n",
    "        results = driver.find_elements(By.CSS_SELECTOR, \".views-row\")\n",
    "\n",
    "        # Si la liste de résultats est vide, cela signifie qu'aucun résultat n'est présent après le défilement\n",
    "        if not results:\n",
    "            # Afficher un message dans la console et retourner True\n",
    "            print(\"Aucun résultat trouvé après un scroll.\")\n",
    "            return True\n",
    "\n",
    "        # Si des résultats sont trouvés, retourner False\n",
    "        return False\n",
    "\n",
    "    except Exception as e:\n",
    "        # En cas d'erreur, afficher un message d'erreur dans la console avec le détail de l'exception\n",
    "        print(f\"Erreur lors de la vérification des résultats : {str(e)}\")\n",
    "        # Retourner False pour indiquer que la vérification a échoué\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Téléchargement de pdf\n",
    "\n",
    "La fonction `download_pdf(url, filename)` permet de télécharger un fichier PDF depuis une URL spécifiée, de le sauvegarder localement avec le nom de fichier indiqué, \n",
    "et de gérer les éventuelles erreurs rencontrées lors du téléchargement. Cette fonction vérifie d'abord la validité de l'URL, puis effectue une requête pour récupérer le contenu du PDF, \n",
    "et enfin l'enregistre dans le dossier `PDFs`.\n",
    "\n",
    "**Objectif** :\n",
    "- Télécharger un fichier PDF à partir d'une URL et le sauvegarder localement avec un nom de fichier spécifique.\n",
    "\n",
    "**Contexte** :\n",
    "- Utile dans des scripts d'extraction de données (scraping) ou d'automatisation pour récupérer des documents PDF de manière systématique.\n",
    "- Peut être utilisé dans des contextes où les documents doivent être archivés pour une consultation hors ligne ou pour des traitements ultérieurs.\n",
    "\n",
    "**Approche** :\n",
    "1. Vérifier et ajuster l'URL pour s'assurer qu'elle commence par `http://` ou `https://`.\n",
    "2. Effectuer une requête HTTP pour récupérer le contenu du PDF.\n",
    "3. Vérifier le succès de la requête (code 200).\n",
    "4. Enregistrer le fichier localement dans le dossier `PDFs` en mode binaire (`wb`).\n",
    "5. Gérer les exceptions spécifiques aux requêtes (problème de réseau, URL invalide) et les autres exceptions.\n",
    "\n",
    "**Avantages** :\n",
    "- Permet de récupérer des fichiers PDF depuis diverses sources en s'assurant que le fichier est correctement téléchargé et sauvegardé.\n",
    "- Gestion d'erreurs intégrée pour éviter les crashs du programme en cas d'échec de téléchargement.\n",
    "\n",
    "**Prérequis** :\n",
    "- Le module `requests` doit être installé (`pip install requests`).\n",
    "- Le module `os` doit être importé pour gérer les chemins de fichiers.\n",
    "- Le dossier `PDFs` doit exister ou avoir été créé auparavant dans le script.\n",
    "\n",
    "**Arguments** :\n",
    "- `url` : URL du fichier PDF à télécharger.\n",
    "- `filename` : Nom sous lequel le fichier doit être sauvegardé localement (incluant l'extension `.pdf`).\n",
    "\n",
    "**Exceptions gérées** :\n",
    "- `requests.exceptions.RequestException` : Levée en cas de problème de connexion, URL invalide ou autre erreur de requête.\n",
    "- `Exception` : Gère toute autre erreur inattendue (par exemple, problème d'écriture de fichier).\n",
    "\n",
    "**Retour** :\n",
    "- Aucun retour spécifique, mais affiche le statut du téléchargement (succès ou échec) dans la console.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Définition de la fonction pour télécharger un fichier PDF depuis une URL spécifiée\n",
    "def download_pdf(url, filename):\n",
    "    try:\n",
    "        # Vérifier et ajuster l'URL si nécessaire (ajoute 'https://' si manquant)\n",
    "        if not (url.startswith('http://') or url.startswith('https://')):\n",
    "            # Ajouter 'https://' au début de l'URL si elle commence par des slashes ou est incomplète\n",
    "            url = 'https://' + url.lstrip('/')\n",
    "\n",
    "        # Envoyer une requête GET à l'URL pour récupérer le fichier PDF\n",
    "        response = requests.get(url)\n",
    "\n",
    "        # Lever une exception si la requête échoue (mauvaise réponse HTTP)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        # Vérifier si la réponse est réussie (code 200)\n",
    "        if response.status_code == 200:\n",
    "            # Construire le chemin complet du fichier PDF à sauvegarder localement\n",
    "            full_path = os.path.join(pdf_folder, filename)\n",
    "\n",
    "            # Ouvrir le fichier en mode binaire (écriture) et y sauvegarder le contenu téléchargé\n",
    "            with open(full_path, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "\n",
    "            # Afficher un message de succès si le fichier est téléchargé avec succès\n",
    "            print(f\"Téléchargement PDF réussi : {full_path}\")\n",
    "        else:\n",
    "            # Afficher un message d'erreur si la réponse HTTP n'est pas correcte (ex: code 404)\n",
    "            print(f\"Échec du téléchargement PDF : {filename}\")\n",
    "\n",
    "    # Gérer les erreurs de requête spécifiques (problème de connexion, URL invalide, etc.)\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Erreur lors du téléchargement du PDF {filename} : {str(e)}\")\n",
    "\n",
    "    # Gérer toute autre erreur inattendue (ex: problème d'écriture dans le fichier)\n",
    "    except Exception as e:\n",
    "        print(f\"Une erreur inattendue est survenue : {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export des données dans un fichier excel\n",
    "\n",
    "La fonction `export_to_excel(data)` permet de créer et d'enregistrer un fichier Excel à partir de données fournies sous forme de liste de listes.\n",
    "Elle organise les informations dans un format structuré en ajoutant des en-têtes de colonnes et les lignes de données correspondantes.\n",
    "Cette fonction utilise le module `openpyxl` pour manipuler les fichiers Excel.\n",
    "\n",
    "**Objectif** :\n",
    "- Exporter des données structurées dans un fichier Excel pour faciliter l'analyse et la consultation.\n",
    "\n",
    "**Contexte** :\n",
    "- Cette fonction est utilisée lorsqu'il est nécessaire de sauvegarder des informations collectées dans un format tabulaire (Excel), \n",
    "  par exemple après l'extraction de données d'un site ou d'une base de données.\n",
    "- Elle permet de centraliser les informations dans un document unique et facilement lisible.\n",
    "\n",
    "**Approche** :\n",
    "1. Créer un nouveau classeur Excel (`Workbook`).\n",
    "2. Ajouter une feuille intitulée \"Informations générales\" pour organiser les données.\n",
    "3. Définir les en-têtes de colonnes correspondant aux champs de données à exporter.\n",
    "4. Ajouter chaque ligne de données à la feuille Excel.\n",
    "5. Sauvegarder le classeur dans le dossier `Fichiers_Excel` avec un nom de fichier spécifique.\n",
    "6. Gérer les erreurs liées à la création ou à la sauvegarde du fichier.\n",
    "\n",
    "**Avantages** :\n",
    "- Permet d'avoir une sauvegarde des informations sous un format standard et universellement lisible.\n",
    "- Facilite le partage et l'analyse des données collectées.\n",
    "\n",
    "**Prérequis** :\n",
    "- Le module `openpyxl` doit être installé (`pip install openpyxl`).\n",
    "- Le module `os` est utilisé pour gérer les chemins de fichiers.\n",
    "- Le dossier `Fichiers_Excel` doit exister ou avoir été créé au préalable dans le script.\n",
    "\n",
    "**Arguments** :\n",
    "- `data` : Une liste de listes, où chaque liste interne représente une ligne à ajouter au fichier Excel.\n",
    "\n",
    "**Exceptions gérées** :\n",
    "- `Exception` : Capture toute erreur générale (problème d'écriture, de structure de données, ou de permissions).\n",
    "\n",
    "**Retour** :\n",
    "- Aucun retour spécifique, mais affiche le statut de l'exportation (succès ou échec) dans la console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Définition de la fonction pour exporter les données vers un fichier Excel\n",
    "def export_to_excel(data):\n",
    "    try:\n",
    "        # Créer un nouveau classeur Excel\n",
    "        wb = Workbook()\n",
    "\n",
    "        # Créer la première feuille de calcul et la nommer \"Informations générales\"\n",
    "        ws_general = wb.active\n",
    "        ws_general.title = 'Informations générales'\n",
    "\n",
    "        # Définir les en-têtes de colonnes correspondant aux champs de données à exporter\n",
    "        headers = [\n",
    "            'Titre', 'Thématique', 'Description', 'Type_document', 'Source', 'Lieu', 'Lien', 'Propriétaire_video', \n",
    "            'Titre_vidéo', 'Nombre de commentaires de la vidéo', 'Nombre de vues de la vidéo', 'Nombre de likes de la vidéo',\n",
    "            'Description de la vidéo', 'Lien de la vidéo', 'Date de publication'\n",
    "        ]\n",
    "\n",
    "        # Ajouter les en-têtes comme première ligne de la feuille de calcul\n",
    "        ws_general.append(headers)\n",
    "\n",
    "        # Ajouter chaque ligne de données fournie dans la liste `data` à la feuille Excel\n",
    "        for line in data:\n",
    "            # Chaque élément de `line` représente une ligne à ajouter au tableau\n",
    "            ws_general.append(line)\n",
    "\n",
    "        # Définir le chemin complet du fichier Excel dans le dossier `Fichiers_Excel`\n",
    "        excel_filename = os.path.join(excel_folder, 'data_Dispositif_Rex.xlsx')\n",
    "\n",
    "        # Sauvegarder le classeur Excel sous le nom 'data_Dispositif_Rex.xlsx' dans le dossier\n",
    "        wb.save(excel_filename)\n",
    "\n",
    "        # Afficher un message dans la console indiquant le succès de l'exportation\n",
    "        print(f\"Données exportées avec succès vers : {excel_filename}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        # En cas de problème lors de la création ou de la sauvegarde du fichier Excel, afficher un message d'erreur\n",
    "        print(f\"Une erreur est survenue lors de l'exportation vers Excel : {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Récupération du nombre de commentaire\n",
    "\n",
    "La fonction `get_nombre_commentaire(driver, video_url)` permet de récupérer le nombre de commentaires d'une vidéo YouTube en utilisant Selenium pour naviguer sur la page. \n",
    "Elle prend en compte les cas où les commentaires sont désactivés et gère les erreurs liées à l'extraction des informations.\n",
    "\n",
    "**Objectif** :\n",
    "- Accéder à une vidéo YouTube et extraire le nombre de commentaires affichés.\n",
    "\n",
    "**Contexte** :\n",
    "- Utilisée dans des scripts de collecte de données pour analyser l'engagement des utilisateurs sur des vidéos YouTube.\n",
    "- Pratique pour récupérer des métriques supplémentaires telles que le nombre de commentaires, vues ou likes, pour des analyses comparatives.\n",
    "\n",
    "**Approche** :\n",
    "1. Charger la page de la vidéo en utilisant `driver.get(video_url)`.\n",
    "2. Scroller vers le bas de la page pour forcer le chargement des commentaires.\n",
    "3. Vérifier si les commentaires sont désactivés en recherchant un message spécifique.\n",
    "4. Si les commentaires sont activés, récupérer le nombre total de commentaires.\n",
    "5. Gérer les exceptions pour garantir que la fonction ne plante pas en cas de problème.\n",
    "\n",
    "**Avantages** :\n",
    "- Gère automatiquement les cas où les commentaires sont désactivés.\n",
    "- Utilise des techniques de défilement et d'attente pour s'assurer que tous les éléments sont chargés avant de tenter de les lire.\n",
    "\n",
    "**Prérequis** :\n",
    "- Le module `selenium` doit être installé (`pip install selenium`).\n",
    "- Le pilote de navigateur (ex. `chromedriver`) doit être configuré correctement.\n",
    "- La page de la vidéo doit être accessible (pas de restrictions d'âge, géographiques, ou de permissions).\n",
    "\n",
    "**Arguments** :\n",
    "- `driver` : Instance de Selenium WebDriver contrôlant le navigateur.\n",
    "- `video_url` : URL de la vidéo YouTube pour laquelle le nombre de commentaires doit être extrait.\n",
    "\n",
    "**Exceptions gérées** :\n",
    "- `TimeoutException` : Levée si l'élément (nombre de commentaires ou message de désactivation) n'est pas trouvé dans le délai imparti.\n",
    "- `Exception` : Gère toute autre erreur liée au chargement de la page ou à l'extraction des informations.\n",
    "\n",
    "**Retour** :\n",
    "- `nombre_commentaires` : Chaîne de caractères représentant le nombre de commentaires (ou \"N/A\" si les commentaires ne sont pas disponibles).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Définition de la fonction pour extraire le nombre de commentaires d'une vidéo YouTube\n",
    "def get_nombre_commentaire(driver, video_url):\n",
    "    try:\n",
    "        # Charger la page de la vidéo spécifiée par `video_url`\n",
    "        driver.get(video_url)\n",
    "\n",
    "        # Scroller vers le bas de la page pour charger la section des commentaires\n",
    "        driver.execute_script(\"window.scrollTo(0, document.documentElement.scrollHeight);\")\n",
    "\n",
    "        # Attendre quelques secondes pour s'assurer que la page a bien défilé et que les commentaires sont chargés\n",
    "        WebDriverWait(driver, 5).until(\n",
    "            EC.presence_of_element_located((By.TAG_NAME, \"body\"))  # Vérifier que le corps de la page est bien chargé\n",
    "        )\n",
    "\n",
    "        # Essayer de détecter si un message indique que les commentaires sont désactivés\n",
    "        try:\n",
    "            commentaire_desactive_element = WebDriverWait(driver, 20).until(\n",
    "                EC.presence_of_element_located((By.XPATH, \"//yt-formatted-string[contains(text(), 'Les commentaires sont désactivés')]\"))\n",
    "            )\n",
    "\n",
    "            # Si l'élément indiquant que les commentaires sont désactivés est trouvé, retourner \"N/A\"\n",
    "            if commentaire_desactive_element:\n",
    "                nombre_commentaires = \"N/A\"\n",
    "                print(\"Les commentaires sont désactivés sur cette vidéo.\")\n",
    "\n",
    "        # Gérer l'exception si le message de désactivation n'est pas trouvé (donc les commentaires ne sont pas désactivés)\n",
    "        except TimeoutException:\n",
    "            try:\n",
    "                # Extraire le nombre de commentaires si l'élément correspondant est trouvé\n",
    "                nombre_commentaires = WebDriverWait(driver, 20).until(\n",
    "                    EC.presence_of_element_located((By.CSS_SELECTOR, 'yt-formatted-string.count-text.style-scope.ytd-comments-header-renderer'))\n",
    "                ).text\n",
    "            except Exception as e:\n",
    "                # Si une autre erreur survient pendant l'extraction du nombre de commentaires, définir `nombre_commentaires` comme \"N/A\"\n",
    "                nombre_commentaires = \"N/A\"\n",
    "                print(f\"Erreur lors de l'extraction du nombre de commentaires : {str(e)}\")\n",
    "\n",
    "    # Gérer les erreurs générales (par exemple, problème lors du chargement de la vidéo)\n",
    "    except Exception as e:\n",
    "        nombre_commentaires = \"N/A\"\n",
    "        print(f\"Erreur lors du chargement de la vidéo : {str(e)}\")\n",
    "\n",
    "    # Retourner le nombre de commentaires récupéré ou \"N/A\" si une erreur s'est produite\n",
    "    return nombre_commentaires\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Récupérer le titre de la vidéo\n",
    "\n",
    "La fonction `get_titre_video(driver, video_url)` permet d'extraire le titre d'une vidéo YouTube en utilisant Selenium pour naviguer sur la page de la vidéo.\n",
    "Elle vérifie que la page est bien chargée, puis localise l'élément contenant le titre de la vidéo et retourne ce texte. \n",
    "\n",
    "**Objectif** :\n",
    "- Accéder à une vidéo YouTube et extraire son titre.\n",
    "\n",
    "**Contexte** :\n",
    "- Utilisé principalement dans des scripts de collecte de données YouTube pour récupérer des informations sur les vidéos, telles que le titre, les vues, ou les commentaires.\n",
    "- Pratique pour construire des bases de données de vidéos ou pour analyser le contenu.\n",
    "\n",
    "**Approche** :\n",
    "1. Charger la page de la vidéo en utilisant `driver.get(video_url)`.\n",
    "2. Attendre que l'élément contenant le titre de la vidéo soit visible sur la page.\n",
    "3. Extraire le texte de cet élément.\n",
    "4. Retourner le titre ou \"N/A\" si l'élément n'est pas trouvé ou qu'une erreur survient.\n",
    "\n",
    "**Avantages** :\n",
    "- La fonction gère les cas où le titre n'est pas disponible (par exemple, si la page n'est pas chargée correctement).\n",
    "- Utilise des techniques de `WebDriverWait` pour s'assurer que l'élément est bien présent avant de tenter de le lire.\n",
    "\n",
    "**Prérequis** :\n",
    "- Le module `selenium` doit être installé (`pip install selenium`).\n",
    "- Le pilote de navigateur (ex. `chromedriver`) doit être configuré correctement.\n",
    "- La page de la vidéo doit être accessible (pas de restrictions d'âge, géographiques, ou de permissions).\n",
    "\n",
    "**Arguments** :\n",
    "- `driver` : Instance de Selenium WebDriver contrôlant le navigateur.\n",
    "- `video_url` : URL de la vidéo YouTube pour laquelle le titre doit être extrait.\n",
    "\n",
    "**Exceptions gérées** :\n",
    "- `TimeoutException` : Levée si l'élément (titre de la vidéo) n'est pas trouvé dans le délai imparti.\n",
    "- `NoSuchElementException` : Levée si l'élément est introuvable sur la page.\n",
    "- `Exception` : Capture toute autre erreur liée au chargement de la page ou à l'extraction du titre.\n",
    "\n",
    "**Retour** :\n",
    "- `titre_video` : Chaîne de caractères représentant le titre de la vidéo, ou \"N/A\" si le titre n'est pas disponible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Définition de la fonction pour extraire le titre d'une vidéo YouTube\n",
    "def get_titre_video(driver, video_url):\n",
    "    try:\n",
    "        # Charger la page de la vidéo spécifiée par `video_url`\n",
    "        driver.get(video_url)\n",
    "\n",
    "        # Attendre que l'élément contenant le titre de la vidéo soit visible sur la page\n",
    "        WebDriverWait(driver, 20).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, 'div.style-scope.ytd-watch-metadata yt-formatted-string.style-scope.ytd-watch-metadata'))\n",
    "        )\n",
    "\n",
    "        # Localiser l'élément contenant le titre de la vidéo\n",
    "        titre_video_element = driver.find_element(By.CSS_SELECTOR, 'div.style-scope.ytd-watch-metadata yt-formatted-string.style-scope.ytd-watch-metadata')\n",
    "\n",
    "        # Retourner le texte du titre s'il est trouvé, sinon \"N/A\"\n",
    "        return titre_video_element.text.strip() if titre_video_element else 'N/A'\n",
    "\n",
    "    except Exception as e:\n",
    "        # En cas d'erreur, afficher un message et retourner \"N/A\"\n",
    "        print(f\"Erreur lors de la récupération du titre de la vidéo : {str(e)}\")\n",
    "        return 'N/A'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Récupérer le nom de la chaîne\n",
    "\n",
    "La fonction `get_video_owner(driver, video_url)` permet de récupérer le nom du propriétaire (auteur) d'une vidéo YouTube. \n",
    "Elle utilise Selenium pour naviguer sur la page de la vidéo et localiser l'élément HTML contenant le nom du propriétaire.\n",
    "\n",
    "**Objectif** :\n",
    "- Accéder à la page d'une vidéo YouTube et extraire le nom de la chaîne ou de l'utilisateur qui a publié la vidéo.\n",
    "\n",
    "**Contexte** :\n",
    "- Utile pour la collecte de données sur les vidéos, notamment pour obtenir des informations sur les auteurs et analyser la répartition des vidéos par chaîne.\n",
    "- Utilisé dans des scripts de scraping ou d'automatisation pour regrouper des informations sur plusieurs vidéos d'une même chaîne.\n",
    "\n",
    "**Approche** :\n",
    "1. Charger la page de la vidéo avec `driver.get(video_url)`.\n",
    "2. Attendre que l'élément contenant le nom du propriétaire de la vidéo soit visible.\n",
    "3. Localiser l'élément spécifique avec un sélecteur CSS (`By.CSS_SELECTOR`).\n",
    "4. Récupérer le texte correspondant au nom du propriétaire.\n",
    "5. Retourner le nom ou \"N/A\" si l'élément n'est pas trouvé ou qu'une erreur survient.\n",
    "\n",
    "**Avantages** :\n",
    "- La fonction utilise des techniques de `WebDriverWait` pour s'assurer que l'élément est bien présent avant de tenter de le lire.\n",
    "- Permet de gérer les erreurs liées au chargement de la page ou à des changements dans la structure HTML de YouTube.\n",
    "\n",
    "**Prérequis** :\n",
    "- Le module `selenium` doit être installé (`pip install selenium`).\n",
    "- Le pilote de navigateur (ex. `chromedriver`) doit être configuré correctement.\n",
    "- La page de la vidéo doit être accessible (pas de restrictions d'âge, géographiques, ou de permissions).\n",
    "\n",
    "**Arguments** :\n",
    "- `driver` : Instance de Selenium WebDriver contrôlant le navigateur.\n",
    "- `video_url` : URL de la vidéo YouTube pour laquelle le nom du propriétaire doit être extrait.\n",
    "\n",
    "**Exceptions gérées** :\n",
    "- `TimeoutException` : Levée si l'élément contenant le nom du propriétaire n'est pas trouvé dans le délai imparti.\n",
    "- `NoSuchElementException` : Levée si l'élément est introuvable sur la page.\n",
    "- `Exception` : Capture toute autre erreur liée au chargement de la page ou à l'extraction du nom.\n",
    "\n",
    "**Retour** :\n",
    "- `owner_name` : Chaîne de caractères représentant le nom de l'auteur de la vidéo, ou \"N/A\" si le nom n'est pas disponible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition de la fonction pour extraire le nom du propriétaire de la vidéo YouTube\n",
    "def get_video_owner(driver, video_url):\n",
    "    try:\n",
    "        # Charger la page de la vidéo spécifiée par `video_url`\n",
    "        driver.get(video_url)\n",
    "\n",
    "        # Attendre que l'élément contenant le nom du propriétaire de la vidéo soit visible sur la page\n",
    "        WebDriverWait(driver, 20).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, 'div.style-scope ytd-channel-name a.yt-simple-endpoint.style-scope.yt-formatted-string'))\n",
    "        )\n",
    "\n",
    "        # Localiser l'élément contenant le nom du propriétaire de la chaîne YouTube\n",
    "        owner_element = driver.find_element(By.CSS_SELECTOR, 'div.style-scope ytd-channel-name a.yt-simple-endpoint.style-scope.yt-formatted-string')\n",
    "\n",
    "        # Retourner le texte du nom du propriétaire s'il est trouvé, sinon \"N/A\"\n",
    "        return owner_element.text.strip() if owner_element else 'N/A'\n",
    "\n",
    "    except Exception as e:\n",
    "        # En cas d'erreur, afficher un message et retourner \"N/A\"\n",
    "        print(f\"Erreur lors de la récupération du propriétaire de la vidéo : {str(e)}\")\n",
    "        return 'N/A'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Récupération du nombre de vues\n",
    "\n",
    "La fonction `get_nombre_vues(driver, video_url)` permet de récupérer le nombre de vues d'une vidéo YouTube en utilisant Selenium pour naviguer sur la page de la vidéo.\n",
    "Elle vérifie la présence de l'élément contenant le nombre de vues, l'extrait, et le retourne sous forme de texte.\n",
    "\n",
    "**Objectif** :\n",
    "- Accéder à la page d'une vidéo YouTube et extraire le nombre de vues affiché.\n",
    "\n",
    "**Contexte** :\n",
    "- Utilisé dans des scripts de collecte de données sur YouTube pour obtenir des informations sur les performances des vidéos (nombre de vues).\n",
    "- Pratique pour analyser l'engagement des utilisateurs sur une vidéo ou pour comparer la popularité de plusieurs vidéos.\n",
    "\n",
    "**Approche** :\n",
    "1. Charger la page de la vidéo en utilisant `driver.get(video_url)`.\n",
    "2. Attendre que l'élément contenant le nombre de vues soit visible sur la page.\n",
    "3. Localiser cet élément avec un sélecteur CSS (`By.CSS_SELECTOR`).\n",
    "4. Extraire le texte représentant le nombre de vues.\n",
    "5. Retourner le nombre de vues ou \"N/A\" si l'élément n'est pas trouvé ou qu'une erreur survient.\n",
    "\n",
    "**Avantages** :\n",
    "- La fonction utilise des techniques de `WebDriverWait` pour s'assurer que l'élément est bien présent avant de tenter de le lire.\n",
    "- Gère les erreurs et retourne \"N/A\" si le nombre de vues n'est pas disponible.\n",
    "\n",
    "**Prérequis** :\n",
    "- Le module `selenium` doit être installé (`pip install selenium`).\n",
    "- Le pilote de navigateur (ex. `chromedriver`) doit être configuré correctement.\n",
    "- La page de la vidéo doit être accessible (pas de restrictions d'âge, géographiques, ou de permissions).\n",
    "\n",
    "**Arguments** :\n",
    "- `driver` : Instance de Selenium WebDriver contrôlant le navigateur.\n",
    "- `video_url` : URL de la vidéo YouTube pour laquelle le nombre de vues doit être extrait.\n",
    "\n",
    "**Exceptions gérées** :\n",
    "- `TimeoutException` : Levée si l'élément contenant le nombre de vues n'est pas trouvé dans le délai imparti.\n",
    "- `NoSuchElementException` : Levée si l'élément est introuvable sur la page.\n",
    "- `Exception` : Capture toute autre erreur liée au chargement de la page ou à l'extraction des vues.\n",
    "\n",
    "**Retour** :\n",
    "- `nombre_vues` : Chaîne de caractères représentant le nombre de vues de la vidéo, ou \"N/A\" si le nombre n'est pas disponible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Définition de la fonction pour extraire le nombre de vues d'une vidéo YouTube\n",
    "def get_nombre_vues(driver, video_url):\n",
    "    try:\n",
    "        # Charger la page de la vidéo spécifiée par `video_url`\n",
    "        driver.get(video_url)\n",
    "\n",
    "        # Attendre que l'élément contenant le nombre de vues soit visible sur la page\n",
    "        WebDriverWait(driver, 20).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, 'yt-formatted-string.style-scope.ytd-watch-info-text span.style-scope.yt-formatted-string.bold'))\n",
    "        )\n",
    "\n",
    "        # Localiser l'élément contenant le nombre de vues de la vidéo\n",
    "        vues_element = driver.find_element(By.CSS_SELECTOR, 'yt-formatted-string.style-scope.ytd-watch-info-text span.style-scope.yt-formatted-string.bold')\n",
    "\n",
    "        # Retourner le texte du nombre de vues s'il est trouvé, sinon \"N/A\"\n",
    "        return vues_element.text.strip() if vues_element else 'N/A'\n",
    "\n",
    "    except Exception as e:\n",
    "        # En cas d'erreur, afficher un message et retourner \"N/A\"\n",
    "        print(f\"Erreur lors de la récupération du nombre de vues : {str(e)}\")\n",
    "        return 'N/A'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Récupération du nombre de likes\n",
    "\n",
    "La fonction `get_nombre_likes(driver, video_url)` permet de récupérer le nombre de \"likes\" d'une vidéo YouTube en utilisant Selenium pour naviguer sur la page de la vidéo.\n",
    "Elle vérifie la présence de l'élément contenant le nombre de likes, l'extrait, et le retourne sous forme de texte. Si le texte de l'élément est \"J'aime\" (sans nombre), \n",
    "cela signifie que le nombre de likes est nul, et la fonction retourne `0`.\n",
    "\n",
    "**Objectif** :\n",
    "- Accéder à la page d'une vidéo YouTube et extraire le nombre de \"likes\" affiché sous le bouton \"J'aime\".\n",
    "\n",
    "**Contexte** :\n",
    "- Utile pour la collecte de données sur les vidéos YouTube afin de mesurer l'engagement du public à travers les interactions.\n",
    "- Pratique pour l'analyse de la popularité d'une vidéo ou pour comparer plusieurs vidéos en fonction de leur nombre de likes.\n",
    "\n",
    "**Approche** :\n",
    "1. Charger la page de la vidéo en utilisant `driver.get(video_url)`.\n",
    "2. Attendre que l'élément contenant le nombre de likes soit visible sur la page.\n",
    "3. Localiser cet élément avec un sélecteur XPath (`By.XPATH`).\n",
    "4. Extraire le texte représentant le nombre de likes.\n",
    "5. Retourner `0` si le texte est \"J'aime\" (signifiant qu'il n'y a pas de likes) ou retourner le nombre extrait.\n",
    "6. Retourner \"N/A\" si l'élément n'est pas trouvé ou qu'une erreur survient.\n",
    "\n",
    "**Avantages** :\n",
    "- La fonction utilise des techniques de `WebDriverWait` pour s'assurer que l'élément est bien présent avant de tenter de le lire.\n",
    "- Gère les erreurs et retourne \"N/A\" si le nombre de likes n'est pas disponible.\n",
    "\n",
    "**Prérequis** :\n",
    "- Le module `selenium` doit être installé (`pip install selenium`).\n",
    "- Le pilote de navigateur (ex. `chromedriver`) doit être configuré correctement.\n",
    "- La page de la vidéo doit être accessible (pas de restrictions d'âge, géographiques, ou de permissions).\n",
    "\n",
    "**Arguments** :\n",
    "- `driver` : Instance de Selenium WebDriver contrôlant le navigateur.\n",
    "- `video_url` : URL de la vidéo YouTube pour laquelle le nombre de likes doit être extrait.\n",
    "\n",
    "**Exceptions gérées** :\n",
    "- `TimeoutException` : Levée si l'élément contenant le nombre de likes n'est pas trouvé dans le délai imparti.\n",
    "- `NoSuchElementException` : Levée si l'élément est introuvable sur la page.\n",
    "- `Exception` : Capture toute autre erreur liée au chargement de la page ou à l'extraction des likes.\n",
    "\n",
    "**Retour** :\n",
    "- `nombre_likes` : Nombre de \"likes\" sous forme de chaîne de caractères, ou `0` si aucun like n'est enregistré, ou \"N/A\" si le nombre n'est pas disponible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Définition de la fonction pour extraire le nombre de likes d'une vidéo YouTube\n",
    "def get_nombre_likes(driver, video_url):\n",
    "    try:\n",
    "        # Accéder à l'URL de la vidéo spécifiée par `video_url`\n",
    "        driver.get(video_url)\n",
    "\n",
    "        # Attendre que l'élément contenant le nombre de likes soit présent sur la page\n",
    "        WebDriverWait(driver, 20).until(\n",
    "            EC.presence_of_element_located((By.XPATH, '/html/body/ytd-app/div[1]/ytd-page-manager/ytd-watch-flexy/div[5]/div[1]/div/div[2]/ytd-watch-metadata/div/div[2]/div[2]/div/div/ytd-menu-renderer/div[1]/segmented-like-dislike-button-view-model/yt-smartimation/div/div/like-button-view-model/toggle-button-view-model/button-view-model/button/div[2]'))\n",
    "        )\n",
    "\n",
    "        # Localiser l'élément contenant le nombre de likes\n",
    "        likes_element = driver.find_element(By.XPATH, '/html/body/ytd-app/div[1]/ytd-page-manager/ytd-watch-flexy/div[5]/div[1]/div/div[2]/ytd-watch-metadata/div/div[2]/div[2]/div/div/ytd-menu-renderer/div[1]/segmented-like-dislike-button-view-model/yt-smartimation/div/div/like-button-view-model/toggle-button-view-model/button-view-model/button/div[2]')\n",
    "\n",
    "        # Récupérer le texte du nombre de likes et le convertir en '0' si le texte est \"J'aime\"\n",
    "        likes_text = likes_element.text.strip() if likes_element else 'N/A'\n",
    "\n",
    "        # Retourner 0 si le texte est \"J'aime\", sinon retourner le texte récupéré\n",
    "        return 0 if likes_text == \"J'aime\" else likes_text\n",
    "\n",
    "    except Exception as e:\n",
    "        # En cas d'erreur, afficher un message et retourner \"N/A\"\n",
    "        print(f\"Erreur lors de la récupération du nombre de likes : {str(e)}\")\n",
    "        return 'N/A'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Récupération de la description vidéo\n",
    "\n",
    "La fonction `get_description_video(driver, video_url)` permet de récupérer la description d'une vidéo YouTube en utilisant Selenium pour naviguer sur la page de la vidéo.\n",
    "Elle clique d'abord sur le bouton \"Afficher plus\" pour développer la description complète, puis extrait le texte de la description en utilisant BeautifulSoup pour parser le contenu HTML.\n",
    "\n",
    "**Objectif** :\n",
    "- Accéder à la page d'une vidéo YouTube, afficher la description complète et l'extraire sous forme de texte.\n",
    "\n",
    "**Contexte** :\n",
    "- Utile pour la collecte de données sur YouTube afin de récupérer les descriptions de vidéos pour analyse sémantique, évaluation du contenu ou comparaison entre vidéos.\n",
    "- Pratique pour construire des bases de données de vidéos ou pour extraire des informations contextuelles sur plusieurs vidéos.\n",
    "\n",
    "**Approche** :\n",
    "1. Charger la page de la vidéo en utilisant `driver.get(video_url)`.\n",
    "2. Attendre que l'élément contenant la description soit visible.\n",
    "3. Tenter de cliquer sur le bouton \"Afficher plus\" pour afficher la description complète.\n",
    "4. Extraire le texte de la description à l'aide de `find_element()` et parser le contenu avec BeautifulSoup.\n",
    "5. Traiter le contenu pour récupérer uniquement le texte pertinent, en ignorant les balises superflues.\n",
    "6. Retourner la description complète ou \"N/A\" si l'élément n'est pas trouvé ou qu'une erreur survient.\n",
    "\n",
    "**Avantages** :\n",
    "- La fonction permet de récupérer la description complète, y compris les liens et informations supplémentaires masquées par défaut.\n",
    "- Utilise BeautifulSoup pour extraire et nettoyer le texte, ce qui permet d'obtenir une description bien formatée.\n",
    "\n",
    "**Prérequis** :\n",
    "- Le module `selenium` doit être installé (`pip install selenium`).\n",
    "- Le module `bs4` (BeautifulSoup) doit être installé (`pip install beautifulsoup4`).\n",
    "- Le pilote de navigateur (ex. `chromedriver`) doit être configuré correctement.\n",
    "- La page de la vidéo doit être accessible (pas de restrictions d'âge, géographiques, ou de permissions).\n",
    "\n",
    "**Arguments** :\n",
    "- `driver` : Instance de Selenium WebDriver contrôlant le navigateur.\n",
    "- `video_url` : URL de la vidéo YouTube pour laquelle la description doit être extraite.\n",
    "\n",
    "**Exceptions gérées** :\n",
    "- `TimeoutException` : Levée si l'élément contenant la description ou le bouton \"Afficher plus\" n'est pas trouvé dans le délai imparti.\n",
    "- `NoSuchElementException` : Levée si l'élément est introuvable sur la page.\n",
    "- `Exception` : Capture toute autre erreur liée au chargement de la page ou à l'extraction de la description.\n",
    "\n",
    "**Retour** :\n",
    "- `description` : Chaîne de caractères représentant la description complète de la vidéo, ou \"N/A\" si la description n'est pas disponible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Définition de la fonction pour extraire la description complète d'une vidéo YouTube\n",
    "def get_description_video(driver, video_url):\n",
    "    try:\n",
    "        # Accéder à l'URL de la vidéo spécifiée par `video_url`\n",
    "        driver.get(video_url)\n",
    "\n",
    "        # Attendre que l'élément contenant la description soit présent sur la page\n",
    "        WebDriverWait(driver, 20).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, 'yt-attributed-string.style-scope.ytd-text-inline-expander span.yt-core-attributed-string.yt-core-attributed-string--white-space-pre-wrap'))\n",
    "        )\n",
    "\n",
    "        # Essayer de cliquer sur le bouton \"Afficher plus\" pour développer la description complète\n",
    "        try:\n",
    "            afficher_plus_button = WebDriverWait(driver, 20).until(\n",
    "                EC.element_to_be_clickable((By.XPATH, \"/html/body/ytd-app/div[1]/ytd-page-manager/ytd-watch-flexy/div[5]/div[1]/div/div[2]/ytd-watch-metadata/div/div[4]/div[1]/div/ytd-text-inline-expander/tp-yt-paper-button[1]\"))\n",
    "            )\n",
    "            afficher_plus_button.click()\n",
    "            print(\"Le bouton 'Afficher plus' a été cliqué.\")\n",
    "            time.sleep(2)  # Attendre 2 secondes après le clic pour laisser le temps de charger la description complète\n",
    "        except Exception:\n",
    "            print(\"Erreur lors du clic sur 'Afficher plus'.\")\n",
    "\n",
    "        # Localiser l'élément contenant la description complète de la vidéo\n",
    "        description_video_element = driver.find_element(By.CSS_SELECTOR, 'yt-attributed-string.style-scope.ytd-text-inline-expander span.yt-core-attributed-string.yt-core-attributed-string--white-space-pre-wrap')\n",
    "\n",
    "        if description_video_element:\n",
    "            # Extraire le contenu HTML de l'élément description\n",
    "            html_content = description_video_element.get_attribute('innerHTML')\n",
    "\n",
    "            # Parser le contenu HTML pour extraire uniquement le texte avec BeautifulSoup\n",
    "            soup = bs(html_content, 'html.parser')\n",
    "\n",
    "            # Rechercher tous les éléments <span> présents dans la description\n",
    "            all_spans = soup.find_all('span')\n",
    "\n",
    "            # Extraire le texte de chaque <span> tout en filtrant les éléments ayant des liens superflus\n",
    "            description_texts = []\n",
    "            for span in all_spans:\n",
    "                # Vérifier si le <span> a une classe spécifique qui le rend pertinent pour la description\n",
    "                if 'yt-core-attributed-string--link-inherit-color' in span.get('class', []):\n",
    "                    description_texts.append(span.get_text().strip())  # Ajouter le texte du <span> dans la liste\n",
    "\n",
    "            # Combiner tous les morceaux de texte extraits pour former la description finale\n",
    "            description = ' '.join(description_texts)\n",
    "\n",
    "            # Retourner la description complète si elle est trouvée, sinon retourner \"N/A\"\n",
    "            return description if description else 'N/A'\n",
    "        else:\n",
    "            return 'N/A'\n",
    "\n",
    "    except Exception as e:\n",
    "        # En cas d'erreur, afficher un message d'erreur et retourner \"N/A\"\n",
    "        print(f\"Erreur lors de la récupération de la description : {str(e)}\")\n",
    "        return 'N/A'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Récupération de la date de publication de la vidéo\n",
    "\n",
    "La fonction `get_date_publication(driver, video_url)` permet de récupérer la date de publication d'une vidéo YouTube en utilisant Selenium pour naviguer sur la page de la vidéo.\n",
    "Elle localise l'élément HTML contenant la date de publication et retourne le texte correspondant.\n",
    "\n",
    "**Objectif** :\n",
    "- Accéder à la page d'une vidéo YouTube et extraire la date de publication affichée.\n",
    "\n",
    "**Contexte** :\n",
    "- Utile pour la collecte de données sur YouTube afin de récupérer des informations temporelles sur les vidéos.\n",
    "- Pratique pour analyser l'évolution des publications ou pour comparer la popularité de vidéos en fonction de leur date de mise en ligne.\n",
    "\n",
    "**Approche** :\n",
    "1. Charger la page de la vidéo en utilisant `driver.get(video_url)`.\n",
    "2. Attendre que l'élément contenant la date de publication soit visible sur la page.\n",
    "3. Localiser cet élément avec un sélecteur XPath (`By.XPATH`).\n",
    "4. Extraire le texte représentant la date de publication.\n",
    "5. Retourner la date de publication ou \"N/A\" si l'élément n'est pas trouvé ou qu'une erreur survient.\n",
    "\n",
    "**Avantages** :\n",
    "- La fonction utilise des techniques de `WebDriverWait` pour s'assurer que l'élément est bien présent avant de tenter de le lire.\n",
    "- Gère les erreurs et retourne \"N/A\" si la date de publication n'est pas disponible.\n",
    "\n",
    "**Prérequis** :\n",
    "- Le module `selenium` doit être installé (`pip install selenium`).\n",
    "- Le pilote de navigateur (ex. `chromedriver`) doit être configuré correctement.\n",
    "- La page de la vidéo doit être accessible (pas de restrictions d'âge, géographiques, ou de permissions).\n",
    "\n",
    "**Arguments** :\n",
    "- `driver` : Instance de Selenium WebDriver contrôlant le navigateur.\n",
    "- `video_url` : URL de la vidéo YouTube pour laquelle la date de publication doit être extraite.\n",
    "\n",
    "**Exceptions gérées** :\n",
    "- `TimeoutException` : Levée si l'élément contenant la date de publication n'est pas trouvé dans le délai imparti.\n",
    "- `NoSuchElementException` : Levée si l'élément est introuvable sur la page.\n",
    "- `Exception` : Capture toute autre erreur liée au chargement de la page ou à l'extraction de la date.\n",
    "\n",
    "**Retour** :\n",
    "- `date_publication` : Chaîne de caractères représentant la date de publication de la vidéo, ou \"N/A\" si la date n'est pas disponible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Définition de la fonction pour extraire la date de publication d'une vidéo YouTube\n",
    "def get_date_publication(driver, video_url):\n",
    "    try:\n",
    "        # Accéder à l'URL de la vidéo spécifiée par `video_url`\n",
    "        driver.get(video_url)\n",
    "\n",
    "        # Attendre que l'élément contenant la date de publication soit présent sur la page\n",
    "        WebDriverWait(driver, 20).until(\n",
    "            EC.presence_of_element_located((By.XPATH, '/html/body/ytd-app/div[1]/ytd-page-manager/ytd-watch-flexy/div[5]/div[1]/div/div[2]/ytd-watch-metadata/div/div[4]/div[1]/div/ytd-watch-info-text/div/yt-formatted-string/span[3]'))\n",
    "        )\n",
    "\n",
    "        # Localiser l'élément contenant la date de publication de la vidéo\n",
    "        date_element = driver.find_element(By.XPATH, '/html/body/ytd-app/div[1]/ytd-page-manager/ytd-watch-flexy/div[5]/div[1]/div/div[2]/ytd-watch-metadata/div/div[4]/div[1]/div/ytd-watch-info-text/div/yt-formatted-string/span[3]')\n",
    "\n",
    "        # Retourner le texte de la date de publication s'il est trouvé, sinon \"N/A\"\n",
    "        return date_element.text.strip() if date_element else 'N/A'\n",
    "\n",
    "    except Exception as e:\n",
    "        # En cas d'erreur, afficher un message d'erreur et retourner \"N/A\"\n",
    "        print(f\"Erreur lors de la récupération de la date de publication : {str(e)}\")\n",
    "        return 'N/A'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction et organisation de toutes les données\n",
    "\n",
    "La fonction `get_info(link, driver)` permet d'extraire des informations principales à partir d'une page web en utilisant les bibliothèques `requests` et `BeautifulSoup` pour analyser le contenu HTML.\n",
    "Si le type de document est une vidéo, elle utilise Selenium pour interagir avec la page YouTube et récupérer des informations supplémentaires telles que le nombre de vues, le nombre de likes, le propriétaire de la vidéo, etc.\n",
    "\n",
    "**Objectif** :\n",
    "- Extraire les informations principales d'une ressource (titre, description, type, lieu, source, thématique, etc.).\n",
    "- Extraire des informations supplémentaires spécifiques aux vidéos si le document est une vidéo.\n",
    "- Télécharger les fichiers PDF associés à la ressource si présents.\n",
    "\n",
    "**Contexte** :\n",
    "- Utile dans le cadre d'un projet de collecte de données pour construire un tableau d'informations à partir de différentes ressources web.\n",
    "- Conçu pour récupérer à la fois des informations textuelles (titre, description, source) et des métadonnées pour des vidéos YouTube.\n",
    "\n",
    "**Approche** :\n",
    "1. Charger la page web en utilisant `requests.get(link)` et créer un objet `BeautifulSoup` pour analyser le contenu.\n",
    "2. Extraire les informations principales telles que le titre, la description, le type de document, la source, le lieu et la thématique.\n",
    "3. Vérifier si le document est une vidéo, et dans ce cas utiliser Selenium (`driver`) pour interagir avec la page YouTube correspondante.\n",
    "4. Récupérer les informations spécifiques à la vidéo (propriétaire, nombre de vues, etc.) si la vidéo est disponible.\n",
    "5. Télécharger les fichiers PDF associés s'ils sont présents sur la page.\n",
    "6. Retourner une ligne de données avec toutes les informations extraites.\n",
    "\n",
    "**Avantages** :\n",
    "- Combine à la fois des techniques de scraping (BeautifulSoup) et d'automatisation de navigateur (Selenium).\n",
    "- Gère différents types de contenu (textuel, vidéo, PDF).\n",
    "\n",
    "**Prérequis** :\n",
    "- Les modules `requests` et `bs4` doivent être installés (`pip install requests beautifulsoup4`).\n",
    "- Selenium doit être configuré avec un pilote approprié (ex: `chromedriver`).\n",
    "- La page de la vidéo doit être accessible (pas de restrictions d'âge, géographiques, ou de permissions).\n",
    "\n",
    "**Arguments** :\n",
    "- `link` : URL de la ressource à analyser.\n",
    "- `driver` : Instance de Selenium WebDriver pour interagir avec les vidéos YouTube.\n",
    "\n",
    "**Exceptions gérées** :\n",
    "- `requests.exceptions.RequestException` : Capture les erreurs liées à la requête HTTP.\n",
    "- `AttributeError` : Capture les erreurs lors de la recherche d'éléments HTML avec BeautifulSoup.\n",
    "- `Exception` : Capture toute autre erreur liée à l'extraction ou au téléchargement de contenu.\n",
    "\n",
    "**Retour** :\n",
    "- `line` : Liste contenant les informations extraites ou `None` en cas d'erreur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Définition de la fonction pour extraire les informations d'une page web\n",
    "def get_info(link, driver):\n",
    "    try:\n",
    "        # Charger la page web spécifiée par `link` et créer un objet `BeautifulSoup` pour analyser le contenu HTML\n",
    "        page = requests.get(link)\n",
    "        soup = bs(page.content, 'html.parser')\n",
    "\n",
    "        # Extraire le titre de la page\n",
    "        Titre = soup.find('div', id=\"block-rexbp-page-title\")\n",
    "        Titre = Titre.find('span').string.strip() if Titre else 'N/A'\n",
    "\n",
    "        # Extraire la description de la ressource\n",
    "        Description = soup.find('div', class_=\"field_texte\")\n",
    "        Description_text = []\n",
    "\n",
    "        # Si une description est trouvée, extraire le texte de chaque paragraphe\n",
    "        if Description:\n",
    "            paragraphs = Description.find_all('p')\n",
    "            if len(paragraphs) > 1:\n",
    "                for p in paragraphs[:-1]:  # Ignorer le dernier paragraphe\n",
    "                    Description_text.append(p.get_text().strip())\n",
    "            elif len(paragraphs) == 1:\n",
    "                Description_text.append(paragraphs[0].get_text().strip())\n",
    "            else:\n",
    "                Description_text = 'N/A'\n",
    "        else:\n",
    "            Description_text = 'N/A'\n",
    "        Description_text = ' '.join(Description_text)  # Combiner tous les paragraphes en une seule chaîne\n",
    "\n",
    "        # Extraire le type de document\n",
    "        Type_document = soup.find('div', class_=\"field_type_document\")\n",
    "        Type_document = Type_document.find('div', class_=\"name\").string if Type_document else 'N/A'\n",
    "\n",
    "        # Extraire le lieu de la ressource\n",
    "        territory = soup.find(class_=\"field_territoire\")\n",
    "        Lieu = territory.text.strip() if territory else 'N/A'\n",
    "\n",
    "        # Extraire la source de la ressource\n",
    "        field_texte_div = soup.find('div', class_='field_texte')\n",
    "        if field_texte_div:\n",
    "            paragraphs = field_texte_div.find_all('p')\n",
    "            if paragraphs:\n",
    "                last_paragraph = paragraphs[-1]\n",
    "                Source = last_paragraph.get_text().strip()\n",
    "            else:\n",
    "                Source = 'N/A'\n",
    "        else:\n",
    "            Source = 'N/A'\n",
    "\n",
    "        # Extraire la thématique de la ressource\n",
    "        thematique_div = soup.find('div', class_='field_thematique')\n",
    "        Thematique = thematique_div.find('div', class_='name').string.strip() if thematique_div else 'N/A'\n",
    "\n",
    "        # Initialiser les informations vidéo\n",
    "        Propriétaire_video = 'N/A'\n",
    "        Titre_vidéo = 'N/A'\n",
    "        Nb_commentaire_video = 'N/A'\n",
    "        Nb_vues_video = 'N/A'\n",
    "        Nb_likes_video = 'N/A'\n",
    "        Description_video = 'N/A'\n",
    "        Lien_video = 'N/A'\n",
    "        Date_publication_video = 'N/A'\n",
    "\n",
    "        # Vérifier si le document est une vidéo et extraire les informations associées\n",
    "        if Type_document.lower() == 'vidéo':\n",
    "            video_div = soup.find('div', class_='video-miniature')\n",
    "            if video_div:\n",
    "                video_url = video_div.get('data-url')\n",
    "                if video_url:\n",
    "                    driver.get(video_url)\n",
    "                    time.sleep(3)\n",
    "\n",
    "                    # Refuser les cookies sur YouTube si le pop-up est présent\n",
    "                    click_refuse_youtube_cookies(driver)\n",
    "\n",
    "                    if \"cette vidéo n'est plus disponible\" not in driver.page_source.lower():\n",
    "                        # Extraire les informations vidéo si la vidéo est disponible\n",
    "                        Propriétaire_video = get_video_owner(driver, video_url)\n",
    "                        Titre_vidéo = get_titre_video(driver, video_url)\n",
    "                        Nb_commentaire_video = get_nombre_commentaire(driver, video_url)\n",
    "                        Nb_vues_video = get_nombre_vues(driver, video_url)\n",
    "                        Nb_likes_video = get_nombre_likes(driver, video_url)\n",
    "                        Description_video = get_description_video(driver, video_url)\n",
    "                        Date_publication_video = get_date_publication(driver, video_url)\n",
    "                        Lien_video = video_url\n",
    "                    else:\n",
    "                        print(\"Cette vidéo n'est plus disponible.\")\n",
    "\n",
    "        # Télécharger les fichiers PDF associés s'ils existent\n",
    "        pdf_div = soup.find('div', class_='field_pdf')\n",
    "        if pdf_div:\n",
    "            pdf_links = pdf_div.find_all('a')\n",
    "            for index, a_tag in enumerate(pdf_links):\n",
    "                pdf_url = a_tag.get('href')\n",
    "                pdf_filename = f\"{Titre}_pdf_{index + 1}.pdf\"\n",
    "                download_pdf(pdf_url, pdf_filename)\n",
    "\n",
    "        # Retourner les informations collectées sous forme de liste\n",
    "        line = [Titre, Thematique, Description_text, Type_document, Source, Lieu, link, Propriétaire_video, Titre_vidéo, Nb_commentaire_video, Nb_vues_video, Nb_likes_video, Description_video, Lien_video, Date_publication_video]\n",
    "        return line\n",
    "\n",
    "    except Exception as e:\n",
    "        # En cas d'erreur, afficher un message et retourner `None`\n",
    "        print(f\"Une erreur est survenue lors de l'extraction des informations : {str(e)}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pagination et collecte de liens  \n",
    "\n",
    "La fonction `paginate_and_collect_data(driver, link_list)` permet de naviguer à travers plusieurs pages web et de collecter les liens des articles disponibles.\n",
    "Elle utilise Selenium pour gérer la pagination et BeautifulSoup pour analyser le contenu de chaque page et extraire les URL d'articles spécifiques.\n",
    "\n",
    "**Objectif** :\n",
    "- Parcourir les pages d'un site avec un bouton de pagination \"Suivant\".\n",
    "- Collecter les liens des articles pertinents et les ajouter à une liste de liens (`link_list`).\n",
    "\n",
    "**Contexte** :\n",
    "- Utilisée pour extraire toutes les ressources (articles, documents) présentes sur un site où le contenu est réparti sur plusieurs pages.\n",
    "- Conçue pour fonctionner sur des pages avec chargement dynamique, où les articles ne sont visibles qu'après avoir cliqué sur le bouton \"Suivant\".\n",
    "\n",
    "**Approche** :\n",
    "1. Parcourir la page initiale, puis cliquer sur le bouton \"Suivant\" pour accéder aux pages suivantes.\n",
    "2. Utiliser `WebDriverWait` pour s'assurer que les articles sont chargés avant d'extraire les informations.\n",
    "3. Collecter les liens des articles en vérifiant qu'ils contiennent le chemin \"/ressource/\" et qu'ils ne sont pas déjà présents dans `link_list`.\n",
    "4. Répéter le processus de pagination jusqu'à ce qu'il n'y ait plus de bouton \"Suivant\" ou qu'une erreur survienne.\n",
    "5. Retourner la liste `link_list` contenant tous les liens collectés.\n",
    "\n",
    "**Avantages** :\n",
    "- Assure que tous les articles sur plusieurs pages sont correctement collectés.\n",
    "- Gère les interruptions de pagination et continue jusqu'à ce que toutes les pages aient été traitées.\n",
    "\n",
    "**Prérequis** :\n",
    "- Le module `selenium` doit être installé (`pip install selenium`).\n",
    "- BeautifulSoup (`bs4`) doit être installé (`pip install beautifulsoup4`).\n",
    "- Le pilote Selenium (ex: `chromedriver`) doit être configuré et compatible avec le navigateur utilisé.\n",
    "\n",
    "**Arguments** :\n",
    "- `driver` : Instance de Selenium WebDriver contrôlant le navigateur.\n",
    "- `link_list` : Liste existante (vide ou partiellement remplie) contenant les liens d'articles à collecter.\n",
    "\n",
    "**Exceptions gérées** :\n",
    "- `TimeoutException` : Capture les erreurs liées à l'attente d'éléments non présents sur la page.\n",
    "- `NoSuchElementException` : Capture les erreurs lors de la recherche du bouton de pagination.\n",
    "- `Exception` : Capture toute autre erreur imprévue liée à la navigation ou à l'extraction des liens.\n",
    "\n",
    "**Retour** :\n",
    "- `link_list` : Liste de chaînes de caractères contenant les liens de tous les articles collectés au cours de la pagination.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition de la fonction pour gérer la pagination et collecter les liens d'articles\n",
    "def paginate_and_collect_data(driver, link_list):\n",
    "    # Initialiser le compteur de pages\n",
    "    page_count = 0\n",
    "\n",
    "    # Boucle de pagination\n",
    "    while True:\n",
    "        print(f\"Traitement de la page {page_count + 1}\")\n",
    "\n",
    "        # Attendre que les articles soient chargés sur la page\n",
    "        WebDriverWait(driver, 20).until(\n",
    "            EC.presence_of_all_elements_located((By.CSS_SELECTOR, \".views-infinite-scroll-content-wrapper.clearfix .views-row article\"))\n",
    "        )\n",
    "\n",
    "        # Utiliser BeautifulSoup pour analyser le contenu de la page\n",
    "        soup = bs(driver.page_source, 'html.parser')\n",
    "        articles = soup.find_all('article')\n",
    "\n",
    "        # Collecter les liens des articles en vérifiant leur pertinence\n",
    "        for article in articles:\n",
    "            about_attr = article.get('about')\n",
    "            # Vérifier que le lien contient \"/ressource/\" et qu'il n'a pas déjà été collecté\n",
    "            if about_attr and \"/ressource/\" in about_attr and about_attr not in link_list:\n",
    "                link_list.append(\"https://www.dispositif-rexbp.com\" + about_attr)  # Ajouter le lien complet\n",
    "\n",
    "        print(f\"Nombre d'éléments dans link_list après la page {page_count + 1} : {len(link_list)}\")\n",
    "        page_count += 1  # Incrémenter le compteur de pages\n",
    "\n",
    "        # Tenter de trouver le bouton de la page suivante\n",
    "        try:\n",
    "            # Localiser le bouton \"Suivant\" en utilisant un sélecteur CSS\n",
    "            next_button = driver.find_element(By.CSS_SELECTOR, 'li.pager__item a[rel=\"next\"]')\n",
    "            if next_button:\n",
    "                # Cliquer sur le bouton \"Suivant\" si trouvé\n",
    "                next_button.click()\n",
    "                print(f\"Cliqué sur le bouton suivant pour la page {page_count + 1}\")\n",
    "                time.sleep(5)  # Pause pour laisser le temps au contenu de charger\n",
    "            else:\n",
    "                # Si aucun bouton \"Suivant\" n'est trouvé, fin de la pagination\n",
    "                print(\"Aucun bouton 'Suivant' trouvé, fin de la pagination.\")\n",
    "                break\n",
    "        except Exception:\n",
    "            # Gérer l'exception si le bouton \"Suivant\" est introuvable ou si une autre erreur survient\n",
    "            print(f\"Erreur lors du clic sur le bouton suivant ou fin de la pagination.\")\n",
    "            break\n",
    "\n",
    "    # Retourner la liste des liens d'articles collectés\n",
    "    return link_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonction principale\n",
    "\n",
    "La fonction `extract_urls_and_info()` est la fonction principale de ce script. Elle initialise le navigateur Web Selenium, recherche les ressources par thématique sur le site, extrait les URLs correspondantes et collecte les informations de chaque ressource trouvée. Les informations collectées sont ensuite exportées vers un fichier Excel.\n",
    "\n",
    "**Objectif** :\n",
    "- Effectuer des recherches thématiques sur un site web pour collecter des données.\n",
    "- Extraire les informations détaillées de chaque ressource disponible (articles, vidéos, etc.).\n",
    "- Organiser les données collectées et les exporter dans un fichier Excel pour une consultation et une analyse ultérieures.\n",
    "\n",
    "**Contexte** :\n",
    "- Conçue pour automatiser le processus de collecte d'informations sur le site `dispositif-rexbp.com`.\n",
    "- Pratique pour les projets nécessitant un stockage structuré de données provenant de plusieurs pages.\n",
    "\n",
    "**Approche** :\n",
    "1. **Initialiser le navigateur Selenium** :\n",
    "   - Ouvrir une instance de navigateur pour interagir avec le site web et effectuer les recherches.\n",
    "2. **Définir les thèmes de recherche** :\n",
    "   - Les thèmes sont définis dans la liste `themes` et chaque thème est traité individuellement.\n",
    "3. **Recherche et vérification des résultats** :\n",
    "   - Pour chaque thème, la fonction effectue une recherche et vérifie si des résultats sont trouvés.\n",
    "   - Si aucun résultat n'est trouvé, passer au thème suivant.\n",
    "4. **Collecte des URLs et extraction des informations** :\n",
    "   - Si des résultats sont trouvés, parcourir toutes les pages et extraire les URLs des ressources.\n",
    "   - Collecter les informations détaillées de chaque URL et les ajouter à la liste `all_data`.\n",
    "5. **Exporter les données** :\n",
    "   - Si des données sont collectées, les exporter dans un fichier Excel.\n",
    "6. **Arrêter le navigateur** :\n",
    "   - Fermer proprement l'instance de Selenium pour libérer les ressources.\n",
    "\n",
    "**Avantages** :\n",
    "- Permet de collecter automatiquement des informations à partir de plusieurs thèmes en une seule exécution.\n",
    "- Gère les erreurs de recherche, les cas où il n'y a pas de résultats, et les exporte efficacement dans un fichier Excel.\n",
    "\n",
    "**Prérequis** :\n",
    "- Le module `selenium` doit être installé (`pip install selenium`).\n",
    "- Le pilote de navigateur (ex: `chromedriver`) doit être configuré correctement.\n",
    "- Les fonctions auxiliaires (`search_by_theme`, `check_no_results`, `paginate_and_collect_data`, `get_info`, et `export_to_excel`) doivent être définies.\n",
    "\n",
    "**Arguments** :\n",
    "- Aucun argument requis. Cette fonction est autonome et s'exécute directement.\n",
    "\n",
    "**Exceptions gérées** :\n",
    "- Les exceptions de Selenium et les erreurs de connexion sont gérées dans les fonctions appelées.\n",
    "\n",
    "**Retour** :\n",
    "- Aucun retour, mais les données sont exportées dans un fichier Excel si la collecte est réussie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction principale pour l'extraction des URLs et des informations associées\n",
    "def extract_urls_and_info():\n",
    "    # Initialiser le navigateur Chrome\n",
    "    driver = webdriver.Chrome()\n",
    "\n",
    "    try:\n",
    "        # Définir la liste des thèmes à rechercher sur le site\n",
    "        themes = [\"Métiers de l'encadrement\", \"BIM\"]\n",
    "        all_data = []  # Liste pour stocker toutes les informations collectées\n",
    "\n",
    "        # Parcourir chaque thème pour effectuer la recherche\n",
    "        for theme in themes:\n",
    "            print(f\"Recherche pour le thème : {theme}\")\n",
    "\n",
    "            # Accéder à la page de recherche de ressources sur le site\n",
    "            driver.get(\"https://www.dispositif-rexbp.com/ressources\")\n",
    "\n",
    "            # Effectuer la recherche par thème en utilisant la fonction `search_by_theme`\n",
    "            search_by_theme(driver, theme)\n",
    "\n",
    "            # Vérifier si aucun résultat n'est trouvé pour le thème en cours\n",
    "            if check_no_results(driver):\n",
    "                print(f\"Pas de résultats pour le thème : {theme}. Passage au thème suivant.\")\n",
    "                continue  # Passer au thème suivant si aucun résultat n'est trouvé\n",
    "\n",
    "            # Initialiser une liste pour stocker les URLs des ressources collectées\n",
    "            link_list = []\n",
    "            link_list = paginate_and_collect_data(driver, link_list)  # Collecter les URLs sur plusieurs pages\n",
    "\n",
    "            print(f\"Nombre total d'éléments dans link_list pour le thème {theme} : {len(link_list)}\")\n",
    "\n",
    "            # Parcourir chaque URL collectée pour extraire les informations détaillées\n",
    "            for index, url in enumerate(link_list):\n",
    "                print(f\"Traitement de l'URL {index + 1}/{len(link_list)}: {url}\")\n",
    "                \n",
    "                # Extraire les informations de la ressource à partir de l'URL\n",
    "                data = get_info(url, driver)\n",
    "                \n",
    "                # Si les informations ont été récupérées avec succès, les ajouter à la liste `all_data`\n",
    "                if data:\n",
    "                    all_data.append(data)\n",
    "                    print(f\"Données ajoutées avec succès pour l'URL : {url}\")\n",
    "                else:\n",
    "                    print(f\"Échec de la récupération des données pour l'URL : {url}\")\n",
    "\n",
    "        # Afficher le nombre total de ressources collectées\n",
    "        print(f\"Nombre total d'éléments à exporter : {len(all_data)}\")\n",
    "\n",
    "        # Si des données ont été collectées, les exporter dans un fichier Excel\n",
    "        if all_data:\n",
    "            export_to_excel(all_data)\n",
    "\n",
    "    # Assurer la fermeture du navigateur même en cas d'erreur\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "# Point d'entrée du script principal\n",
    "if __name__ == \"__main__\":\n",
    "    extract_urls_and_info()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
