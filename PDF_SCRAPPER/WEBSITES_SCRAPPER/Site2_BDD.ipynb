{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importation des bibliothèques nécessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# `requests` est une bibliothèque pour effectuer des requêtes HTTP (GET, POST, etc.)\n",
    "import requests\n",
    "\n",
    "# `BeautifulSoup` de la bibliothèque `bs4` permet de parser (analyser) le contenu HTML et XML.\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "# `os` fournit des fonctions pour interagir avec le système d'exploitation, comme la gestion des fichiers et des répertoires.\n",
    "import os\n",
    "\n",
    "# `time` est utilisé pour effectuer des opérations liées au temps, comme mettre des pauses dans le script.\n",
    "import time\n",
    "\n",
    "# `MongoClient` de la bibliothèque `pymongo` permet de se connecter et d'interagir avec une base de données MongoDB.\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# `webdriver` de la bibliothèque `selenium` permet de contrôler un navigateur web pour l'automatisation.\n",
    "from selenium import webdriver\n",
    "\n",
    "# `By` fournit des moyens pour sélectionner des éléments HTML, comme `By.ID`, `By.XPATH`, etc.\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# `WebDriverWait` permet de définir une attente explicite pour certaines conditions d'éléments (ex: présence d'un bouton).\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "\n",
    "# `expected_conditions` permet de définir des conditions, comme la présence d'un élément ou qu'un élément soit cliquable.\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# `TimeoutException` est une exception levée lorsque l'attente explicite dépasse le temps imparti.\n",
    "from selenium.common.exceptions import TimeoutException\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connexion à la base de données\n",
    "\n",
    "Cette fonction établit une connexion à une base de données MongoDB distante et sélectionne une collection spécifique.\n",
    "L'objectif est de configurer correctement l'accès à une base de données en utilisant l'URI MongoDB.\n",
    "\n",
    "- **Objectif** : Se connecter à une base de données MongoDB distante et récupérer une collection pour y stocker ou récupérer des documents.\n",
    "- **Contexte** : Utilisé dans des applications où les données doivent être stockées de manière persistante et consultables via MongoDB.\n",
    "  \n",
    "- **Approche** :\n",
    "  1. Utiliser l'URI fourni pour se connecter au cluster MongoDB.\n",
    "  2. Sélectionner la base de données spécifiée dans `client['nom_de_ta_base']`.\n",
    "  3. Accéder à la collection souhaitée dans la base de données pour effectuer des opérations.\n",
    "  4. Vérifier que la connexion est réussie en affichant le nom de la base de données et de la collection.\n",
    "  \n",
    "- **Avantages** :\n",
    "  - Simplifie la connexion à MongoDB.\n",
    "  - Permet de gérer et interagir avec des collections dans une base de données distante.\n",
    "  - Affiche les informations de connexion dans la console pour un suivi rapide.\n",
    "\n",
    "Prérequis :\n",
    "- Le module `pymongo` doit être installé (`pip install pymongo`).\n",
    "- Le nom de la base de données (`nom_de_ta_base`) doit être correct et existant dans MongoDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Connexion à MongoDB à l'aide de l'URI fourni (remplace l'URI par celui correspondant à ton environnement).\n",
    "# Pour éviter tout problème de sécurité, il est conseillé d'utiliser des variables d'environnement pour stocker l'URI.\n",
    "client = MongoClient('mongodb+srv://serginemengue46:tu3uF7Ap0g2RQDou@cluster0.7xuvx.mongodb.net')\n",
    "\n",
    "# Sélection de la base de données spécifique.\n",
    "# Remplace `nom_de_ta_base` par le nom exact de la base de données à utiliser.\n",
    "db = client['nom_de_ta_base']\n",
    "\n",
    "# Sélection de la collection 'Dispositif-Rex' dans la base de données.\n",
    "collection = db['Dispositif-Rex']\n",
    "\n",
    "# Affichage des informations de connexion pour confirmation.\n",
    "print(\"# Connexion à MongoDB établie avec succès !\")  # Confirmation de la connexion établie\n",
    "print(f\"# Base de données sélectionnée : {db.name}\")  # Affiche le nom de la base de données utilisée\n",
    "print(f\"# Collection sélectionnée : {collection.name}\")  # Affiche le nom de la collection sélectionnée\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création de dossier local\n",
    "\n",
    "Cette section de code vérifie l'existence d'un dossier local nommé `PDFs` et le crée s'il n'existe pas déjà.\n",
    "L'objectif est de garantir qu'un répertoire spécifique est disponible pour stocker les fichiers PDF téléchargés localement.\n",
    "\n",
    "- **Objectif** : Créer un dossier local pour sauvegarder les fichiers PDF de manière organisée.\n",
    "- **Contexte** : Utilisé dans des applications où les fichiers doivent être téléchargés, enregistrés localement, et traités de manière répétée.\n",
    "  \n",
    "- **Approche** :\n",
    "  1. Définir le nom du dossier où les fichiers PDF seront enregistrés (`pdf_folder`).\n",
    "  2. Vérifier si le dossier existe déjà à l'emplacement courant à l'aide de `os.path.exists()`.\n",
    "  3. Si le dossier n'existe pas, le créer à l'aide de `os.makedirs()` pour s'assurer que tous les fichiers PDF puissent y être enregistrés.\n",
    "  \n",
    "- **Avantages** :\n",
    "  - Évite les erreurs liées à un répertoire manquant lors de l'enregistrement des fichiers.\n",
    "  - Assure que tous les fichiers PDF sont stockés au même endroit, facilitant la gestion et la récupération.\n",
    "\n",
    "Prérequis :\n",
    "- Le module `os` doit être importé (`import os`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Dossier pour enregistrer les fichiers PDF localement\n",
    "pdf_folder = \"PDFs\"  # Définition du nom du dossier pour les fichiers PDF\n",
    "\n",
    "# Vérifier si le dossier `PDFs` existe déjà\n",
    "if not os.path.exists(pdf_folder):  # `os.path.exists` retourne True si le dossier existe, False sinon.\n",
    "    # Créer le dossier s'il n'existe pas pour éviter les erreurs lors de l'enregistrement des fichiers.\n",
    "    os.makedirs(pdf_folder)  # `os.makedirs` permet de créer le répertoire spécifié (et tous les dossiers parents si nécessaire).\n",
    "    print(f\"# Le dossier '{pdf_folder}' a été créé avec succès.\")  # Confirmation de la création du dossier\n",
    "else:\n",
    "    print(f\"# Le dossier '{pdf_folder}' existe déjà.\")  # Confirmation si le dossier est déjà présent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refus de cookies\n",
    "\n",
    "Cette fonction automatise le refus des cookies sur YouTube en utilisant Selenium.\n",
    "L'objectif est de fermer la boîte de dialogue des cookies en cliquant sur le bouton \"Tout refuser\" pour permettre la navigation automatisée sur la plateforme.\n",
    "\n",
    "- **Objectif** : Refuser automatiquement les cookies sur YouTube lors de l'utilisation d'un navigateur automatisé.\n",
    "- **Contexte** : Utilisé lors du scraping ou de l'automatisation de tâches sur YouTube, où la boîte de dialogue des cookies empêche l'interaction avec d'autres éléments de la page.\n",
    "\n",
    "- **Approche** :\n",
    "  1. Mettre en pause l'exécution pendant 2 secondes pour permettre le chargement complet de la page.\n",
    "  2. Attendre que le bouton \"Tout refuser\" soit cliquable à l'aide de `WebDriverWait`.\n",
    "  3. Cliquer sur le bouton à l'aide de `driver.execute_script` pour simuler un clic JavaScript, évitant ainsi certains problèmes d'interaction.\n",
    "  4. Attendre que le bouton soit bien cliqué et vérifier si la boîte de dialogue a disparu.\n",
    "  5. Afficher un message de confirmation si le clic a réussi.\n",
    "  6. Gérer les exceptions si le bouton n'est pas trouvé ou si un problème survient.\n",
    "\n",
    "- **Avantages** :\n",
    "  - Automatise le processus de refus des cookies pour ne pas bloquer le reste de la navigation.\n",
    "  - Évite les interruptions lors de l'automatisation des tâches sur YouTube.\n",
    "  - Affiche un message d'erreur si le processus échoue, facilitant le débogage.\n",
    "\n",
    "Prérequis :\n",
    "- Le module `time` doit être importé (`import time`).\n",
    "- Le module `selenium` doit être installé et importé (`pip install selenium`).\n",
    "- Le driver Selenium (par exemple, ChromeDriver) doit être configuré pour interagir avec le navigateur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Fonction pour refuser les cookies sur YouTube\n",
    "def click_refuse_youtube_cookies(driver):\n",
    "    try:\n",
    "        # Pause de 2 secondes pour laisser la boîte de dialogue des cookies apparaître\n",
    "        time.sleep(2)\n",
    "\n",
    "        # Attendre que le bouton \"Tout refuser\" devienne cliquable\n",
    "        refuse_button = WebDriverWait(driver, 5).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, \"//button//span[text()='Tout refuser']\"))\n",
    "        )\n",
    "\n",
    "        # Utiliser `execute_script` pour cliquer sur le bouton \"Tout refuser\"\n",
    "        driver.execute_script(\"arguments[0].click();\", refuse_button)\n",
    "\n",
    "        # Attendre que le clic soit pris en compte et que l'élément soit à nouveau cliquable\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, '/html/body/ytd-app/ytd-consent-bump-v2-lightbox/tp-yt-paper-dialog/div[4]/div[2]/div[6]/div[1]/ytd-button-renderer[1]/yt-button-shape/button/yt-touch-feedback-shape/div/div[2]'))\n",
    "        )\n",
    "\n",
    "        # Cliquer sur le bouton \"Tout refuser\"\n",
    "        refuse_button.click()\n",
    "\n",
    "        # Afficher un message de confirmation si le clic a réussi\n",
    "        print(\"Bouton 'Tout refuser' cliqué sur YouTube.\")\n",
    "    \n",
    "    # Gérer les erreurs si le bouton n'est pas trouvé ou si une autre exception survient\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors du refus des cookies sur YouTube : {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recherche par thème\n",
    "\n",
    "Cette fonction effectue une recherche sur un site web en utilisant Selenium et en se basant sur un thème spécifié.\n",
    "L'objectif est de localiser le champ de recherche, d'y entrer le thème souhaité, puis de lancer la recherche automatiquement.\n",
    "\n",
    "- **Objectif** : Automatiser la recherche d'un thème spécifique sur un site web.\n",
    "- **Contexte** : Utilisé dans des applications de scraping ou de navigation automatisée pour interagir avec un champ de recherche et obtenir les résultats correspondant au thème fourni.\n",
    "\n",
    "- **Approche** :\n",
    "  1. Utiliser `WebDriverWait` pour attendre la présence de l'élément correspondant au champ de recherche.\n",
    "  2. Vider le champ de recherche avec `clear()` afin d'éviter les doublons ou les erreurs de saisie.\n",
    "  3. Entrer le thème à rechercher à l'aide de `send_keys()`.\n",
    "  4. Localiser et attendre que le bouton de recherche soit cliquable.\n",
    "  5. Lancer la recherche en simulant un clic sur le bouton.\n",
    "  6. Afficher un message de confirmation lorsque la recherche est effectuée avec succès.\n",
    "  \n",
    "- **Avantages** :\n",
    "  - Automatise l'interaction avec le champ de recherche, permettant de gagner du temps.\n",
    "  - Peut être utilisé pour rechercher rapidement plusieurs thèmes de manière séquentielle.\n",
    "  - Gère les exceptions pour détecter les erreurs de saisie ou d'éléments non trouvés.\n",
    "\n",
    "Prérequis :\n",
    "- Le module `selenium` doit être installé et importé (`pip install selenium`).\n",
    "- Le driver Selenium (par exemple, ChromeDriver) doit être configuré pour interagir avec le navigateur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Fonction pour effectuer une recherche sur le site en utilisant un thème spécifique\n",
    "def search_by_theme(driver, theme):\n",
    "    try:\n",
    "        # Attendre que le champ de recherche avec le nom 'mot_cle' soit présent dans le DOM\n",
    "        search_input = WebDriverWait(driver, 20).until(\n",
    "            EC.presence_of_element_located((By.NAME, \"mot_cle\"))\n",
    "        )\n",
    "\n",
    "        # Vider le champ de texte s'il contient déjà des informations\n",
    "        search_input.clear()  # Efface le contenu du champ pour éviter les conflits de recherche\n",
    "\n",
    "        # Entrer le thème à rechercher dans le champ de recherche\n",
    "        search_input.send_keys(theme)  # Envoie le thème spécifié au champ de recherche\n",
    "\n",
    "        # Attendre que le bouton de recherche soit cliquable\n",
    "        search_button = WebDriverWait(driver, 20).until(\n",
    "            EC.element_to_be_clickable((By.CSS_SELECTOR, \"input[title='Lancer la recherche'][type='submit']\"))\n",
    "        )\n",
    "\n",
    "        # Cliquer sur le bouton pour lancer la recherche\n",
    "        search_button.click()\n",
    "\n",
    "        # Afficher un message de confirmation dans la console une fois la recherche lancée\n",
    "        print(f\"Recherche lancée pour le thème : {theme}\")\n",
    "\n",
    "    # Gérer les erreurs si le champ de recherche ou le bouton de recherche ne sont pas trouvés\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la recherche : {e}\")  # Afficher le message d'erreur correspondant\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Vérification des résulats disponibles\n",
    "\n",
    "Cette fonction vérifie s'il y a des résultats disponibles pour une recherche sur une page web.\n",
    "Elle utilise Selenium pour faire défiler la page et vérifier l'existence d'un message indiquant qu'il n'y a pas de résultats,\n",
    "ou bien pour déterminer si la liste des résultats est vide.\n",
    "\n",
    "- **Objectif** : Détecter s'il n'y a pas de résultats correspondant aux critères de recherche sur une page.\n",
    "- **Contexte** : Utilisé lors de la navigation automatisée ou du scraping pour identifier rapidement les pages sans résultats et gérer ces cas efficacement.\n",
    "\n",
    "- **Approche** :\n",
    "  1. Faire défiler la page vers le bas pour charger tout le contenu visible à l'aide de `driver.execute_script`.\n",
    "  2. Mettre en pause l'exécution pendant 2 secondes pour laisser le temps à la page de se mettre à jour.\n",
    "  3. Rechercher un élément contenant le texte \"Nous n'avons pas de ressources disponibles avec ces critères\".\n",
    "  4. Si le texte est trouvé, afficher un message dans la console indiquant l'absence de résultats.\n",
    "  5. Si le texte n'est pas trouvé, rechercher s'il y a des éléments correspondant aux résultats (`.views-row`).\n",
    "  6. Si aucun résultat n'est trouvé après le défilement, retourner `True` (pas de résultats).\n",
    "  7. Si des résultats sont présents, retourner `False`.\n",
    "  \n",
    "- **Avantages** :\n",
    "  - Permet de détecter automatiquement l'absence de résultats, ce qui est utile pour ajuster le comportement de l'application.\n",
    "  - Évite les tentatives d'extraction de données sur des pages vides, ce qui réduit les erreurs.\n",
    "\n",
    "Prérequis :\n",
    "- Le module `selenium` doit être installé et importé (`pip install selenium`).\n",
    "- Le module `time` doit être importé (`import time`).\n",
    "- Le driver Selenium (par exemple, ChromeDriver) doit être configuré pour interagir avec le navigateur.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Fonction pour vérifier s'il n'y a pas de résultats disponibles pour une recherche\n",
    "def check_no_results(driver):\n",
    "    # Texte indiquant qu'il n'y a pas de résultats disponibles pour les critères de recherche donnés\n",
    "    no_results_text = \"Nous n'avons pas de ressources disponibles avec ces critères\"\n",
    "    \n",
    "    try:\n",
    "        # Faire défiler la page vers le bas pour charger le contenu (scroll vers le bas)\n",
    "        driver.execute_script(\"window.scrollBy(0, window.innerHeight);\")\n",
    "\n",
    "        # Pause de 2 secondes pour permettre à la page de se mettre à jour\n",
    "        time.sleep(2)\n",
    "\n",
    "        # Rechercher le conteneur affichant un message d'absence de résultats (élément CSS `div.views-empty`)\n",
    "        header = driver.find_elements(By.CSS_SELECTOR, \"div.views-empty\")\n",
    "        \n",
    "        # Si le texte indiquant \"pas de ressources disponibles\" est trouvé dans le conteneur, il n'y a pas de résultats\n",
    "        if header and no_results_text in header[0].text:\n",
    "            print(\"Aucun résultat trouvé pour ce thème.\")  # Confirmation affichée dans la console\n",
    "            return True  # Retourner True pour indiquer l'absence de résultats\n",
    "\n",
    "        # Rechercher des éléments correspondant à des résultats potentiels (`.views-row`)\n",
    "        results = driver.find_elements(By.CSS_SELECTOR, \".views-row\")\n",
    "        \n",
    "        # Si aucun résultat n'est trouvé après le scroll, afficher un message\n",
    "        if not results:\n",
    "            print(\"Aucun résultat trouvé après un scroll.\")  # Confirmation affichée dans la console\n",
    "            return True  # Retourner True car il n'y a pas de résultats visibles\n",
    "\n",
    "        # Retourner False si des résultats sont trouvés\n",
    "        return False\n",
    "\n",
    "    # Gérer les erreurs si un élément n'est pas trouvé ou si une autre exception survient\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la vérification des résultats : {str(e)}\")  # Afficher l'erreur dans la console\n",
    "        return False  # Retourner False en cas d'exception\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Télécgargement de pdf\n",
    "\n",
    "Cette fonction télécharge un fichier PDF à partir d'une URL donnée et l'enregistre localement sous un nom de fichier spécifique.\n",
    "L'objectif est de récupérer un fichier PDF à partir d'un lien, de le télécharger et de le sauvegarder localement.\n",
    "\n",
    "- **Objectif** : Télécharger un fichier PDF depuis une URL donnée et l'enregistrer localement sous un nom correspondant au titre spécifié.\n",
    "- **Contexte** : Utilisé dans des applications où les fichiers PDF doivent être téléchargés automatiquement pour être archivés localement ou analysés par la suite.\n",
    "  \n",
    "- **Approche** :\n",
    "  1. Vérifier si l'URL est correcte et commencer par `http://` ou `https://`. Si ce n'est pas le cas, ajouter le préfixe `https://`.\n",
    "  2. Envoyer une requête HTTP GET à l'URL pour récupérer le contenu du PDF.\n",
    "  3. Vérifier si la requête est réussie (code 200). Si oui, sauvegarder le fichier localement.\n",
    "  4. Créer un chemin d'accès spécifique avec le dossier de destination et le nom de fichier.\n",
    "  5. Écrire le contenu du PDF dans un fichier binaire à l'aide de `open()`.\n",
    "  6. Afficher un message de confirmation lorsque le téléchargement est réussi et retourner le chemin du fichier.\n",
    "  7. Gérer les exceptions liées aux requêtes HTTP pour éviter les plantages du script.\n",
    "\n",
    "- **Avantages** :\n",
    "  - Automatisation du téléchargement de fichiers PDF à partir d'URL externes.\n",
    "  - Enregistrement systématique sous un nom de fichier unique pour faciliter la gestion et l'accès.\n",
    "  - Gère les erreurs de connexion et les URL malformées pour éviter les interruptions.\n",
    "\n",
    "Prérequis :\n",
    "- Le module `requests` doit être installé et importé (`pip install requests`).\n",
    "- Le module `os` doit être importé pour gérer les chemins de fichiers (`import os`).\n",
    "- Un dossier cible (`pdf_folder`) doit être défini et exister pour que le fichier soit sauvegardé.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Fonction pour télécharger et enregistrer un PDF à partir d'une URL donnée\n",
    "def download_pdf(url, title):\n",
    "    try:\n",
    "        # Vérifier si l'URL commence par 'http://' ou 'https://'\n",
    "        # Si ce n'est pas le cas, ajouter 'https://' au début\n",
    "        if not (url.startswith('http://') or url.startswith('https://')):\n",
    "            url = 'https://' + url.lstrip('/')  # Corriger l'URL malformée en ajoutant le préfixe approprié\n",
    "\n",
    "        # Envoyer une requête HTTP GET à l'URL pour récupérer le contenu du PDF\n",
    "        response = requests.get(url)\n",
    "\n",
    "        # Vérifier si la requête est réussie (statut 200)\n",
    "        response.raise_for_status()  # Lève une exception si la requête a échoué\n",
    "\n",
    "        # Si la requête est réussie, enregistrer le PDF localement\n",
    "        if response.status_code == 200:\n",
    "            # Définir le chemin de sauvegarde du PDF avec le nom de fichier basé sur le titre\n",
    "            pdf_path = os.path.join(pdf_folder, title + \".pdf\")\n",
    "\n",
    "            # Ouvrir le fichier en mode binaire (wb) pour y écrire le contenu du PDF\n",
    "            with open(pdf_path, \"wb\") as pdf_file:\n",
    "                pdf_file.write(response.content)  # Écrire le contenu du fichier\n",
    "\n",
    "            # Afficher un message de succès et retourner le chemin d'accès\n",
    "            print(f\"PDF enregistré avec succès : {pdf_path}\")\n",
    "            return pdf_path  # Retourner le chemin du fichier PDF enregistré\n",
    "\n",
    "        else:\n",
    "            # Si le statut de la requête n'est pas 200, indiquer un échec\n",
    "            print(f\"Échec du téléchargement PDF : {title}\")\n",
    "            return None  # Retourner None en cas d'échec\n",
    "\n",
    "    # Gérer les exceptions liées aux requêtes HTTP (problèmes de connexion, URL incorrecte, etc.)\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Erreur lors du téléchargement du PDF {title} : {str(e)}\")  # Afficher l'erreur\n",
    "        return None  # Retourner None en cas d'exception\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export des données dans la BDD \n",
    "\n",
    "Cette fonction exporte un ensemble de documents sous forme de dictionnaires dans une collection MongoDB.\n",
    "L'objectif est de parcourir une liste de documents et de les insérer un par un dans une collection spécifiée.\n",
    "\n",
    "- **Objectif** : Exporter les données d'une liste de dictionnaires vers une collection MongoDB.\n",
    "- **Contexte** : Utilisé lorsqu'on souhaite sauvegarder des données structurées dans une base de données pour une utilisation future ou une analyse.\n",
    "\n",
    "- **Approche** :\n",
    "  1. Parcourir chaque document de la liste `data`.\n",
    "  2. Insérer chaque document dans la collection MongoDB spécifiée avec `insert_one()`.\n",
    "  3. Afficher un message de succès une fois l'insertion terminée.\n",
    "  4. Gérer les exceptions potentielles lors de l'insertion, telles que les erreurs de connexion ou les conflits de structure des documents.\n",
    "  \n",
    "- **Avantages** :\n",
    "  - Automatise l'insertion de plusieurs documents à la fois dans MongoDB.\n",
    "  - Permet de stocker les données de manière persistante pour une analyse ou une récupération ultérieure.\n",
    "  - Gère les exceptions pour détecter rapidement les problèmes lors de l'exportation.\n",
    "\n",
    "Prérequis :\n",
    "- Le module `pymongo` doit être installé et importé (`pip install pymongo`).\n",
    "- La connexion MongoDB et la collection (`collection`) doivent être préalablement définies dans le code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Fonction pour exporter une liste de documents vers une collection MongoDB\n",
    "def export_to_mongo(data):\n",
    "    try:\n",
    "        # Parcourir chaque document de la liste `data`\n",
    "        for document in data:\n",
    "            # Insérer chaque document dans la collection MongoDB spécifiée\n",
    "            collection.insert_one(document)  # `insert_one` ajoute le document dans la collection\n",
    "\n",
    "        # Afficher un message de confirmation lorsque l'exportation est réussie\n",
    "        print(f\"Données exportées avec succès vers MongoDB\")\n",
    "\n",
    "    # Gérer les erreurs lors de l'exportation vers MongoDB\n",
    "    except Exception as e:\n",
    "        # Afficher le message d'erreur dans la console\n",
    "        print(f\"Une erreur est survenue lors de l'exportation vers MongoDB : {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Récupération du nombre de commentaire \n",
    "\n",
    "Cette fonction récupère le nombre de commentaires d'une vidéo YouTube spécifiée par son URL.\n",
    "Elle utilise Selenium pour automatiser la navigation et l'extraction du nombre de commentaires, en gérant le cas où les commentaires seraient désactivés.\n",
    "\n",
    "- **Objectif** : Extraire le nombre de commentaires d'une vidéo YouTube en naviguant automatiquement sur la page de la vidéo.\n",
    "- **Contexte** : Utilisé dans des applications d'analyse de contenu YouTube ou de scraping, où le nombre de commentaires est un indicateur d'engagement.\n",
    "\n",
    "- **Approche** :\n",
    "  1. Charger la page de la vidéo spécifiée par `video_url` en utilisant `driver.get`.\n",
    "  2. Faire défiler la page vers le bas pour s'assurer que tous les éléments, y compris les commentaires, sont chargés.\n",
    "  3. Attendre la présence de l'élément `body` pour vérifier que la page est complètement chargée.\n",
    "  4. Rechercher un message indiquant que les commentaires sont désactivés.\n",
    "  5. Si les commentaires sont désactivés, définir le nombre de commentaires à `\"N/A\"` et afficher un message correspondant.\n",
    "  6. Si les commentaires ne sont pas désactivés, localiser l'élément contenant le nombre de commentaires et extraire son texte.\n",
    "  7. Gérer les exceptions en cas d'erreur de chargement de la page ou d'élément introuvable.\n",
    "  \n",
    "- **Avantages** :\n",
    "  - Automatise la récupération du nombre de commentaires pour plusieurs vidéos YouTube.\n",
    "  - Gère les cas particuliers, comme les commentaires désactivés ou les erreurs de chargement de la page.\n",
    "  - Affiche des messages d'erreur et de confirmation dans la console pour faciliter le suivi.\n",
    "\n",
    "Prérequis :\n",
    "- Le module `selenium` doit être installé et importé (`pip install selenium`).\n",
    "- Le driver Selenium (par exemple, ChromeDriver) doit être configuré pour interagir avec le navigateur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# Fonction pour récupérer le nombre de commentaires d'une vidéo YouTube\n",
    "def get_nombre_commentaire(driver, video_url):\n",
    "    try:\n",
    "        # Charger la page de la vidéo YouTube spécifiée\n",
    "        driver.get(video_url)  # Ouvre la vidéo via l'URL fournie\n",
    "\n",
    "        # Faire défiler la page vers le bas pour s'assurer que les commentaires sont chargés\n",
    "        driver.execute_script(\"window.scrollTo(0, document.documentElement.scrollHeight);\")\n",
    "\n",
    "        # Attendre que le contenu de la page soit chargé\n",
    "        WebDriverWait(driver, 5).until(\n",
    "            EC.presence_of_element_located((By.TAG_NAME, \"body\"))  # Vérifier que le corps de la page est entièrement chargé\n",
    "        )\n",
    "\n",
    "        # Essayer de détecter si les commentaires sont désactivés\n",
    "        try:\n",
    "            # Attendre l'élément contenant le texte \"Les commentaires sont désactivés\"\n",
    "            commentaire_desactive_element = WebDriverWait(driver, 20).until(\n",
    "                EC.presence_of_element_located((By.XPATH, \"//yt-formatted-string[contains(text(), 'Les commentaires sont désactivés')]\"))\n",
    "            )\n",
    "\n",
    "            # Si l'élément est trouvé, les commentaires sont désactivés\n",
    "            if commentaire_desactive_element:\n",
    "                nombre_commentaires = \"N/A\"  # Marquer le nombre de commentaires comme non applicable (désactivés)\n",
    "                print(\"Les commentaires sont désactivés sur cette vidéo.\")  # Afficher un message de confirmation\n",
    "\n",
    "        # Gérer le cas où le texte \"Les commentaires sont désactivés\" n'est pas trouvé\n",
    "        except TimeoutException:\n",
    "            # Si les commentaires ne sont pas désactivés, essayer d'extraire le nombre de commentaires\n",
    "            try:\n",
    "                # Extraire le texte indiquant le nombre de commentaires\n",
    "                nombre_commentaires = WebDriverWait(driver, 20).until(\n",
    "                    EC.presence_of_element_located((By.CSS_SELECTOR, 'yt-formatted-string.count-text.style-scope.ytd-comments-header-renderer'))\n",
    "                ).text  # Récupérer le texte du nombre de commentaires\n",
    "\n",
    "            # Gérer les exceptions lors de l'extraction du nombre de commentaires\n",
    "            except Exception as e:\n",
    "                nombre_commentaires = \"N/A\"  # Marquer le nombre de commentaires comme non applicable en cas d'erreur\n",
    "                print(f\"Erreur lors de l'extraction du nombre de commentaires : {str(e)}\")  # Afficher l'erreur\n",
    "\n",
    "    # Gérer les exceptions lors du chargement de la page de la vidéo\n",
    "    except Exception as e:\n",
    "        nombre_commentaires = \"N/A\"  # Marquer le nombre de commentaires comme non applicable\n",
    "        print(f\"Erreur lors du chargement de la vidéo : {str(e)}\")  # Afficher l'erreur dans la console\n",
    "\n",
    "    # Retourner le nombre de commentaires (ou \"N/A\" si désactivés ou en cas d'erreur)\n",
    "    return nombre_commentaires\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Récupération du titre de la vidéo\n",
    "\n",
    "Cette fonction récupère le titre d'une vidéo YouTube spécifiée par son URL.\n",
    "Elle utilise Selenium pour automatiser la navigation et l'extraction du titre de la vidéo.\n",
    "\n",
    "- **Objectif** : Extraire le titre de la vidéo à partir d'une URL donnée.\n",
    "- **Contexte** : Utilisé dans des applications de scraping, d'analyse de contenu ou de suivi des informations sur YouTube, où le titre de la vidéo est un élément clé.\n",
    "\n",
    "- **Approche** :\n",
    "  1. Charger la page de la vidéo YouTube à l'aide de `driver.get(video_url)`.\n",
    "  2. Utiliser `WebDriverWait` pour attendre que l'élément contenant le titre de la vidéo soit présent.\n",
    "  3. Une fois l'élément trouvé, extraire son texte à l'aide de `find_element` avec le sélecteur CSS correspondant.\n",
    "  4. Si l'élément est trouvé, retourner le texte extrait (le titre de la vidéo).\n",
    "  5. Si une exception survient (par exemple, élément introuvable ou problème de chargement), afficher un message d'erreur et retourner `\"N/A\"`.\n",
    "  \n",
    "- **Avantages** :\n",
    "  - Automatisation rapide et fiable de la récupération du titre des vidéos YouTube.\n",
    "  - Gère les exceptions pour détecter les erreurs d'élément introuvable ou les problèmes de chargement de la page.\n",
    "  - Retourne un message par défaut (\"N/A\") en cas d'échec, évitant ainsi les interruptions du script.\n",
    "\n",
    "Prérequis :\n",
    "- Le module `selenium` doit être installé et importé (`pip install selenium`).\n",
    "- Le driver Selenium (par exemple, ChromeDriver) doit être configuré pour interagir avec le navigateur.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Fonction pour récupérer le titre d'une vidéo YouTube\n",
    "def get_titre_video(driver, video_url):\n",
    "    try:\n",
    "        # Charger la page de la vidéo YouTube spécifiée\n",
    "        driver.get(video_url)  # Navigue vers l'URL de la vidéo\n",
    "\n",
    "        # Attendre que l'élément contenant le titre soit présent dans le DOM\n",
    "        WebDriverWait(driver, 20).until(\n",
    "            EC.presence_of_element_located(\n",
    "                (By.CSS_SELECTOR, 'div.style-scope.ytd-watch-metadata yt-formatted-string.style-scope.ytd-watch-metadata')\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Rechercher l'élément contenant le titre de la vidéo avec le sélecteur CSS correspondant\n",
    "        titre_video_element = driver.find_element(\n",
    "            By.CSS_SELECTOR, 'div.style-scope.ytd-watch-metadata yt-formatted-string.style-scope.ytd-watch-metadata'\n",
    "        )\n",
    "\n",
    "        # Si l'élément est trouvé, retourner le texte du titre, sinon retourner \"N/A\"\n",
    "        return titre_video_element.text.strip() if titre_video_element else 'N/A'\n",
    "\n",
    "    # Gérer les exceptions en cas de problème de chargement de la page ou d'élément introuvable\n",
    "    except Exception as e:\n",
    "        # Afficher l'erreur dans la console pour le suivi\n",
    "        print(f\"Erreur lors de la récupération du titre de la vidéo : {str(e)}\")\n",
    "        return 'N/A'  # Retourner \"N/A\" en cas d'erreur\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Récupération du nom de la chaîne \n",
    "\n",
    "Cette fonction récupère le nom du propriétaire (créateur) d'une vidéo YouTube spécifiée par son URL.\n",
    "Elle utilise Selenium pour automatiser la navigation et l'extraction du nom de la chaîne associée à la vidéo.\n",
    "\n",
    "- **Objectif** : Extraire le nom de la chaîne YouTube qui a publié la vidéo.\n",
    "- **Contexte** : Utilisé dans des applications d'analyse de contenu, de scraping ou de veille concurrentielle sur YouTube, où le nom de la chaîne est un indicateur clé pour identifier le créateur.\n",
    "\n",
    "- **Approche** :\n",
    "  1. Charger la page de la vidéo à l'aide de `driver.get(video_url)`.\n",
    "  2. Utiliser `WebDriverWait` pour attendre que l'élément contenant le nom de la chaîne soit chargé et visible.\n",
    "  3. Une fois l'élément trouvé, localiser le nom de la chaîne à l'aide de `find_element` avec le sélecteur CSS approprié.\n",
    "  4. Extraire et retourner le texte du nom de la chaîne s'il est trouvé, sinon retourner `\"N/A\"`.\n",
    "  5. Gérer les exceptions en cas de problème de chargement de la page ou si l'élément est introuvable, et afficher un message d'erreur.\n",
    "\n",
    "- **Avantages** :\n",
    "  - Automatisation rapide et fiable de la récupération du nom de la chaîne pour plusieurs vidéos YouTube.\n",
    "  - Gère les exceptions pour détecter les erreurs d'élément introuvable ou les problèmes de chargement de la page.\n",
    "  - Retourne un message par défaut (\"N/A\") en cas d'échec, évitant ainsi les interruptions du script.\n",
    "\n",
    "Prérequis :\n",
    "- Le module `selenium` doit être installé et importé (`pip install selenium`).\n",
    "- Le driver Selenium (par exemple, ChromeDriver) doit être configuré pour interagir avec le navigateur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Fonction pour récupérer le nom du propriétaire (chaîne YouTube) d'une vidéo\n",
    "def get_video_owner(driver, video_url):\n",
    "    try:\n",
    "        # Charger la page de la vidéo YouTube spécifiée\n",
    "        driver.get(video_url)  # Navigue vers l'URL de la vidéo YouTube\n",
    "\n",
    "        # Attendre que l'élément contenant le nom de la chaîne soit présent dans le DOM\n",
    "        WebDriverWait(driver, 20).until(\n",
    "            EC.presence_of_element_located(\n",
    "                (By.CSS_SELECTOR, 'div.style-scope ytd-channel-name a.yt-simple-endpoint.style-scope.yt-formatted-string')\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Rechercher l'élément contenant le nom de la chaîne avec le sélecteur CSS correspondant\n",
    "        owner_element = driver.find_element(\n",
    "            By.CSS_SELECTOR, 'div.style-scope ytd-channel-name a.yt-simple-endpoint.style-scope.yt-formatted-string'\n",
    "        )\n",
    "\n",
    "        # Si l'élément est trouvé, retourner le texte du propriétaire (nom de la chaîne), sinon retourner \"N/A\"\n",
    "        return owner_element.text.strip() if owner_element else 'N/A'\n",
    "\n",
    "    # Gérer les exceptions en cas de problème de chargement de la page ou d'élément introuvable\n",
    "    except Exception as e:\n",
    "        # Afficher l'erreur dans la console pour le suivi\n",
    "        print(f\"Erreur lors de la récupération du propriétaire de la vidéo : {str(e)}\")\n",
    "        return 'N/A'  # Retourner \"N/A\" en cas d'erreur\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Récupération du nombre de vues\n",
    "\n",
    "Cette fonction récupère le nombre de vues d'une vidéo YouTube spécifiée par son URL.\n",
    "Elle utilise Selenium pour automatiser la navigation et extraire le nombre de vues affiché sur la page de la vidéo.\n",
    "\n",
    "- **Objectif** : Extraire le nombre de vues d'une vidéo YouTube donnée.\n",
    "- **Contexte** : Utilisé dans des applications de scraping ou d'analyse de contenu YouTube pour évaluer la popularité d'une vidéo.\n",
    "\n",
    "- **Approche** :\n",
    "  1. Charger la page de la vidéo en utilisant `driver.get(video_url)`.\n",
    "  2. Utiliser `WebDriverWait` pour attendre que l'élément contenant le nombre de vues soit chargé et visible.\n",
    "  3. Localiser l'élément contenant le nombre de vues avec le sélecteur CSS approprié.\n",
    "  4. Extraire et retourner le texte indiquant le nombre de vues si l'élément est trouvé, sinon retourner `\"N/A\"`.\n",
    "  5. Gérer les exceptions en cas de problème de chargement de la page ou si l'élément est introuvable, et afficher un message d'erreur.\n",
    "\n",
    "- **Avantages** :\n",
    "  - Automatisation rapide et fiable de la récupération du nombre de vues pour plusieurs vidéos YouTube.\n",
    "  - Gère les exceptions pour détecter les erreurs d'élément introuvable ou les problèmes de chargement de la page.\n",
    "  - Retourne un message par défaut (\"N/A\") en cas d'échec, évitant ainsi les interruptions du script.\n",
    "\n",
    "Prérequis :\n",
    "- Le module `selenium` doit être installé et importé (`pip install selenium`).\n",
    "- Le driver Selenium (par exemple, ChromeDriver) doit être configuré pour interagir avec le navigateur.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Fonction pour récupérer le nombre de vues d'une vidéo YouTube\n",
    "def get_nombre_vues(driver, video_url):\n",
    "    try:\n",
    "        # Charger la page de la vidéo YouTube spécifiée\n",
    "        driver.get(video_url)  # Ouvre la page de la vidéo via l'URL donnée\n",
    "\n",
    "        # Attendre que l'élément contenant le nombre de vues soit présent dans le DOM\n",
    "        WebDriverWait(driver, 20).until(\n",
    "            EC.presence_of_element_located(\n",
    "                (By.CSS_SELECTOR, 'yt-formatted-string.style-scope.ytd-watch-info-text span.style-scope.yt-formatted-string.bold')\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Rechercher l'élément contenant le nombre de vues avec le sélecteur CSS correspondant\n",
    "        vues_element = driver.find_element(\n",
    "            By.CSS_SELECTOR, 'yt-formatted-string.style-scope.ytd-watch-info-text span.style-scope.yt-formatted-string.bold'\n",
    "        )\n",
    "\n",
    "        # Si l'élément est trouvé, retourner le texte du nombre de vues, sinon retourner \"N/A\"\n",
    "        return vues_element.text.strip() if vues_element else 'N/A'\n",
    "\n",
    "    # Gérer les exceptions en cas de problème de chargement de la page ou d'élément introuvable\n",
    "    except Exception as e:\n",
    "        # Afficher l'erreur dans la console pour le suivi\n",
    "        print(f\"Erreur lors de la récupération du nombre de vues : {str(e)}\")\n",
    "        return 'N/A'  # Retourner \"N/A\" en cas d'erreur\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Récupération du nombre de likes \n",
    "\n",
    "Cette fonction récupère le nombre de likes d'une vidéo YouTube spécifiée par son URL.\n",
    "Elle utilise Selenium pour automatiser la navigation et extraire le nombre de likes affiché sur la page de la vidéo.\n",
    "\n",
    "- **Objectif** : Extraire le nombre de likes d'une vidéo YouTube donnée.\n",
    "- **Contexte** : Utilisé dans des applications d'analyse de contenu YouTube pour évaluer la popularité d'une vidéo à travers le nombre de likes.\n",
    "\n",
    "- **Approche** :\n",
    "  1. Charger la page de la vidéo en utilisant `driver.get(video_url)`.\n",
    "  2. Utiliser `WebDriverWait` pour attendre que l'élément contenant le nombre de likes soit chargé et visible.\n",
    "  3. Localiser l'élément correspondant avec le sélecteur XPath approprié.\n",
    "  4. Extraire et retourner le texte indiquant le nombre de likes s'il est trouvé, sinon retourner `\"N/A\"`.\n",
    "  5. Remplacer le texte `\"J'aime\"` par `0` pour les vidéos sans like affiché.\n",
    "  6. Gérer les exceptions en cas de problème de chargement de la page ou si l'élément est introuvable, et afficher un message d'erreur.\n",
    "\n",
    "- **Avantages** :\n",
    "  - Automatisation rapide et fiable de la récupération du nombre de likes pour plusieurs vidéos YouTube.\n",
    "  - Gère les exceptions pour détecter les erreurs d'élément introuvable ou les problèmes de chargement de la page.\n",
    "  - Retourne un message par défaut (\"N/A\") en cas d'échec, évitant ainsi les interruptions du script.\n",
    "\n",
    "Prérequis :\n",
    "- Le module `selenium` doit être installé et importé (`pip install selenium`).\n",
    "- Le driver Selenium (par exemple, ChromeDriver) doit être configuré pour interagir avec le navigateur.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fonction pour récupérer le nombre de likes d'une vidéo YouTube\n",
    "def get_nombre_likes(driver, video_url):\n",
    "    try:\n",
    "        # Accéder à l'URL de la vidéo YouTube spécifiée\n",
    "        driver.get(video_url)  # Ouvre la page de la vidéo via l'URL donnée\n",
    "\n",
    "        # Attendre que l'élément contenant le nombre de likes soit présent dans le DOM\n",
    "        WebDriverWait(driver, 20).until(\n",
    "            EC.presence_of_element_located(\n",
    "                (By.XPATH, '/html/body/ytd-app/div[1]/ytd-page-manager/ytd-watch-flexy/div[5]/div[1]/div/div[2]/ytd-watch-metadata/div/div[2]/div[2]/div/div/ytd-menu-renderer/div[1]/segmented-like-dislike-button-view-model/yt-smartimation/div/div/like-button-view-model/toggle-button-view-model/button-view-model/button/div[2]')\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Rechercher l'élément contenant le nombre de likes avec le sélecteur XPath correspondant\n",
    "        likes_element = driver.find_element(\n",
    "            By.XPATH, '/html/body/ytd-app/div[1]/ytd-page-manager/ytd-watch-flexy/div[5]/div[1]/div/div[2]/ytd-watch-metadata/div/div[2]/div[2]/div/div/ytd-menu-renderer/div[1]/segmented-like-dislike-button-view-model/yt-smartimation/div/div/like-button-view-model/toggle-button-view-model/button-view-model/button/div[2]'\n",
    "        )\n",
    "\n",
    "        # Si l'élément est trouvé, récupérer le texte du nombre de likes, sinon retourner \"N/A\"\n",
    "        likes_text = likes_element.text.strip() if likes_element else 'N/A'\n",
    "\n",
    "        # Si le texte est \"J'aime\", cela signifie qu'il n'y a pas de likes affichés, donc retourner 0\n",
    "        return 0 if likes_text == \"J'aime\" else likes_text\n",
    "\n",
    "    # Gérer les exceptions en cas de problème de chargement de la page ou d'élément introuvable\n",
    "    except Exception as e:\n",
    "        # Afficher l'erreur dans la console pour le suivi\n",
    "        print(f\"Erreur lors de la récupération du nombre de likes : {str(e)}\")\n",
    "        return 'N/A'  # Retourner \"N/A\" en cas d'erreur\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Récupétaion de la description\n",
    "\n",
    "Cette fonction récupère la description complète d'une vidéo YouTube spécifiée par son URL.\n",
    "Elle utilise Selenium pour naviguer automatiquement sur la page, cliquer sur le bouton \"Afficher plus\" (si présent), et extraire la description en utilisant BeautifulSoup pour analyser le contenu HTML.\n",
    "\n",
    "- **Objectif** : Extraire la description complète d'une vidéo YouTube.\n",
    "- **Contexte** : Utilisé dans des applications d'analyse de contenu YouTube, où la description peut contenir des informations clés comme des liens, des mots-clés, ou des détails supplémentaires sur la vidéo.\n",
    "\n",
    "- **Approche** :\n",
    "  1. Charger la page de la vidéo en utilisant `driver.get(video_url)`.\n",
    "  2. Utiliser `WebDriverWait` pour attendre que l'élément de description soit chargé et visible.\n",
    "  3. Cliquer sur le bouton \"Afficher plus\" pour révéler la description complète (si présent).\n",
    "  4. Extraire le contenu HTML de la description à l'aide de `get_attribute('innerHTML')`.\n",
    "  5. Utiliser `BeautifulSoup` pour parser le HTML et récupérer tous les éléments de description (balises `<span>`).\n",
    "  6. Rechercher les textes associés à chaque lien et les concaténer pour obtenir la description complète.\n",
    "  7. Gérer les exceptions en cas de problème de chargement de la page ou si l'élément est introuvable, et afficher un message d'erreur.\n",
    "\n",
    "- **Avantages** :\n",
    "  - Automatise la récupération de la description complète, même si elle est partiellement cachée par défaut.\n",
    "  - Gère les exceptions pour détecter les erreurs d'élément introuvable ou les problèmes de chargement de la page.\n",
    "  - Retourne un message par défaut (\"N/A\") en cas d'échec, évitant ainsi les interruptions du script.\n",
    "\n",
    "Prérequis :\n",
    "- Le module `selenium` doit être installé et importé (`pip install selenium`).\n",
    "- Le module `bs4` (BeautifulSoup) doit être installé (`pip install beautifulsoup4`).\n",
    "- Le driver Selenium (par exemple, ChromeDriver) doit être configuré pour interagir avec le navigateur.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Fonction pour récupérer la description d'une vidéo YouTube\n",
    "def get_description_video(driver, video_url):\n",
    "    try:\n",
    "        # Charger la page de la vidéo YouTube spécifiée\n",
    "        driver.get(video_url)  # Ouvre la page de la vidéo via l'URL donnée\n",
    "\n",
    "        # Attendre que l'élément contenant la description soit présent dans le DOM\n",
    "        WebDriverWait(driver, 20).until(\n",
    "            EC.presence_of_element_located(\n",
    "                (By.CSS_SELECTOR, 'yt-attributed-string.style-scope.ytd-text-inline-expander span.yt-core-attributed-string.yt-core-attributed-string--white-space-pre-wrap')\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Essayer de cliquer sur le bouton \"Afficher plus\" pour afficher la description complète\n",
    "        try:\n",
    "            # Attendre que le bouton \"Afficher plus\" soit cliquable et cliquer dessus\n",
    "            afficher_plus_button = WebDriverWait(driver, 20).until(\n",
    "                EC.element_to_be_clickable((By.XPATH, \"/html/body/ytd-app/div[1]/ytd-page-manager/ytd-watch-flexy/div[5]/div[1]/div/div[2]/ytd-watch-metadata/div/div[4]/div[1]/div/ytd-text-inline-expander/tp-yt-paper-button[1]\"))\n",
    "            )\n",
    "            afficher_plus_button.click()  # Cliquer sur le bouton\n",
    "            print(\"Le bouton 'Afficher plus' a été cliqué.\")  # Confirmation du clic\n",
    "            time.sleep(2)  # Pause de 2 secondes pour laisser le temps à la description de s'afficher\n",
    "\n",
    "        # Gérer le cas où le bouton \"Afficher plus\" est introuvable ou non cliquable\n",
    "        except Exception:\n",
    "            print(f\"Erreur lors du clic sur 'Afficher plus'\")\n",
    "\n",
    "        # Rechercher l'élément contenant la description complète\n",
    "        description_video_element = driver.find_element(\n",
    "            By.CSS_SELECTOR, 'yt-attributed-string.style-scope.ytd-text-inline-expander span.yt-core-attributed-string.yt-core-attributed-string--white-space-pre-wrap'\n",
    "        )\n",
    "\n",
    "        # Si l'élément est trouvé, extraire et parser le contenu HTML de la description\n",
    "        if description_video_element:\n",
    "            html_content = description_video_element.get_attribute('innerHTML')  # Récupérer le HTML de la description\n",
    "            soup = bs(html_content, 'html.parser')  # Analyser le HTML avec BeautifulSoup\n",
    "\n",
    "            # Extraire tous les éléments <span> de la description\n",
    "            all_spans = soup.find_all('span')\n",
    "\n",
    "            # Parcourir tous les <span> pour récupérer les textes des liens dans la description\n",
    "            description_texts = []\n",
    "            for span in all_spans:\n",
    "                # Vérifier si le <span> contient un lien et extraire son texte\n",
    "                if 'yt-core-attributed-string--link-inherit-color' in span.get('class', []):\n",
    "                    description_texts.append(span.get_text().strip())  # Ajouter le texte du lien à la liste\n",
    "\n",
    "            # Concaténer tous les textes de description récupérés\n",
    "            description = ' '.join(description_texts)\n",
    "\n",
    "            # Retourner la description finale si elle est trouvée, sinon retourner \"N/A\"\n",
    "            return description if description else 'N/A'\n",
    "        \n",
    "        # Si l'élément de description n'est pas trouvé, retourner \"N/A\"\n",
    "        else:\n",
    "            return 'N/A'\n",
    "\n",
    "    # Gérer les exceptions en cas de problème de chargement de la page ou d'élément introuvable\n",
    "    except Exception as e:\n",
    "        # Afficher l'erreur dans la console pour le suivi\n",
    "        print(f\"Erreur lors de la récupération de la description : {str(e)}\")\n",
    "        return 'N/A'  # Retourner \"N/A\" en cas d'erreur\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Récupération de la date de publication\n",
    "\n",
    "Cette fonction récupère la date de publication d'une vidéo YouTube spécifiée par son URL.\n",
    "Elle utilise Selenium pour naviguer automatiquement sur la page de la vidéo et extraire la date de publication affichée.\n",
    "\n",
    "- **Objectif** : Extraire la date de publication d'une vidéo YouTube.\n",
    "- **Contexte** : Utilisé dans des applications d'analyse de contenu YouTube ou de veille pour déterminer la date de mise en ligne de la vidéo.\n",
    "\n",
    "- **Approche** :\n",
    "  1. Charger la page de la vidéo en utilisant `driver.get(video_url)`.\n",
    "  2. Utiliser `WebDriverWait` pour attendre que l'élément contenant la date de publication soit chargé et visible.\n",
    "  3. Localiser l'élément correspondant avec le sélecteur XPath approprié.\n",
    "  4. Extraire et retourner le texte indiquant la date de publication s'il est trouvé, sinon retourner `\"N/A\"`.\n",
    "  5. Gérer les exceptions en cas de problème de chargement de la page ou si l'élément est introuvable, et afficher un message d'erreur.\n",
    "\n",
    "- **Avantages** :\n",
    "  - Automatisation rapide et fiable de la récupération de la date de publication pour plusieurs vidéos YouTube.\n",
    "  - Gère les exceptions pour détecter les erreurs d'élément introuvable ou les problèmes de chargement de la page.\n",
    "  - Retourne un message par défaut (\"N/A\") en cas d'échec, évitant ainsi les interruptions du script.\n",
    "\n",
    "Prérequis :\n",
    "- Le module `selenium` doit être installé et importé (`pip install selenium`).\n",
    "- Le driver Selenium (par exemple, ChromeDriver) doit être configuré pour interagir avec le navigateur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Fonction pour récupérer la date de publication d'une vidéo YouTube\n",
    "def get_date_publication(driver, video_url):\n",
    "    try:\n",
    "        # Charger la page de la vidéo YouTube spécifiée\n",
    "        driver.get(video_url)  # Ouvre la page de la vidéo via l'URL donnée\n",
    "\n",
    "        # Attendre que l'élément contenant la date de publication soit présent dans le DOM\n",
    "        WebDriverWait(driver, 20).until(\n",
    "            EC.presence_of_element_located(\n",
    "                (By.XPATH, '/html/body/ytd-app/div[1]/ytd-page-manager/ytd-watch-flexy/div[5]/div[1]/div/div[2]/ytd-watch-metadata/div/div[4]/div[1]/div/ytd-watch-info-text/div/yt-formatted-string/span[3]')\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Rechercher l'élément contenant la date de publication avec le sélecteur XPath correspondant\n",
    "        date_element = driver.find_element(\n",
    "            By.XPATH, '/html/body/ytd-app/div[1]/ytd-page-manager/ytd-watch-flexy/div[5]/div[1]/div/div[2]/ytd-watch-metadata/div/div[4]/div[1]/div/ytd-watch-info-text/div/yt-formatted-string/span[3]'\n",
    "        )\n",
    "\n",
    "        # Si l'élément est trouvé, retourner le texte de la date, sinon retourner \"N/A\"\n",
    "        return date_element.text.strip() if date_element else 'N/A'\n",
    "\n",
    "    # Gérer les exceptions en cas de problème de chargement de la page ou d'élément introuvable\n",
    "    except Exception as e:\n",
    "        # Afficher l'erreur dans la console pour le suivi\n",
    "        print(f\"Erreur lors de la récupération de la date de publication : {str(e)}\")\n",
    "        return 'N/A'  # Retourner \"N/A\" en cas d'erreur\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction et organisation de toutes les données\n",
    "\n",
    "Cette fonction extrait des informations structurées à partir d'une page web spécifiée par son URL.\n",
    "Elle utilise BeautifulSoup pour analyser le contenu HTML et Selenium pour interagir avec les vidéos YouTube liées, afin de récupérer des détails comme le titre, la description, le type de document, le lieu, les thématiques et d'autres informations.\n",
    "\n",
    "- **Objectif** : Récupérer des informations d'un document (texte, PDF ou vidéo) à partir de l'URL fournie.\n",
    "- **Contexte** : Utilisé dans des applications de scraping pour extraire automatiquement des informations clés de pages web et des vidéos intégrées (par exemple, YouTube).\n",
    "\n",
    "- **Approche** :\n",
    "  1. Envoyer une requête GET à l'URL spécifiée pour récupérer le contenu HTML de la page.\n",
    "  2. Utiliser BeautifulSoup pour extraire le titre, la description, le type de document, le lieu et d'autres informations à partir des balises correspondantes.\n",
    "  3. Si le document est une vidéo, utiliser Selenium pour récupérer des informations supplémentaires (titre de la vidéo, propriétaire, nombre de vues, nombre de likes, etc.).\n",
    "  4. Télécharger les fichiers PDF s'ils sont présents sur la page et enregistrer leurs chemins d'accès.\n",
    "  5. Structurer toutes les informations extraites dans un dictionnaire et les retourner.\n",
    "  6. Gérer les exceptions en cas de problème de chargement de la page ou si les éléments sont introuvables.\n",
    "\n",
    "- **Avantages** :\n",
    "  - Automatisation de l'extraction des informations structurées, ce qui réduit le temps de collecte manuelle.\n",
    "  - Gestion des vidéos intégrées avec Selenium pour obtenir des informations détaillées (YouTube).\n",
    "  - Téléchargement des fichiers PDF associés à la page pour un stockage local.\n",
    "\n",
    "Prérequis :\n",
    "- Le module `requests` doit être installé et importé (`pip install requests`).\n",
    "- Le module `bs4` (BeautifulSoup) doit être installé (`pip install beautifulsoup4`).\n",
    "- Le module `selenium` doit être installé (`pip install selenium`).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Fonction pour extraire les informations d'une page web et gérer les vidéos associées\n",
    "def get_info(link, driver):\n",
    "    try:\n",
    "        # Envoyer une requête GET à l'URL pour récupérer le contenu de la page\n",
    "        page = requests.get(link)\n",
    "        soup = bs(page.content, 'html.parser')  # Analyser le HTML de la page\n",
    "\n",
    "        # Récupérer le titre de la page\n",
    "        Titre = soup.find('div', id=\"block-rexbp-page-title\")\n",
    "        Titre = Titre.find('span').string.strip() if Titre else 'N/A'\n",
    "\n",
    "        # Récupérer la description de la page\n",
    "        Description = soup.find('div', class_=\"field_texte\")\n",
    "        Description_text = []\n",
    "\n",
    "        # Vérifier s'il y a plusieurs paragraphes dans la description et les extraire\n",
    "        if Description:\n",
    "            paragraphs = Description.find_all('p')\n",
    "            if len(paragraphs) > 1:\n",
    "                for p in paragraphs[:-1]:\n",
    "                    Description_text.append(p.get_text().strip())  # Ajouter chaque paragraphe à la liste\n",
    "            elif len(paragraphs) == 1:\n",
    "                Description_text.append(paragraphs[0].get_text().strip())  # Si un seul paragraphe, l'ajouter\n",
    "            else:\n",
    "                Description_text = 'N/A'  # Pas de paragraphes trouvés\n",
    "        else:\n",
    "            Description_text = 'N/A'  # Pas de description trouvée\n",
    "\n",
    "        # Convertir la liste des paragraphes en une chaîne de caractères\n",
    "        Description_text = ' '.join(Description_text)\n",
    "\n",
    "        # Récupérer le type de document\n",
    "        Type_document = soup.find('div', class_=\"field_type_document\")\n",
    "        Type_document = Type_document.find('div', class_=\"name\").string if Type_document else 'N/A'\n",
    "\n",
    "        # Récupérer le lieu du document\n",
    "        territory = soup.find(class_=\"field_territoire\")\n",
    "        Lieu = territory.text.strip() if territory else 'N/A'\n",
    "\n",
    "        # Récupérer la source du document (dernier paragraphe)\n",
    "        field_texte_div = soup.find('div', class_='field_texte')\n",
    "        if field_texte_div:\n",
    "            paragraphs = field_texte_div.find_all('p')\n",
    "            if paragraphs:\n",
    "                last_paragraph = paragraphs[-1]\n",
    "                Source = last_paragraph.get_text().strip()\n",
    "            else:\n",
    "                Source = 'N/A'\n",
    "        else:\n",
    "            Source = 'N/A'\n",
    "\n",
    "        # Récupérer la thématique associée au document\n",
    "        thematique_div = soup.find('div', class_='field_thematique')\n",
    "        Thematique = thematique_div.find('div', class_='name').string.strip() if thematique_div else 'N/A'\n",
    "\n",
    "        # Initialiser les variables pour les informations de la vidéo\n",
    "        Propriétaire_video = 'N/A'\n",
    "        Titre_vidéo = 'N/A'\n",
    "        Nb_commentaire_video = 'N/A'\n",
    "        Nb_vues_video = 'N/A'\n",
    "        Nb_likes_video = 'N/A'\n",
    "        Description_video = 'N/A'\n",
    "        Lien_video = 'N/A'\n",
    "        Date_publication_video = 'N/A'\n",
    "\n",
    "        # Si le type de document est une vidéo, extraire les informations vidéo avec Selenium\n",
    "        if Type_document.lower() == 'vidéo':\n",
    "            video_div = soup.find('div', class_='video-miniature')\n",
    "            if video_div:\n",
    "                video_url = video_div.get('data-url')  # Récupérer l'URL de la vidéo\n",
    "                if video_url:\n",
    "                    driver.get(video_url)\n",
    "                    time.sleep(3)  # Pause pour permettre le chargement de la vidéo\n",
    "\n",
    "                    # Refuser les cookies sur YouTube avant de continuer\n",
    "                    click_refuse_youtube_cookies(driver)\n",
    "                    \n",
    "                    # Vérifier si la vidéo est disponible\n",
    "                    if \"cette vidéo n'est plus disponible\" not in driver.page_source.lower():\n",
    "                        Propriétaire_video = get_video_owner(driver, video_url)\n",
    "                        Titre_vidéo = get_titre_video(driver, video_url)\n",
    "                        Nb_commentaire_video = get_nombre_commentaire(driver, video_url)\n",
    "                        Nb_vues_video = get_nombre_vues(driver, video_url)\n",
    "                        Nb_likes_video = get_nombre_likes(driver, video_url)\n",
    "                        Description_video = get_description_video(driver, video_url)\n",
    "                        Date_publication_video = get_date_publication(driver, video_url)\n",
    "                        Lien_video = video_url\n",
    "                    else:\n",
    "                        print(\"Cette vidéo n'est plus disponible.\")\n",
    "\n",
    "        # Récupérer les liens vers les fichiers PDF présents sur la page\n",
    "        pdf_div = soup.find('div', class_='field_pdf')\n",
    "        pdf_paths = []\n",
    "        if pdf_div:\n",
    "            pdf_links = pdf_div.find_all('a')\n",
    "            for index, a_tag in enumerate(pdf_links):\n",
    "                pdf_url = a_tag.get('href')\n",
    "                pdf_path = download_pdf(pdf_url, f\"{Titre}_pdf_{index + 1}\")  # Télécharger et enregistrer le PDF\n",
    "                if pdf_path:\n",
    "                    pdf_paths.append(pdf_path)  # Ajouter le chemin du fichier PDF\n",
    "\n",
    "        # Créer un dictionnaire contenant toutes les informations extraites\n",
    "        document = {\n",
    "            \"Titre\": Titre,\n",
    "            \"Thématique\": Thematique,\n",
    "            \"Description\": Description_text,\n",
    "            \"Type_document\": Type_document,\n",
    "            \"Source\": Source,\n",
    "            \"Lieu\": Lieu,\n",
    "            \"Lien\": link,\n",
    "            \"Propriétaire_video\": Propriétaire_video,\n",
    "            \"Titre_vidéo\": Titre_vidéo,\n",
    "            \"Nb_commentaire_video\": Nb_commentaire_video,\n",
    "            \"Nb_vues_video\": Nb_vues_video,\n",
    "            \"Nb_likes_video\": Nb_likes_video,\n",
    "            \"Description_video\": Description_video,\n",
    "            \"Lien_video\": Lien_video,\n",
    "            \"Date_publication_video\": Date_publication_video,\n",
    "            \"PDFs\": pdf_paths  # Ajouter les chemins d'accès des fichiers PDF\n",
    "        }\n",
    "\n",
    "        # Retourner le dictionnaire des informations extraites\n",
    "        return document\n",
    "\n",
    "    # Gérer les erreurs lors de l'extraction des informations\n",
    "    except Exception as e:\n",
    "        print(f\"Une erreur est survenue lors de l'extraction des informations : {str(e)}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Pagination et collecte de liens\n",
    "\n",
    "Cette fonction parcourt les pages d'une liste de ressources sur un site web, en collectant les liens pertinents et en les stockant dans une liste.\n",
    "Elle utilise Selenium pour automatiser la navigation entre les pages et BeautifulSoup pour analyser le contenu HTML.\n",
    "\n",
    "- **Objectif** : Extraire les liens vers les ressources sur plusieurs pages d'un site.\n",
    "- **Contexte** : Utilisé dans des applications de scraping pour parcourir une liste paginée de ressources et collecter les liens des offres d'emploi ou des ressources spécifiques.\n",
    "\n",
    "- **Approche** :\n",
    "  1. Charger chaque page et attendre que tous les articles soient chargés.\n",
    "  2. Utiliser BeautifulSoup pour analyser le contenu HTML et extraire les liens des articles pertinents.\n",
    "  3. Ajouter les liens des articles qui ne sont pas déjà présents dans `link_list`.\n",
    "  4. Naviguer à la page suivante en cliquant sur le bouton \"Suivant\" si disponible.\n",
    "  5. Répéter jusqu'à ce qu'il n'y ait plus de pages ou qu'une erreur survienne (comme l'absence du bouton \"Suivant\").\n",
    "  6. Retourner la liste complète des liens collectés.\n",
    "\n",
    "- **Avantages** :\n",
    "  - Automatisation de la collecte de liens à travers plusieurs pages, économisant le temps d'extraction manuel.\n",
    "  - Utilisation combinée de Selenium et BeautifulSoup pour garantir la collecte même sur des pages dynamiques.\n",
    "  - Gère la pagination de manière continue et stoppe proprement lorsqu'il n'y a plus de pages.\n",
    "\n",
    "Prérequis :\n",
    "- Le module `selenium` doit être installé et importé (`pip install selenium`).\n",
    "- Le module `bs4` (BeautifulSoup) doit être installé (`pip install beautifulsoup4`).\n",
    "- Le driver Selenium (par exemple, ChromeDriver) doit être configuré pour interagir avec le navigateur.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fonction pour parcourir les pages d'une liste de ressources et collecter les liens pertinents\n",
    "def paginate_and_collect_link(driver, link_list):\n",
    "    page_count = 0  # Initialiser le compteur de pages\n",
    "\n",
    "    while True:  # Boucle pour parcourir toutes les pages\n",
    "        print(f\"Traitement de la page {page_count + 1}\")  # Indiquer la page en cours de traitement\n",
    "\n",
    "        # Attendre que tous les articles sur la page soient chargés\n",
    "        WebDriverWait(driver, 20).until(\n",
    "            EC.presence_of_all_elements_located((By.CSS_SELECTOR, \".views-infinite-scroll-content-wrapper.clearfix .views-row article\"))\n",
    "        )\n",
    "\n",
    "        # Analyser le contenu de la page avec BeautifulSoup\n",
    "        soup = bs(driver.page_source, 'html.parser')\n",
    "        articles = soup.find_all('article')  # Extraire tous les éléments <article>\n",
    "\n",
    "        # Parcourir chaque article pour extraire les liens pertinents\n",
    "        for article in articles:\n",
    "            about_attr = article.get('about')  # Récupérer l'attribut 'about'\n",
    "            if about_attr and \"/ressource/\" in about_attr and about_attr not in link_list:\n",
    "                # Ajouter le lien complet à la liste des jobs s'il n'y est pas déjà\n",
    "                link_list.append(\"https://www.dispositif-rexbp.com\" + about_attr)\n",
    "\n",
    "        # Afficher le nombre d'éléments collectés après chaque page\n",
    "        print(f\"Nombre d'éléments dans link_list après la page {page_count + 1} : {len(link_list)}\")\n",
    "        page_count += 1  # Incrémenter le compteur de pages\n",
    "\n",
    "        try:\n",
    "            # Rechercher le bouton \"Suivant\" pour passer à la page suivante\n",
    "            next_button = driver.find_element(By.CSS_SELECTOR, 'li.pager__item a[rel=\"next\"]')\n",
    "            if next_button:\n",
    "                next_button.click()  # Cliquer sur le bouton \"Suivant\"\n",
    "                print(f\"Cliqué sur le bouton suivant pour la page {page_count + 1}\")\n",
    "                time.sleep(5)  # Pause pour laisser le temps à la nouvelle page de charger\n",
    "            else:\n",
    "                print(\"Aucun bouton 'Suivant' trouvé, fin de la pagination.\")\n",
    "                break  # Sortir de la boucle si aucun bouton \"Suivant\" n'est trouvé\n",
    "\n",
    "        # Gérer les erreurs ou l'absence du bouton \"Suivant\"\n",
    "        except Exception:\n",
    "            print(f\"Erreur lors du clic sur le bouton suivant ou fin de la pagination\")\n",
    "            break  # Sortir de la boucle en cas d'erreur\n",
    "\n",
    "    # Retourner la liste des liens collectés\n",
    "    return link_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recherche par thème\n",
    "\n",
    "Cette fonction effectue une recherche sur un site web pour extraire des URL correspondant à différents thèmes.\n",
    "Elle automatise le processus de recherche pour chaque thème, navigue à travers plusieurs pages pour collecter les URL,\n",
    "extrait les informations de chaque URL trouvée, et stocke les données collectées dans une base de données MongoDB.\n",
    "\n",
    "- **Objectif** : Automatiser la collecte d'URL de ressources basées sur différents thèmes, extraire les informations de chaque URL, et les sauvegarder dans MongoDB.\n",
    "- **Contexte** : Utilisé dans des applications de scraping pour collecter automatiquement des informations structurées à partir de sites web avec plusieurs pages de ressources.\n",
    "\n",
    "- **Approche** :\n",
    "  1. Initialiser un navigateur Selenium pour naviguer sur le site cible.\n",
    "  2. Définir les thèmes de recherche à explorer.\n",
    "  3. Pour chaque thème, effectuer une recherche sur le site et vérifier s'il y a des résultats.\n",
    "  4. Si des résultats sont trouvés, collecter les URL de chaque page de résultats.\n",
    "  5. Pour chaque URL, extraire les informations pertinentes (titre, description, type, etc.).\n",
    "  6. Organiser les informations extraites dans un document structuré et l'exporter vers MongoDB.\n",
    "  7. Fermer le navigateur Selenium à la fin de l'exécution.\n",
    "  \n",
    "- **Avantages** :\n",
    "  - Automatisation complète du processus de collecte d'informations, réduisant le temps nécessaire pour la collecte manuelle.\n",
    "  - Structure les données extraites pour une insertion facile dans une base de données.\n",
    "  - Gère les erreurs et affiche les messages de progression pour un suivi en temps réel.\n",
    "\n",
    "Prérequis :\n",
    "- Le module `selenium` doit être installé et importé (`pip install selenium`).\n",
    "- Le driver Selenium (par exemple, ChromeDriver) doit être configuré pour interagir avec le navigateur.\n",
    "- Une base de données MongoDB doit être accessible pour stocker les informations extraites.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fonction principale pour rechercher, extraire et stocker des informations basées sur des thèmes\n",
    "def extract_urls_and_info():\n",
    "    # Initialiser le navigateur Selenium avec Chrome\n",
    "    driver = webdriver.Chrome()\n",
    "\n",
    "    try:\n",
    "        # Définir la liste des thèmes à rechercher\n",
    "        themes = [\"Métiers de l'encadrement\", \"BIM\"]  # Ajouter ici d'autres thèmes si nécessaire\n",
    "        \n",
    "        # Parcourir chaque thème de la liste\n",
    "        for theme in themes:\n",
    "            print(f\"Recherche pour le thème : {theme}\")\n",
    "\n",
    "            # Ouvrir la page de recherche des ressources\n",
    "            driver.get(\"https://www.dispositif-rexbp.com/ressources\")\n",
    "\n",
    "            # Lancer la recherche pour le thème spécifié\n",
    "            search_by_theme(driver, theme)\n",
    "\n",
    "            # Vérifier si des résultats sont disponibles pour le thème\n",
    "            if check_no_results(driver):\n",
    "                print(f\"Pas de résultats pour le thème : {theme}. Passage au thème suivant.\")\n",
    "                continue  # Passer au thème suivant si aucun résultat n'est trouvé\n",
    "\n",
    "            # Initialiser une liste pour collecter les URL des ressources\n",
    "            link_list = []\n",
    "            link_list = paginate_and_collect_link(driver, link_list)  # Paginer et collecter les liens d'articles\n",
    "\n",
    "            # Afficher le nombre total de ressources collectées pour le thème actuel\n",
    "            print(f\"Nombre total d'éléments dans link_list pour le thème {theme} : {len(link_list)}\")\n",
    "\n",
    "            # Créer une liste pour stocker les données associées au thème\n",
    "            theme_data = []\n",
    "\n",
    "            # Parcourir chaque URL collectée dans `jobs_list`\n",
    "            for index, url in enumerate(link_list):\n",
    "                print(f\"Traitement de l'URL {index + 1}/{len(link_list)}: {url}\")\n",
    "                \n",
    "                # Extraire les informations de chaque URL\n",
    "                data = get_info(url, driver)\n",
    "                \n",
    "                # Si des informations sont extraites avec succès, les ajouter à `theme_data`\n",
    "                if data:\n",
    "                    theme_data.append(data)\n",
    "                    print(f\"Données ajoutées avec succès pour l'URL : {url}\")\n",
    "                else:\n",
    "                    print(f\"Échec de la récupération des données pour l'URL : {url}\")\n",
    "\n",
    "            # Si des données ont été collectées pour le thème, créer un document structuré\n",
    "            if theme_data:\n",
    "                # Créer un document thématique contenant toutes les données du thème\n",
    "                document = {\n",
    "                    \"theme\": theme,  # Ajouter le nom du thème\n",
    "                    \"data\": theme_data,  # Ajouter toutes les données extraites\n",
    "                    \"date_extraction\": time.strftime(\"%Y-%m-%d %H:%M:%S\")  # Ajouter la date de l'extraction\n",
    "                }\n",
    "                \n",
    "                # Exporter le document vers la base de données MongoDB\n",
    "                export_to_mongo([document])\n",
    "                print(f\"Données exportées avec succès pour le thème : {theme}\")\n",
    "\n",
    "    # Fermer le navigateur Selenium à la fin de l'exécution ou en cas d'erreur\n",
    "    finally:\n",
    "        driver.quit()\n",
    "        print(\"Le navigateur Selenium a été fermé.\")\n",
    "\n",
    "# Exécuter la fonction `extract_urls_and_info()` si le script est lancé directement\n",
    "if __name__ == \"__main__\":\n",
    "    extract_urls_and_info()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
